{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import RidgeClassifier, LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve, auc, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import TunedThresholdClassifierCV\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>safra</th>\n",
       "      <th>y</th>\n",
       "      <th>VAR_1</th>\n",
       "      <th>VAR_2</th>\n",
       "      <th>VAR_3</th>\n",
       "      <th>VAR_4</th>\n",
       "      <th>VAR_5</th>\n",
       "      <th>VAR_6</th>\n",
       "      <th>VAR_7</th>\n",
       "      <th>...</th>\n",
       "      <th>VAR_54</th>\n",
       "      <th>VAR_57</th>\n",
       "      <th>VAR_59</th>\n",
       "      <th>VAR_65</th>\n",
       "      <th>VAR_66</th>\n",
       "      <th>VAR_67</th>\n",
       "      <th>VAR_72</th>\n",
       "      <th>VAR_74</th>\n",
       "      <th>VAR_76</th>\n",
       "      <th>VAR_77</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>201404</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.727634</td>\n",
       "      <td>-0.306095</td>\n",
       "      <td>-0.342735</td>\n",
       "      <td>-0.482881</td>\n",
       "      <td>0.673819</td>\n",
       "      <td>0.278301</td>\n",
       "      <td>-0.213637</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.809742</td>\n",
       "      <td>-0.064927</td>\n",
       "      <td>-0.943633</td>\n",
       "      <td>0.143174</td>\n",
       "      <td>-0.685373</td>\n",
       "      <td>0.142450</td>\n",
       "      <td>-0.014629</td>\n",
       "      <td>2.354360</td>\n",
       "      <td>-0.525657</td>\n",
       "      <td>-0.433522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>201407</td>\n",
       "      <td>0</td>\n",
       "      <td>0.627340</td>\n",
       "      <td>-0.306095</td>\n",
       "      <td>2.017805</td>\n",
       "      <td>0.336321</td>\n",
       "      <td>-0.566411</td>\n",
       "      <td>0.150841</td>\n",
       "      <td>0.541208</td>\n",
       "      <td>...</td>\n",
       "      <td>0.175248</td>\n",
       "      <td>1.107199</td>\n",
       "      <td>-0.932521</td>\n",
       "      <td>0.284367</td>\n",
       "      <td>0.800071</td>\n",
       "      <td>0.198180</td>\n",
       "      <td>0.107461</td>\n",
       "      <td>-0.270421</td>\n",
       "      <td>-0.499363</td>\n",
       "      <td>0.272032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>201405</td>\n",
       "      <td>0</td>\n",
       "      <td>1.368341</td>\n",
       "      <td>1.278230</td>\n",
       "      <td>2.017805</td>\n",
       "      <td>1.155524</td>\n",
       "      <td>-0.040989</td>\n",
       "      <td>0.056239</td>\n",
       "      <td>-0.798100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105216</td>\n",
       "      <td>-1.158910</td>\n",
       "      <td>0.066244</td>\n",
       "      <td>-0.246443</td>\n",
       "      <td>0.243029</td>\n",
       "      <td>0.209016</td>\n",
       "      <td>-0.201156</td>\n",
       "      <td>-0.270421</td>\n",
       "      <td>0.738035</td>\n",
       "      <td>1.160245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>201403</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.727634</td>\n",
       "      <td>-0.306095</td>\n",
       "      <td>-0.342735</td>\n",
       "      <td>-0.482881</td>\n",
       "      <td>-0.201561</td>\n",
       "      <td>-0.155736</td>\n",
       "      <td>-0.473936</td>\n",
       "      <td>...</td>\n",
       "      <td>0.796639</td>\n",
       "      <td>-0.611919</td>\n",
       "      <td>-0.224547</td>\n",
       "      <td>0.262330</td>\n",
       "      <td>-0.221172</td>\n",
       "      <td>-0.486060</td>\n",
       "      <td>-0.272375</td>\n",
       "      <td>-0.270421</td>\n",
       "      <td>-0.244562</td>\n",
       "      <td>-0.433522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>201405</td>\n",
       "      <td>0</td>\n",
       "      <td>0.563826</td>\n",
       "      <td>-0.306095</td>\n",
       "      <td>4.378344</td>\n",
       "      <td>0.336321</td>\n",
       "      <td>-0.234582</td>\n",
       "      <td>-0.201127</td>\n",
       "      <td>-0.493764</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.612744</td>\n",
       "      <td>-1.002627</td>\n",
       "      <td>-0.176851</td>\n",
       "      <td>-0.563487</td>\n",
       "      <td>-0.221172</td>\n",
       "      <td>0.209016</td>\n",
       "      <td>-0.509773</td>\n",
       "      <td>-0.270421</td>\n",
       "      <td>-0.226272</td>\n",
       "      <td>-0.433522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id   safra  y     VAR_1     VAR_2     VAR_3     VAR_4     VAR_5     VAR_6  \\\n",
       "0  1.0  201404  0 -0.727634 -0.306095 -0.342735 -0.482881  0.673819  0.278301   \n",
       "1  2.0  201407  0  0.627340 -0.306095  2.017805  0.336321 -0.566411  0.150841   \n",
       "2  3.0  201405  0  1.368341  1.278230  2.017805  1.155524 -0.040989  0.056239   \n",
       "3  5.0  201403  1 -0.727634 -0.306095 -0.342735 -0.482881 -0.201561 -0.155736   \n",
       "4  6.0  201405  0  0.563826 -0.306095  4.378344  0.336321 -0.234582 -0.201127   \n",
       "\n",
       "      VAR_7  ...    VAR_54    VAR_57    VAR_59    VAR_65    VAR_66    VAR_67  \\\n",
       "0 -0.213637  ... -0.809742 -0.064927 -0.943633  0.143174 -0.685373  0.142450   \n",
       "1  0.541208  ...  0.175248  1.107199 -0.932521  0.284367  0.800071  0.198180   \n",
       "2 -0.798100  ...  0.105216 -1.158910  0.066244 -0.246443  0.243029  0.209016   \n",
       "3 -0.473936  ...  0.796639 -0.611919 -0.224547  0.262330 -0.221172 -0.486060   \n",
       "4 -0.493764  ... -0.612744 -1.002627 -0.176851 -0.563487 -0.221172  0.209016   \n",
       "\n",
       "     VAR_72    VAR_74    VAR_76    VAR_77  \n",
       "0 -0.014629  2.354360 -0.525657 -0.433522  \n",
       "1  0.107461 -0.270421 -0.499363  0.272032  \n",
       "2 -0.201156 -0.270421  0.738035  1.160245  \n",
       "3 -0.272375 -0.270421 -0.244562 -0.433522  \n",
       "4 -0.509773 -0.270421 -0.226272 -0.433522  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_parquet(\"../data/SOT/base_tratada_treino_sem_outliers.parquet\")\n",
    "df_test = pd.read_parquet(\"../data/SOT/base_tratada_teste.parquet\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>safra</th>\n",
       "      <th>y</th>\n",
       "      <th>VAR_1</th>\n",
       "      <th>VAR_2</th>\n",
       "      <th>VAR_3</th>\n",
       "      <th>VAR_4</th>\n",
       "      <th>VAR_5</th>\n",
       "      <th>VAR_6</th>\n",
       "      <th>VAR_7</th>\n",
       "      <th>...</th>\n",
       "      <th>VAR_54</th>\n",
       "      <th>VAR_57</th>\n",
       "      <th>VAR_59</th>\n",
       "      <th>VAR_65</th>\n",
       "      <th>VAR_66</th>\n",
       "      <th>VAR_67</th>\n",
       "      <th>VAR_72</th>\n",
       "      <th>VAR_74</th>\n",
       "      <th>VAR_76</th>\n",
       "      <th>VAR_77</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>201411</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.727634</td>\n",
       "      <td>-0.306095</td>\n",
       "      <td>-0.342735</td>\n",
       "      <td>-0.482881</td>\n",
       "      <td>1.335696</td>\n",
       "      <td>-0.147789</td>\n",
       "      <td>-0.678210</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.481412</td>\n",
       "      <td>-0.064927</td>\n",
       "      <td>0.031056</td>\n",
       "      <td>-0.311434</td>\n",
       "      <td>-0.128332</td>\n",
       "      <td>0.145546</td>\n",
       "      <td>0.046416</td>\n",
       "      <td>-0.270421</td>\n",
       "      <td>-0.153449</td>\n",
       "      <td>-0.433522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>201411</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.727634</td>\n",
       "      <td>-0.306095</td>\n",
       "      <td>-0.342735</td>\n",
       "      <td>-0.482881</td>\n",
       "      <td>-0.157372</td>\n",
       "      <td>0.001526</td>\n",
       "      <td>-0.251333</td>\n",
       "      <td>...</td>\n",
       "      <td>1.554235</td>\n",
       "      <td>0.638348</td>\n",
       "      <td>0.031056</td>\n",
       "      <td>-0.311434</td>\n",
       "      <td>-0.499693</td>\n",
       "      <td>0.114585</td>\n",
       "      <td>2.528917</td>\n",
       "      <td>-0.270421</td>\n",
       "      <td>-0.153449</td>\n",
       "      <td>-0.433522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>201411</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.537090</td>\n",
       "      <td>-0.306095</td>\n",
       "      <td>-0.342735</td>\n",
       "      <td>-0.482881</td>\n",
       "      <td>-0.008453</td>\n",
       "      <td>0.351812</td>\n",
       "      <td>-0.251333</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.122948</td>\n",
       "      <td>-1.080769</td>\n",
       "      <td>0.636713</td>\n",
       "      <td>0.621421</td>\n",
       "      <td>0.057349</td>\n",
       "      <td>0.161027</td>\n",
       "      <td>-0.408031</td>\n",
       "      <td>0.604506</td>\n",
       "      <td>1.045672</td>\n",
       "      <td>0.200039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>201411</td>\n",
       "      <td>1</td>\n",
       "      <td>0.309768</td>\n",
       "      <td>-0.306095</td>\n",
       "      <td>-0.342735</td>\n",
       "      <td>0.336321</td>\n",
       "      <td>-0.451647</td>\n",
       "      <td>-0.128991</td>\n",
       "      <td>0.166783</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087416</td>\n",
       "      <td>-0.377494</td>\n",
       "      <td>-0.639244</td>\n",
       "      <td>-0.224089</td>\n",
       "      <td>-0.128332</td>\n",
       "      <td>0.145546</td>\n",
       "      <td>-0.723430</td>\n",
       "      <td>2.354360</td>\n",
       "      <td>-0.389530</td>\n",
       "      <td>-0.433522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47</td>\n",
       "      <td>201411</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.727634</td>\n",
       "      <td>-0.306095</td>\n",
       "      <td>-0.342735</td>\n",
       "      <td>-0.482881</td>\n",
       "      <td>-0.157372</td>\n",
       "      <td>-0.183704</td>\n",
       "      <td>-0.251333</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.744076</td>\n",
       "      <td>1.419765</td>\n",
       "      <td>0.031056</td>\n",
       "      <td>1.076810</td>\n",
       "      <td>-0.128332</td>\n",
       "      <td>0.145546</td>\n",
       "      <td>0.334685</td>\n",
       "      <td>-0.270421</td>\n",
       "      <td>-0.153449</td>\n",
       "      <td>-0.433522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   safra  y     VAR_1     VAR_2     VAR_3     VAR_4     VAR_5     VAR_6  \\\n",
       "0  13  201411  1 -0.727634 -0.306095 -0.342735 -0.482881  1.335696 -0.147789   \n",
       "1  20  201411  0 -0.727634 -0.306095 -0.342735 -0.482881 -0.157372  0.001526   \n",
       "2  32  201411  0 -0.537090 -0.306095 -0.342735 -0.482881 -0.008453  0.351812   \n",
       "3  36  201411  1  0.309768 -0.306095 -0.342735  0.336321 -0.451647 -0.128991   \n",
       "4  47  201411  0 -0.727634 -0.306095 -0.342735 -0.482881 -0.157372 -0.183704   \n",
       "\n",
       "      VAR_7  ...    VAR_54    VAR_57    VAR_59    VAR_65    VAR_66    VAR_67  \\\n",
       "0 -0.678210  ... -0.481412 -0.064927  0.031056 -0.311434 -0.128332  0.145546   \n",
       "1 -0.251333  ...  1.554235  0.638348  0.031056 -0.311434 -0.499693  0.114585   \n",
       "2 -0.251333  ... -0.122948 -1.080769  0.636713  0.621421  0.057349  0.161027   \n",
       "3  0.166783  ... -0.087416 -0.377494 -0.639244 -0.224089 -0.128332  0.145546   \n",
       "4 -0.251333  ... -0.744076  1.419765  0.031056  1.076810 -0.128332  0.145546   \n",
       "\n",
       "     VAR_72    VAR_74    VAR_76    VAR_77  \n",
       "0  0.046416 -0.270421 -0.153449 -0.433522  \n",
       "1  2.528917 -0.270421 -0.153449 -0.433522  \n",
       "2 -0.408031  0.604506  1.045672  0.200039  \n",
       "3 -0.723430  2.354360 -0.389530 -0.433522  \n",
       "4  0.334685 -0.270421 -0.153449 -0.433522  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(columns=[\"id\", \"safra\", \"y\"])\n",
    "y_train = df_train[\"y\"]\n",
    "X_test = df_test.drop(columns=[\"id\", \"safra\", \"y\"])\n",
    "y_test = df_test[\"y\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ParÃ¢metros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForest\n",
    "rf_params = {\n",
    "    'n_estimators': [50, 100],  \n",
    "    'max_depth': [None, 10],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'bootstrap': [True]\n",
    "}\n",
    "\n",
    "# Ridge \n",
    "ridge_params = {\n",
    "    'alpha': [0.1, 1],\n",
    "    'solver': ['auto', 'saga'], \n",
    "    'fit_intercept': [True]\n",
    "}\n",
    "\n",
    "# Logistic Regression \n",
    "logreg_params = {\n",
    "    'C': [0.1, 1],\n",
    "    'solver': ['lbfgs'],\n",
    "    'max_iter': [100] \n",
    "}\n",
    "\n",
    "# SVC\n",
    "svc_params = {\n",
    "    'C': [0.1, 1],\n",
    "    'kernel': ['linear'],\n",
    "    'gamma': ['scale']\n",
    "}\n",
    "\n",
    "# KNN\n",
    "knn_params = {\n",
    "    'n_neighbors': [3, 5],\n",
    "    'weights': ['uniform'],\n",
    "    'metric': ['euclidean']\n",
    "}\n",
    "\n",
    "# DecisionTree\n",
    "dt_params = {\n",
    "    'criterion': ['gini'],\n",
    "    'max_depth': [10], \n",
    "    'min_samples_split': [2], \n",
    "    'min_samples_leaf': [1], \n",
    "}\n",
    "\n",
    "# AdaBoost \n",
    "ada_params = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'learning_rate': [0.1],\n",
    "    'algorithm': ['SAMME']\n",
    "}\n",
    "\n",
    "# GradientBoosting \n",
    "gb_params = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'learning_rate': [0.1],\n",
    "    'max_depth': [3], \n",
    "    'min_samples_split': [2] \n",
    "}\n",
    "\n",
    "# ExtraTree\n",
    "et_params = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [10], \n",
    "    'min_samples_split': [2], \n",
    "    'min_samples_leaf': [1],\n",
    "    'bootstrap': [True] \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = {\n",
    "    'RandomForest': RandomForestClassifier(random_state=98),\n",
    "    'Ridge': RidgeClassifier(random_state=98),\n",
    "    'LogisticRegression': LogisticRegression(random_state=98),\n",
    "    'SVC': SVC(random_state=98),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'DecisionTree': DecisionTreeClassifier(random_state=98),\n",
    "    'AdaBoost': AdaBoostClassifier(random_state=98),\n",
    "    'GradientBoosting': GradientBoostingClassifier(random_state=98),\n",
    "    'ExtraTrees': ExtraTreesClassifier(random_state=98)\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'RandomForest': rf_params,\n",
    "    'Ridge': ridge_params,\n",
    "    'LogisticRegression': logreg_params,\n",
    "    'SVC': svc_params,\n",
    "    'KNN': knn_params,\n",
    "    'DecisionTree': dt_params,\n",
    "    'AdaBoost': ada_params,\n",
    "    'GradientBoosting': gb_params,\n",
    "    'ExtraTrees': et_params\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificadores sem balanceamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classifiers(clfs, params, X_train, y_train, X_test, y_test, tune_threshold=False):\n",
    "        rgsrs = {}\n",
    "        results = {}\n",
    "\n",
    "        for model in clfs.keys():\n",
    "                gs = GridSearchCV(clfs[model], params[model], cv=5, scoring='f1_weighted', n_jobs=-1)\n",
    "                gs.fit(X_train, y_train)\n",
    "                print(f'{model} best params: {gs.best_params_}')\n",
    "                if tune_threshold:\n",
    "                        gs = TunedThresholdClassifierCV(gs, cv=5, scoring='f1_weighted', n_jobs=-1)\n",
    "                        gs.fit(X_train, y_train)\n",
    "\n",
    "                rgsrs[model] = gs\n",
    "                results[model] = gs.best_score_\n",
    "                print(f'{model} best score: {gs.best_score_}')\n",
    "\n",
    "                y_pred = gs.predict(X_test)\n",
    "                print(f'{model} accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "                print(f'{model} confusion matrix: {confusion_matrix(y_test, y_pred)}')\n",
    "                print(f'{model} classification report:')\n",
    "                print(f'{classification_report(y_test, y_pred)}')\n",
    "                print('------------------------------------------------------------')\n",
    "        \n",
    "        return rgsrs, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest best score: 0.7895887860006082\n",
      "RandomForest best params: {'bootstrap': True, 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "RandomForest accuracy: 0.6757425742574258\n",
      "RandomForest confusion matrix: [[529  10]\n",
      " [252  17]]\n",
      "RandomForest classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.98      0.80       539\n",
      "           1       0.63      0.06      0.11       269\n",
      "\n",
      "    accuracy                           0.68       808\n",
      "   macro avg       0.65      0.52      0.46       808\n",
      "weighted avg       0.66      0.68      0.57       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "Ridge best score: 0.7839054318245146\n",
      "Ridge best params: {'alpha': 1, 'fit_intercept': True, 'solver': 'saga'}\n",
      "Ridge accuracy: 0.681930693069307\n",
      "Ridge confusion matrix: [[524  15]\n",
      " [242  27]]\n",
      "Ridge classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.97      0.80       539\n",
      "           1       0.64      0.10      0.17       269\n",
      "\n",
      "    accuracy                           0.68       808\n",
      "   macro avg       0.66      0.54      0.49       808\n",
      "weighted avg       0.67      0.68      0.59       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "LogisticRegression best score: 0.7859313642295364\n",
      "LogisticRegression best params: {'C': 0.1, 'max_iter': 100, 'solver': 'lbfgs'}\n",
      "LogisticRegression accuracy: 0.6868811881188119\n",
      "LogisticRegression confusion matrix: [[522  17]\n",
      " [236  33]]\n",
      "LogisticRegression classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.97      0.80       539\n",
      "           1       0.66      0.12      0.21       269\n",
      "\n",
      "    accuracy                           0.69       808\n",
      "   macro avg       0.67      0.55      0.51       808\n",
      "weighted avg       0.68      0.69      0.61       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "SVC best score: 0.7726591957168234\n",
      "SVC best params: {'C': 1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "SVC accuracy: 0.6707920792079208\n",
      "SVC confusion matrix: [[527  12]\n",
      " [254  15]]\n",
      "SVC classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.98      0.80       539\n",
      "           1       0.56      0.06      0.10       269\n",
      "\n",
      "    accuracy                           0.67       808\n",
      "   macro avg       0.62      0.52      0.45       808\n",
      "weighted avg       0.64      0.67      0.57       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "KNN best score: 0.6986869771834583\n",
      "KNN best params: {'metric': 'euclidean', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "KNN accuracy: 0.6658415841584159\n",
      "KNN confusion matrix: [[487  52]\n",
      " [218  51]]\n",
      "KNN classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.90      0.78       539\n",
      "           1       0.50      0.19      0.27       269\n",
      "\n",
      "    accuracy                           0.67       808\n",
      "   macro avg       0.59      0.55      0.53       808\n",
      "weighted avg       0.63      0.67      0.61       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "DecisionTree best score: 0.6860738410159029\n",
      "DecisionTree best params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "DecisionTree accuracy: 0.6522277227722773\n",
      "DecisionTree confusion matrix: [[495  44]\n",
      " [237  32]]\n",
      "DecisionTree classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.92      0.78       539\n",
      "           1       0.42      0.12      0.19       269\n",
      "\n",
      "    accuracy                           0.65       808\n",
      "   macro avg       0.55      0.52      0.48       808\n",
      "weighted avg       0.59      0.65      0.58       808\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Leonardo\\anaconda3\\envs\\credit-score-challenge\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost best score: 0.7614176858281264\n",
      "AdaBoost best params: {'algorithm': 'SAMME', 'learning_rate': 0.1, 'n_estimators': 100}\n",
      "AdaBoost accuracy: 0.6707920792079208\n",
      "AdaBoost confusion matrix: [[532   7]\n",
      " [259  10]]\n",
      "AdaBoost classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.99      0.80       539\n",
      "           1       0.59      0.04      0.07       269\n",
      "\n",
      "    accuracy                           0.67       808\n",
      "   macro avg       0.63      0.51      0.43       808\n",
      "weighted avg       0.64      0.67      0.56       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "GradientBoosting best score: 0.8025369499076607\n",
      "GradientBoosting best params: {'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "GradientBoosting accuracy: 0.6806930693069307\n",
      "GradientBoosting confusion matrix: [[526  13]\n",
      " [245  24]]\n",
      "GradientBoosting classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.98      0.80       539\n",
      "           1       0.65      0.09      0.16       269\n",
      "\n",
      "    accuracy                           0.68       808\n",
      "   macro avg       0.67      0.53      0.48       808\n",
      "weighted avg       0.67      0.68      0.59       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "ExtraTrees best score: 0.7802440452647408\n",
      "ExtraTrees best params: {'bootstrap': True, 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "ExtraTrees accuracy: 0.6745049504950495\n",
      "ExtraTrees confusion matrix: [[535   4]\n",
      " [259  10]]\n",
      "ExtraTrees classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.99      0.80       539\n",
      "           1       0.71      0.04      0.07       269\n",
      "\n",
      "    accuracy                           0.67       808\n",
      "   macro avg       0.69      0.51      0.44       808\n",
      "weighted avg       0.69      0.67      0.56       808\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Call the function\n",
    "rgsrs, results = evaluate_classifiers(clfs, params, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Com OverSampling por SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y\n",
       "0    6249\n",
       "1    6249\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote=SMOTE(sampling_strategy='minority') \n",
    "X_train_sampled, y_train_sampled = smote.fit_resample(X_train,y_train)\n",
    "y_train_sampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTrees best params: {'bootstrap': True, 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "ExtraTrees best score: 0.743578808684535\n",
      "ExtraTrees accuracy: 0.7066831683168316\n",
      "ExtraTrees confusion matrix: [[437 102]\n",
      " [135 134]]\n",
      "ExtraTrees classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.81      0.79       539\n",
      "           1       0.57      0.50      0.53       269\n",
      "\n",
      "    accuracy                           0.71       808\n",
      "   macro avg       0.67      0.65      0.66       808\n",
      "weighted avg       0.70      0.71      0.70       808\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "rgsrs, results = evaluate_classifiers(clfs, params, X_train_sampled, y_train_sampled, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tentando FEAT com ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y\n",
       "1    6489\n",
       "0    6249\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "# Applying ADASYN\n",
    "adasyn = ADASYN(sampling_strategy='minority')\n",
    "X_train_sampled, y_train_sampled = adasyn.fit_resample(X_train,y_train)\n",
    "y_train_sampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest best params: {'bootstrap': True, 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "RandomForest best score: 0.8524325643627524\n",
      "RandomForest accuracy: 0.7042079207920792\n",
      "RandomForest confusion matrix: [[481  58]\n",
      " [181  88]]\n",
      "RandomForest classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.89      0.80       539\n",
      "           1       0.60      0.33      0.42       269\n",
      "\n",
      "    accuracy                           0.70       808\n",
      "   macro avg       0.66      0.61      0.61       808\n",
      "weighted avg       0.69      0.70      0.68       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "Ridge best params: {'alpha': 1, 'fit_intercept': True, 'solver': 'saga'}\n",
      "Ridge best score: 0.6878953975843491\n",
      "Ridge accuracy: 0.698019801980198\n",
      "Ridge confusion matrix: [[420 119]\n",
      " [125 144]]\n",
      "Ridge classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.78      0.77       539\n",
      "           1       0.55      0.54      0.54       269\n",
      "\n",
      "    accuracy                           0.70       808\n",
      "   macro avg       0.66      0.66      0.66       808\n",
      "weighted avg       0.70      0.70      0.70       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "LogisticRegression best params: {'C': 0.1, 'max_iter': 100, 'solver': 'lbfgs'}\n",
      "LogisticRegression best score: 0.6878082590096957\n",
      "LogisticRegression accuracy: 0.7029702970297029\n",
      "LogisticRegression confusion matrix: [[423 116]\n",
      " [124 145]]\n",
      "LogisticRegression classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.78      0.78       539\n",
      "           1       0.56      0.54      0.55       269\n",
      "\n",
      "    accuracy                           0.70       808\n",
      "   macro avg       0.66      0.66      0.66       808\n",
      "weighted avg       0.70      0.70      0.70       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "SVC best params: {'C': 1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "SVC best score: 0.6846512884674041\n",
      "SVC accuracy: 0.6918316831683168\n",
      "SVC confusion matrix: [[402 137]\n",
      " [112 157]]\n",
      "SVC classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.75      0.76       539\n",
      "           1       0.53      0.58      0.56       269\n",
      "\n",
      "    accuracy                           0.69       808\n",
      "   macro avg       0.66      0.66      0.66       808\n",
      "weighted avg       0.70      0.69      0.70       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "KNN best params: {'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "KNN best score: 0.7432560714644465\n",
      "KNN accuracy: 0.6051980198019802\n",
      "KNN confusion matrix: [[344 195]\n",
      " [124 145]]\n",
      "KNN classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.64      0.68       539\n",
      "           1       0.43      0.54      0.48       269\n",
      "\n",
      "    accuracy                           0.61       808\n",
      "   macro avg       0.58      0.59      0.58       808\n",
      "weighted avg       0.63      0.61      0.61       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "DecisionTree best params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "DecisionTree best score: 0.7319075356265349\n",
      "DecisionTree accuracy: 0.6522277227722773\n",
      "DecisionTree confusion matrix: [[446  93]\n",
      " [188  81]]\n",
      "DecisionTree classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.83      0.76       539\n",
      "           1       0.47      0.30      0.37       269\n",
      "\n",
      "    accuracy                           0.65       808\n",
      "   macro avg       0.58      0.56      0.56       808\n",
      "weighted avg       0.62      0.65      0.63       808\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Leonardo\\anaconda3\\envs\\credit-score-challenge\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost best params: {'algorithm': 'SAMME', 'learning_rate': 0.1, 'n_estimators': 100}\n",
      "AdaBoost best score: 0.7137288506431813\n",
      "AdaBoost accuracy: 0.6918316831683168\n",
      "AdaBoost confusion matrix: [[441  98]\n",
      " [151 118]]\n",
      "AdaBoost classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.82      0.78       539\n",
      "           1       0.55      0.44      0.49       269\n",
      "\n",
      "    accuracy                           0.69       808\n",
      "   macro avg       0.65      0.63      0.63       808\n",
      "weighted avg       0.68      0.69      0.68       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "GradientBoosting best params: {'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "GradientBoosting best score: 0.7975652544758873\n",
      "GradientBoosting accuracy: 0.6881188118811881\n",
      "GradientBoosting confusion matrix: [[468  71]\n",
      " [181  88]]\n",
      "GradientBoosting classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.87      0.79       539\n",
      "           1       0.55      0.33      0.41       269\n",
      "\n",
      "    accuracy                           0.69       808\n",
      "   macro avg       0.64      0.60      0.60       808\n",
      "weighted avg       0.67      0.69      0.66       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "ExtraTrees best params: {'bootstrap': True, 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "ExtraTrees best score: 0.7246935619883987\n",
      "ExtraTrees accuracy: 0.6881188118811881\n",
      "ExtraTrees confusion matrix: [[393 146]\n",
      " [106 163]]\n",
      "ExtraTrees classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.73      0.76       539\n",
      "           1       0.53      0.61      0.56       269\n",
      "\n",
      "    accuracy                           0.69       808\n",
      "   macro avg       0.66      0.67      0.66       808\n",
      "weighted avg       0.70      0.69      0.69       808\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "rgsrs, results = evaluate_classifiers(clfs, params, X_train_sampled, y_train_sampled, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Borderline SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y\n",
       "0    6249\n",
       "1    6249\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "\n",
    "# Applying ADASYN\n",
    "blsmote = BorderlineSMOTE(sampling_strategy='minority', kind='borderline-1')\n",
    "X_train_sampled, y_train_sampled = blsmote.fit_resample(X_train,y_train)\n",
    "y_train_sampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest best score: 0.9313598073338671\n",
      "RandomForest best params: {'bootstrap': True, 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "RandomForest accuracy: 0.6967821782178217\n",
      "RandomForest confusion matrix: [[470  69]\n",
      " [176  93]]\n",
      "RandomForest classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.87      0.79       539\n",
      "           1       0.57      0.35      0.43       269\n",
      "\n",
      "    accuracy                           0.70       808\n",
      "   macro avg       0.65      0.61      0.61       808\n",
      "weighted avg       0.68      0.70      0.67       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "Ridge best score: 0.763205688160128\n",
      "Ridge best params: {'alpha': 0.1, 'fit_intercept': True, 'solver': 'auto'}\n",
      "Ridge accuracy: 0.6955445544554455\n",
      "Ridge confusion matrix: [[411 128]\n",
      " [118 151]]\n",
      "Ridge classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.76      0.77       539\n",
      "           1       0.54      0.56      0.55       269\n",
      "\n",
      "    accuracy                           0.70       808\n",
      "   macro avg       0.66      0.66      0.66       808\n",
      "weighted avg       0.70      0.70      0.70       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "LogisticRegression best score: 0.7634616408134507\n",
      "LogisticRegression best params: {'C': 0.1, 'max_iter': 100, 'solver': 'lbfgs'}\n",
      "LogisticRegression accuracy: 0.7017326732673267\n",
      "LogisticRegression confusion matrix: [[417 122]\n",
      " [119 150]]\n",
      "LogisticRegression classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.77      0.78       539\n",
      "           1       0.55      0.56      0.55       269\n",
      "\n",
      "    accuracy                           0.70       808\n",
      "   macro avg       0.66      0.67      0.67       808\n",
      "weighted avg       0.70      0.70      0.70       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "SVC best score: 0.7622360946164932\n",
      "SVC best params: {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "SVC accuracy: 0.6943069306930693\n",
      "SVC confusion matrix: [[402 137]\n",
      " [110 159]]\n",
      "SVC classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.75      0.76       539\n",
      "           1       0.54      0.59      0.56       269\n",
      "\n",
      "    accuracy                           0.69       808\n",
      "   macro avg       0.66      0.67      0.66       808\n",
      "weighted avg       0.70      0.69      0.70       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "KNN best score: 0.8460953090664531\n",
      "KNN best params: {'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "KNN accuracy: 0.6064356435643564\n",
      "KNN confusion matrix: [[360 179]\n",
      " [139 130]]\n",
      "KNN classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.67      0.69       539\n",
      "           1       0.42      0.48      0.45       269\n",
      "\n",
      "    accuracy                           0.61       808\n",
      "   macro avg       0.57      0.58      0.57       808\n",
      "weighted avg       0.62      0.61      0.61       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "DecisionTree best score: 0.8047240205732585\n",
      "DecisionTree best params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "DecisionTree accuracy: 0.6522277227722773\n",
      "DecisionTree confusion matrix: [[414 125]\n",
      " [156 113]]\n",
      "DecisionTree classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.75       539\n",
      "           1       0.47      0.42      0.45       269\n",
      "\n",
      "    accuracy                           0.65       808\n",
      "   macro avg       0.60      0.59      0.60       808\n",
      "weighted avg       0.64      0.65      0.65       808\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Leonardo\\anaconda3\\envs\\credit-score-challenge\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost best score: 0.7735108667542034\n",
      "AdaBoost best params: {'algorithm': 'SAMME', 'learning_rate': 0.1, 'n_estimators': 100}\n",
      "AdaBoost accuracy: 0.6905940594059405\n",
      "AdaBoost confusion matrix: [[422 117]\n",
      " [133 136]]\n",
      "AdaBoost classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.78      0.77       539\n",
      "           1       0.54      0.51      0.52       269\n",
      "\n",
      "    accuracy                           0.69       808\n",
      "   macro avg       0.65      0.64      0.65       808\n",
      "weighted avg       0.69      0.69      0.69       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "GradientBoosting best score: 0.8896749080800641\n",
      "GradientBoosting best params: {'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "GradientBoosting accuracy: 0.6967821782178217\n",
      "GradientBoosting confusion matrix: [[471  68]\n",
      " [177  92]]\n",
      "GradientBoosting classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.87      0.79       539\n",
      "           1       0.57      0.34      0.43       269\n",
      "\n",
      "    accuracy                           0.70       808\n",
      "   macro avg       0.65      0.61      0.61       808\n",
      "weighted avg       0.68      0.70      0.67       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "ExtraTrees best score: 0.8098529718622898\n",
      "ExtraTrees best params: {'bootstrap': True, 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "ExtraTrees accuracy: 0.6967821782178217\n",
      "ExtraTrees confusion matrix: [[401 138]\n",
      " [107 162]]\n",
      "ExtraTrees classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.74      0.77       539\n",
      "           1       0.54      0.60      0.57       269\n",
      "\n",
      "    accuracy                           0.70       808\n",
      "   macro avg       0.66      0.67      0.67       808\n",
      "weighted avg       0.71      0.70      0.70       808\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "rgsrs, results = evaluate_classifiers(clfs, params, X_train_sampled, y_train_sampled, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smote-ENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y\n",
       "1    5051\n",
       "0    2343\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.combine import SMOTEENN\n",
    "smote_enn = SMOTEENN()\n",
    "X_train_sampled, y_train_sampled = smote_enn.fit_resample(X_train,y_train)\n",
    "y_train_sampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest best score: 0.972185841472737\n",
      "RandomForest best params: {'bootstrap': True, 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "RandomForest accuracy: 0.6695544554455446\n",
      "RandomForest confusion matrix: [[382 157]\n",
      " [110 159]]\n",
      "RandomForest classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.71      0.74       539\n",
      "           1       0.50      0.59      0.54       269\n",
      "\n",
      "    accuracy                           0.67       808\n",
      "   macro avg       0.64      0.65      0.64       808\n",
      "weighted avg       0.69      0.67      0.68       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "Ridge best score: 0.9057700540973199\n",
      "Ridge best params: {'alpha': 1, 'fit_intercept': True, 'solver': 'saga'}\n",
      "Ridge accuracy: 0.6349009900990099\n",
      "Ridge confusion matrix: [[302 237]\n",
      " [ 58 211]]\n",
      "Ridge classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.56      0.67       539\n",
      "           1       0.47      0.78      0.59       269\n",
      "\n",
      "    accuracy                           0.63       808\n",
      "   macro avg       0.65      0.67      0.63       808\n",
      "weighted avg       0.72      0.63      0.64       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "LogisticRegression best score: 0.9154437988992681\n",
      "LogisticRegression best params: {'C': 1, 'max_iter': 100, 'solver': 'lbfgs'}\n",
      "LogisticRegression accuracy: 0.6485148514851485\n",
      "LogisticRegression confusion matrix: [[321 218]\n",
      " [ 66 203]]\n",
      "LogisticRegression classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.60      0.69       539\n",
      "           1       0.48      0.75      0.59       269\n",
      "\n",
      "    accuracy                           0.65       808\n",
      "   macro avg       0.66      0.68      0.64       808\n",
      "weighted avg       0.71      0.65      0.66       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "SVC best score: 0.9137036998531821\n",
      "SVC best params: {'C': 1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "SVC accuracy: 0.6423267326732673\n",
      "SVC confusion matrix: [[313 226]\n",
      " [ 63 206]]\n",
      "SVC classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.58      0.68       539\n",
      "           1       0.48      0.77      0.59       269\n",
      "\n",
      "    accuracy                           0.64       808\n",
      "   macro avg       0.65      0.67      0.64       808\n",
      "weighted avg       0.71      0.64      0.65       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "KNN best score: 0.9659040095834154\n",
      "KNN best params: {'metric': 'euclidean', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "KNN accuracy: 0.556930693069307\n",
      "KNN confusion matrix: [[247 292]\n",
      " [ 66 203]]\n",
      "KNN classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.46      0.58       539\n",
      "           1       0.41      0.75      0.53       269\n",
      "\n",
      "    accuracy                           0.56       808\n",
      "   macro avg       0.60      0.61      0.56       808\n",
      "weighted avg       0.66      0.56      0.56       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "DecisionTree best score: 0.8417266035294123\n",
      "DecisionTree best params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "DecisionTree accuracy: 0.5977722772277227\n",
      "DecisionTree confusion matrix: [[382 157]\n",
      " [168 101]]\n",
      "DecisionTree classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.71      0.70       539\n",
      "           1       0.39      0.38      0.38       269\n",
      "\n",
      "    accuracy                           0.60       808\n",
      "   macro avg       0.54      0.54      0.54       808\n",
      "weighted avg       0.59      0.60      0.60       808\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Leonardo\\anaconda3\\envs\\credit-score-challenge\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost best score: 0.9107064693168357\n",
      "AdaBoost best params: {'algorithm': 'SAMME', 'learning_rate': 0.1, 'n_estimators': 100}\n",
      "AdaBoost accuracy: 0.594059405940594\n",
      "AdaBoost confusion matrix: [[276 263]\n",
      " [ 65 204]]\n",
      "AdaBoost classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.51      0.63       539\n",
      "           1       0.44      0.76      0.55       269\n",
      "\n",
      "    accuracy                           0.59       808\n",
      "   macro avg       0.62      0.64      0.59       808\n",
      "weighted avg       0.69      0.59      0.60       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "GradientBoosting best score: 0.9573007638476756\n",
      "GradientBoosting best params: {'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "GradientBoosting accuracy: 0.6584158415841584\n",
      "GradientBoosting confusion matrix: [[341 198]\n",
      " [ 78 191]]\n",
      "GradientBoosting classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.63      0.71       539\n",
      "           1       0.49      0.71      0.58       269\n",
      "\n",
      "    accuracy                           0.66       808\n",
      "   macro avg       0.65      0.67      0.65       808\n",
      "weighted avg       0.71      0.66      0.67       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "ExtraTrees best score: 0.9329726459639209\n",
      "ExtraTrees best params: {'bootstrap': True, 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "ExtraTrees accuracy: 0.6089108910891089\n",
      "ExtraTrees confusion matrix: [[285 254]\n",
      " [ 62 207]]\n",
      "ExtraTrees classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.53      0.64       539\n",
      "           1       0.45      0.77      0.57       269\n",
      "\n",
      "    accuracy                           0.61       808\n",
      "   macro avg       0.64      0.65      0.61       808\n",
      "weighted avg       0.70      0.61      0.62       808\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "rgsrs, results = evaluate_classifiers(clfs, params, X_train_sampled, y_train_sampled, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ParÃ¢metros com Class Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = {\n",
    "    'RandomForest': RandomForestClassifier(class_weight='balanced',random_state=98),\n",
    "    'Ridge': RidgeClassifier(class_weight='balanced', random_state=98),\n",
    "    'LogisticRegression': LogisticRegression(class_weight='balanced', random_state=98),\n",
    "    'SVC': SVC(class_weight='balanced', random_state=98),\n",
    "    'DecisionTree': DecisionTreeClassifier(class_weight=\"balanced\",random_state=98),\n",
    "    # 'AdaBoost': AdaBoostClassifier(random_state=98),\n",
    "    # 'GradientBoosting': GradientBoostingClassifier(random_state=98),\n",
    "    'ExtraTrees': ExtraTreesClassifier(class_weight='balanced', random_state=98)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'RandomForest': rf_params,\n",
    "    'Ridge': ridge_params,\n",
    "    'LogisticRegression': logreg_params,\n",
    "    'SVC': svc_params,\n",
    "    'DecisionTree': dt_params,\n",
    "    # 'AdaBoost': ada_params,\n",
    "    # 'GradientBoosting': gb_params,\n",
    "    'ExtraTrees': et_params\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest best score: 0.791079008614386\n",
      "RandomForest best params: {'bootstrap': True, 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "RandomForest accuracy: 0.7128712871287128\n",
      "RandomForest confusion matrix: [[504  35]\n",
      " [197  72]]\n",
      "RandomForest classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.94      0.81       539\n",
      "           1       0.67      0.27      0.38       269\n",
      "\n",
      "    accuracy                           0.71       808\n",
      "   macro avg       0.70      0.60      0.60       808\n",
      "weighted avg       0.70      0.71      0.67       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "Ridge best score: 0.7858027219857531\n",
      "Ridge best params: {'alpha': 1, 'fit_intercept': True, 'solver': 'auto'}\n",
      "Ridge accuracy: 0.7215346534653465\n",
      "Ridge confusion matrix: [[460  79]\n",
      " [146 123]]\n",
      "Ridge classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.85      0.80       539\n",
      "           1       0.61      0.46      0.52       269\n",
      "\n",
      "    accuracy                           0.72       808\n",
      "   macro avg       0.68      0.66      0.66       808\n",
      "weighted avg       0.71      0.72      0.71       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "LogisticRegression best score: 0.7860844583784397\n",
      "LogisticRegression best params: {'C': 0.1, 'max_iter': 100, 'solver': 'lbfgs'}\n",
      "LogisticRegression accuracy: 0.7153465346534653\n",
      "LogisticRegression confusion matrix: [[452  87]\n",
      " [143 126]]\n",
      "LogisticRegression classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.84      0.80       539\n",
      "           1       0.59      0.47      0.52       269\n",
      "\n",
      "    accuracy                           0.72       808\n",
      "   macro avg       0.68      0.65      0.66       808\n",
      "weighted avg       0.70      0.72      0.71       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "SVC best score: 0.7841610430672349\n",
      "SVC best params: {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "SVC accuracy: 0.7091584158415841\n",
      "SVC confusion matrix: [[448  91]\n",
      " [144 125]]\n",
      "SVC classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.83      0.79       539\n",
      "           1       0.58      0.46      0.52       269\n",
      "\n",
      "    accuracy                           0.71       808\n",
      "   macro avg       0.67      0.65      0.65       808\n",
      "weighted avg       0.70      0.71      0.70       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "DecisionTree best score: 0.692166282540909\n",
      "DecisionTree best params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "DecisionTree accuracy: 0.6534653465346535\n",
      "DecisionTree confusion matrix: [[398 141]\n",
      " [139 130]]\n",
      "DecisionTree classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.74      0.74       539\n",
      "           1       0.48      0.48      0.48       269\n",
      "\n",
      "    accuracy                           0.65       808\n",
      "   macro avg       0.61      0.61      0.61       808\n",
      "weighted avg       0.65      0.65      0.65       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "ExtraTrees best score: 0.777056671833036\n",
      "ExtraTrees best params: {'bootstrap': True, 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "ExtraTrees accuracy: 0.724009900990099\n",
      "ExtraTrees confusion matrix: [[474  65]\n",
      " [158 111]]\n",
      "ExtraTrees classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.88      0.81       539\n",
      "           1       0.63      0.41      0.50       269\n",
      "\n",
      "    accuracy                           0.72       808\n",
      "   macro avg       0.69      0.65      0.65       808\n",
      "weighted avg       0.71      0.72      0.71       808\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "rgsrs, results = evaluate_classifiers(clfs, params, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Weight + SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y\n",
       "0    6249\n",
       "1    3749\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smote = SMOTE(sampling_strategy=0.6, random_state=98) \n",
    "X_train_sampled, y_train_sampled = smote.fit_resample(X_train,y_train)\n",
    "y_train_sampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest best score: 0.8657714388132419\n",
      "RandomForest best params: {'bootstrap': True, 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "RandomForest accuracy: 0.6868811881188119\n",
      "RandomForest confusion matrix: [[519  20]\n",
      " [233  36]]\n",
      "RandomForest classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.96      0.80       539\n",
      "           1       0.64      0.13      0.22       269\n",
      "\n",
      "    accuracy                           0.69       808\n",
      "   macro avg       0.67      0.55      0.51       808\n",
      "weighted avg       0.67      0.69      0.61       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "Ridge best score: 0.7933723144907951\n",
      "Ridge best params: {'alpha': 1, 'fit_intercept': True, 'solver': 'auto'}\n",
      "Ridge accuracy: 0.7103960396039604\n",
      "Ridge confusion matrix: [[452  87]\n",
      " [147 122]]\n",
      "Ridge classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.84      0.79       539\n",
      "           1       0.58      0.45      0.51       269\n",
      "\n",
      "    accuracy                           0.71       808\n",
      "   macro avg       0.67      0.65      0.65       808\n",
      "weighted avg       0.70      0.71      0.70       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "LogisticRegression best score: 0.7936612470271508\n",
      "LogisticRegression best params: {'C': 1, 'max_iter': 100, 'solver': 'lbfgs'}\n",
      "LogisticRegression accuracy: 0.7091584158415841\n",
      "LogisticRegression confusion matrix: [[449  90]\n",
      " [145 124]]\n",
      "LogisticRegression classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.83      0.79       539\n",
      "           1       0.58      0.46      0.51       269\n",
      "\n",
      "    accuracy                           0.71       808\n",
      "   macro avg       0.67      0.65      0.65       808\n",
      "weighted avg       0.70      0.71      0.70       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "SVC best score: 0.792597651269441\n",
      "SVC best params: {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "SVC accuracy: 0.719059405940594\n",
      "SVC confusion matrix: [[447  92]\n",
      " [135 134]]\n",
      "SVC classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.83      0.80       539\n",
      "           1       0.59      0.50      0.54       269\n",
      "\n",
      "    accuracy                           0.72       808\n",
      "   macro avg       0.68      0.66      0.67       808\n",
      "weighted avg       0.71      0.72      0.71       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "DecisionTree best score: 0.7423338483388331\n",
      "DecisionTree best params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "DecisionTree accuracy: 0.6745049504950495\n",
      "DecisionTree confusion matrix: [[397 142]\n",
      " [121 148]]\n",
      "DecisionTree classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.74      0.75       539\n",
      "           1       0.51      0.55      0.53       269\n",
      "\n",
      "    accuracy                           0.67       808\n",
      "   macro avg       0.64      0.64      0.64       808\n",
      "weighted avg       0.68      0.67      0.68       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "ExtraTrees best score: 0.8046064195056696\n",
      "ExtraTrees best params: {'bootstrap': True, 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "ExtraTrees accuracy: 0.7202970297029703\n",
      "ExtraTrees confusion matrix: [[456  83]\n",
      " [143 126]]\n",
      "ExtraTrees classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.85      0.80       539\n",
      "           1       0.60      0.47      0.53       269\n",
      "\n",
      "    accuracy                           0.72       808\n",
      "   macro avg       0.68      0.66      0.66       808\n",
      "weighted avg       0.71      0.72      0.71       808\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "rgsrs, results = evaluate_classifiers(clfs, params, X_train_sampled, y_train_sampled, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAW Data + PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from lib_aux import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>safra</th>\n",
       "      <th>y</th>\n",
       "      <th>VAR_1</th>\n",
       "      <th>VAR_2</th>\n",
       "      <th>VAR_3</th>\n",
       "      <th>VAR_4</th>\n",
       "      <th>VAR_5</th>\n",
       "      <th>VAR_6</th>\n",
       "      <th>VAR_7</th>\n",
       "      <th>...</th>\n",
       "      <th>VAR_69</th>\n",
       "      <th>VAR_70</th>\n",
       "      <th>VAR_71</th>\n",
       "      <th>VAR_72</th>\n",
       "      <th>VAR_73</th>\n",
       "      <th>VAR_74</th>\n",
       "      <th>VAR_75</th>\n",
       "      <th>VAR_76</th>\n",
       "      <th>VAR_77</th>\n",
       "      <th>VAR_78</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>201404</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>124.54</td>\n",
       "      <td>3277.0</td>\n",
       "      <td>51.98</td>\n",
       "      <td>...</td>\n",
       "      <td>156.38</td>\n",
       "      <td>7.52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>477.84</td>\n",
       "      <td>173.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>201407</td>\n",
       "      <td>0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>47.92</td>\n",
       "      <td>2443.0</td>\n",
       "      <td>84.72</td>\n",
       "      <td>...</td>\n",
       "      <td>707.84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>187.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>184.69</td>\n",
       "      <td>54.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>201405</td>\n",
       "      <td>0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>80.38</td>\n",
       "      <td>1824.0</td>\n",
       "      <td>26.63</td>\n",
       "      <td>...</td>\n",
       "      <td>471.86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>732.00</td>\n",
       "      <td>121.98</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>201412</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.58</td>\n",
       "      <td>3796.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>119.96</td>\n",
       "      <td>23.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>417.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>201403</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.46</td>\n",
       "      <td>437.0</td>\n",
       "      <td>40.69</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>914.45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   safra  y  VAR_1  VAR_2  VAR_3  VAR_4   VAR_5   VAR_6  VAR_7  ...  \\\n",
       "0   1  201404  0    0.0    0.0    0.0    0.0  124.54  3277.0  51.98  ...   \n",
       "1   2  201407  0   64.0    0.0    2.0    1.0   47.92  2443.0  84.72  ...   \n",
       "2   3  201405  0   99.0    2.0    2.0    2.0   80.38  1824.0  26.63  ...   \n",
       "3   4  201412  0    0.0    0.0    0.0    0.0   10.58  3796.0    NaN  ...   \n",
       "4   5  201403  1    0.0    0.0    0.0    0.0   70.46   437.0  40.69  ...   \n",
       "\n",
       "   VAR_69  VAR_70  VAR_71  VAR_72  VAR_73  VAR_74  VAR_75  VAR_76  VAR_77  \\\n",
       "0  156.38    7.52     0.0   151.0     0.0     3.0  477.84  173.06    0.00   \n",
       "1  707.84     NaN     NaN   187.0     NaN     NaN     NaN  184.69   54.00   \n",
       "2  471.86     NaN     NaN    96.0     NaN     NaN     NaN  732.00  121.98   \n",
       "3  119.96   23.00     0.0   417.0     0.0     0.0     NaN     NaN    0.00   \n",
       "4     NaN     NaN     0.0    75.0     0.0     0.0  914.45     NaN     NaN   \n",
       "\n",
       "   VAR_78  \n",
       "0     3.0  \n",
       "1     NaN  \n",
       "2     NaN  \n",
       "3     0.0  \n",
       "4     0.0  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/SOR/base_modelo.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_test shape: (808, 81)\n",
      "df_val shape: (786, 81)\n",
      "df shape: (9144, 81)\n"
     ]
    }
   ],
   "source": [
    "# Apply filtering\n",
    "df_test = df[df[\"safra\"] == 201411].copy(deep=True)\n",
    "df_val = df[df[\"safra\"] == 201412].copy(deep=True)\n",
    "df = df[df[\"safra\"] < 201411].reset_index(drop=True)\n",
    "\n",
    "# Print final results\n",
    "print(\"df_test shape:\", df_test.shape)\n",
    "print(\"df_val shape:\", df_val.shape)\n",
    "print(\"df shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(columns=['id', 'safra'], inplace=True)\n",
    "df_test.drop(columns=['id', 'safra'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_count = (df_train.isna().sum() / len(df_train) * 100).sort_values(ascending=False)\n",
    "na_count_critical = na_count[na_count >= 60]\n",
    "df_train.drop(columns = na_count_critical.index, inplace=True)\n",
    "df_test.drop(columns=na_count_critical.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = fill_na_by(df_train, method = \"median\") ### Preenche os NA's\n",
    "df_test = fill_na_by(df_test, method = \"median\") ### Preenche os NA's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(columns=[\"y\"])\n",
    "y_train = df_train[\"y\"]\n",
    "X_test = df_test.drop(columns=[\"y\"])\n",
    "y_test = df_test[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),          # Step 1: StandardScaler for normalization\n",
    "    ('pca', PCA(n_components=0.95)),       # Step 2: PCA to retain 95% variance\n",
    "    ('clf', LogisticRegression())         # Step 3: Logistic Regression classifier\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForest\n",
    "rf_params = {\n",
    "    'clf__n_estimators': [50, 100],  \n",
    "    'clf__max_depth': [None, 10],\n",
    "    'clf__min_samples_split': [2, 5],\n",
    "    'clf__min_samples_leaf': [1, 2],\n",
    "    'clf__bootstrap': [True]\n",
    "}\n",
    "\n",
    "# Ridge \n",
    "ridge_params = {\n",
    "    'clf__alpha': [0.1, 1],\n",
    "    'clf__solver': ['auto', 'saga'], \n",
    "    'clf__fit_intercept': [True]\n",
    "}\n",
    "\n",
    "# Logistic Regression \n",
    "logreg_params = {\n",
    "    'clf__C': [0.1, 1],\n",
    "    'clf__solver': ['lbfgs'],\n",
    "    'clf__max_iter': [100] \n",
    "}\n",
    "\n",
    "# SVC\n",
    "svc_params = {\n",
    "    'clf__C': [0.1, 1],\n",
    "    'clf__kernel': ['linear'],\n",
    "    'clf__gamma': ['scale']\n",
    "}\n",
    "\n",
    "# KNN\n",
    "knn_params = {\n",
    "    'clf__n_neighbors': [3, 5],\n",
    "    'clf__weights': ['uniform'],\n",
    "    'clf__metric': ['euclidean']\n",
    "}\n",
    "\n",
    "# DecisionTree\n",
    "dt_params = {\n",
    "    'clf__criterion': ['gini'],\n",
    "    'clf__max_depth': [10], \n",
    "    'clf__min_samples_split': [2], \n",
    "    'clf__min_samples_leaf': [1], \n",
    "}\n",
    "\n",
    "# AdaBoost \n",
    "ada_params = {\n",
    "    'clf__n_estimators': [50, 100],\n",
    "    'clf__learning_rate': [0.1],\n",
    "    'clf__algorithm': ['SAMME']\n",
    "}\n",
    "\n",
    "# GradientBoosting \n",
    "gb_params = {\n",
    "    'clf__n_estimators': [50, 100],\n",
    "    'clf__learning_rate': [0.1],\n",
    "    'clf__max_depth': [3], \n",
    "    'clf__min_samples_split': [2] \n",
    "}\n",
    "\n",
    "# ExtraTree\n",
    "et_params = {\n",
    "    'clf__n_estimators': [50, 100],\n",
    "    'clf__max_depth': [10], \n",
    "    'clf__min_samples_split': [2], \n",
    "    'clf__min_samples_leaf': [1],\n",
    "    'clf__bootstrap': [True] \n",
    "}\n",
    "\n",
    "params = {\n",
    "    'RandomForest': rf_params,\n",
    "    'Ridge': ridge_params,\n",
    "    'LogisticRegression': logreg_params,\n",
    "    'SVC': svc_params,\n",
    "    'KNN': knn_params,\n",
    "    'DecisionTree': dt_params,\n",
    "    'AdaBoost': ada_params,\n",
    "    'GradientBoosting': gb_params,\n",
    "    'ExtraTrees': et_params\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest best score: 0.7661389890232708\n",
      "RandomForest best params: {'clf__bootstrap': True, 'clf__max_depth': 10, 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 5, 'clf__n_estimators': 100}\n",
      "RandomForest accuracy: 0.7116336633663366\n",
      "RandomForest confusion matrix: [[487  52]\n",
      " [181  88]]\n",
      "RandomForest classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.90      0.81       539\n",
      "           1       0.63      0.33      0.43       269\n",
      "\n",
      "    accuracy                           0.71       808\n",
      "   macro avg       0.68      0.62      0.62       808\n",
      "weighted avg       0.70      0.71      0.68       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "Ridge best score: 0.7750761796494046\n",
      "Ridge best params: {'clf__alpha': 1, 'clf__fit_intercept': True, 'clf__solver': 'saga'}\n",
      "Ridge accuracy: 0.7091584158415841\n",
      "Ridge confusion matrix: [[436 103]\n",
      " [132 137]]\n",
      "Ridge classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.81      0.79       539\n",
      "           1       0.57      0.51      0.54       269\n",
      "\n",
      "    accuracy                           0.71       808\n",
      "   macro avg       0.67      0.66      0.66       808\n",
      "weighted avg       0.70      0.71      0.70       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "LogisticRegression best score: 0.7758526290234855\n",
      "LogisticRegression best params: {'clf__C': 0.1, 'clf__max_iter': 100, 'clf__solver': 'lbfgs'}\n",
      "LogisticRegression accuracy: 0.7116336633663366\n",
      "LogisticRegression confusion matrix: [[434 105]\n",
      " [128 141]]\n",
      "LogisticRegression classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.81      0.79       539\n",
      "           1       0.57      0.52      0.55       269\n",
      "\n",
      "    accuracy                           0.71       808\n",
      "   macro avg       0.67      0.66      0.67       808\n",
      "weighted avg       0.71      0.71      0.71       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "SVC best score: 0.7731281718822827\n",
      "SVC best params: {'clf__C': 0.1, 'clf__gamma': 'scale', 'clf__kernel': 'linear'}\n",
      "SVC accuracy: 0.7066831683168316\n",
      "SVC confusion matrix: [[431 108]\n",
      " [129 140]]\n",
      "SVC classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.80      0.78       539\n",
      "           1       0.56      0.52      0.54       269\n",
      "\n",
      "    accuracy                           0.71       808\n",
      "   macro avg       0.67      0.66      0.66       808\n",
      "weighted avg       0.70      0.71      0.70       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "DecisionTree best score: 0.65475770955633\n",
      "DecisionTree best params: {'clf__criterion': 'gini', 'clf__max_depth': 10, 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 2}\n",
      "DecisionTree accuracy: 0.6349009900990099\n",
      "DecisionTree confusion matrix: [[381 158]\n",
      " [137 132]]\n",
      "DecisionTree classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.71      0.72       539\n",
      "           1       0.46      0.49      0.47       269\n",
      "\n",
      "    accuracy                           0.63       808\n",
      "   macro avg       0.60      0.60      0.60       808\n",
      "weighted avg       0.64      0.63      0.64       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "ExtraTrees best score: 0.7477639700064269\n",
      "ExtraTrees best params: {'clf__bootstrap': True, 'clf__max_depth': 10, 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 2, 'clf__n_estimators': 100}\n",
      "ExtraTrees accuracy: 0.7091584158415841\n",
      "ExtraTrees confusion matrix: [[448  91]\n",
      " [144 125]]\n",
      "ExtraTrees classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.83      0.79       539\n",
      "           1       0.58      0.46      0.52       269\n",
      "\n",
      "    accuracy                           0.71       808\n",
      "   macro avg       0.67      0.65      0.65       808\n",
      "weighted avg       0.70      0.71      0.70       808\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "rgsrs = {}\n",
    "results = {}\n",
    "\n",
    "for model, clf in clfs.items():\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),          # Step 1: StandardScaler for normalization\n",
    "        ('pca', PCA(n_components=0.95)),       # Step 2: PCA to retain 95% variance\n",
    "        ('clf', clf)                           # Step 3: Classifier (this will change)\n",
    "    ])\n",
    "    \n",
    "    # Step 4b: Set up GridSearchCV for each classifier with its respective parameters\n",
    "    gs = GridSearchCV(pipeline, param_grid=params[model], cv=5, n_jobs=-1, scoring='roc_auc')\n",
    "\n",
    "    gs.fit(X_train, y_train)\n",
    "    y_pred = gs.predict(X_test)\n",
    "    rgsrs[model] = gs\n",
    "    results[model] = gs.best_score_\n",
    "    print(f'{model} best score: {gs.best_score_}')\n",
    "    print(f'{model} best params: {gs.best_params_}')\n",
    "    print(f'{model} accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "    print(f'{model} confusion matrix: {confusion_matrix(y_test, y_pred)}')\n",
    "    print(f'{model} classification report:')\n",
    "    print(f'{classification_report(y_test, y_pred)}')\n",
    "    print('------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe com LOGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>safra</th>\n",
       "      <th>y</th>\n",
       "      <th>VAR_2</th>\n",
       "      <th>VAR_3</th>\n",
       "      <th>VAR_4</th>\n",
       "      <th>VAR_9</th>\n",
       "      <th>VAR_14</th>\n",
       "      <th>VAR_17</th>\n",
       "      <th>VAR_19</th>\n",
       "      <th>...</th>\n",
       "      <th>log_VAR_65</th>\n",
       "      <th>log_VAR_15</th>\n",
       "      <th>log_VAR_35</th>\n",
       "      <th>log_VAR_52</th>\n",
       "      <th>log_VAR_5</th>\n",
       "      <th>log_VAR_38</th>\n",
       "      <th>log_VAR_24</th>\n",
       "      <th>log_VAR_45</th>\n",
       "      <th>log_VAR_1</th>\n",
       "      <th>log_VAR_59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>201404</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.306095</td>\n",
       "      <td>-0.342735</td>\n",
       "      <td>-0.482881</td>\n",
       "      <td>-0.979672</td>\n",
       "      <td>1.743720</td>\n",
       "      <td>0.520456</td>\n",
       "      <td>2.336353</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533531</td>\n",
       "      <td>-1.062919</td>\n",
       "      <td>0.433640</td>\n",
       "      <td>-1.840272</td>\n",
       "      <td>0.971073</td>\n",
       "      <td>0.133697</td>\n",
       "      <td>0.809207</td>\n",
       "      <td>0.939938</td>\n",
       "      <td>-1.336531</td>\n",
       "      <td>-0.598788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>201407</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.306095</td>\n",
       "      <td>2.017805</td>\n",
       "      <td>0.336321</td>\n",
       "      <td>-0.220662</td>\n",
       "      <td>-0.263784</td>\n",
       "      <td>-0.190603</td>\n",
       "      <td>0.646951</td>\n",
       "      <td>...</td>\n",
       "      <td>0.632763</td>\n",
       "      <td>-0.134397</td>\n",
       "      <td>-0.273064</td>\n",
       "      <td>-0.090019</td>\n",
       "      <td>-0.582670</td>\n",
       "      <td>0.716001</td>\n",
       "      <td>0.245783</td>\n",
       "      <td>-0.076276</td>\n",
       "      <td>0.988031</td>\n",
       "      <td>-0.580202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>201405</td>\n",
       "      <td>0</td>\n",
       "      <td>1.278230</td>\n",
       "      <td>2.017805</td>\n",
       "      <td>1.155524</td>\n",
       "      <td>1.135459</td>\n",
       "      <td>-0.283257</td>\n",
       "      <td>-0.125598</td>\n",
       "      <td>-0.354176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.163875</td>\n",
       "      <td>0.707608</td>\n",
       "      <td>-1.691245</td>\n",
       "      <td>0.614341</td>\n",
       "      <td>0.254137</td>\n",
       "      <td>-0.552518</td>\n",
       "      <td>0.360154</td>\n",
       "      <td>0.018516</td>\n",
       "      <td>1.227918</td>\n",
       "      <td>0.328328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>201403</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.306095</td>\n",
       "      <td>-0.342735</td>\n",
       "      <td>-0.482881</td>\n",
       "      <td>1.297356</td>\n",
       "      <td>-0.862141</td>\n",
       "      <td>-0.279770</td>\n",
       "      <td>-0.479317</td>\n",
       "      <td>...</td>\n",
       "      <td>0.618105</td>\n",
       "      <td>-0.903285</td>\n",
       "      <td>0.580232</td>\n",
       "      <td>-0.386644</td>\n",
       "      <td>0.039806</td>\n",
       "      <td>0.666908</td>\n",
       "      <td>0.810336</td>\n",
       "      <td>0.073144</td>\n",
       "      <td>-1.336531</td>\n",
       "      <td>0.149738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>201405</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.306095</td>\n",
       "      <td>4.378344</td>\n",
       "      <td>0.336321</td>\n",
       "      <td>-1.131474</td>\n",
       "      <td>-0.283257</td>\n",
       "      <td>-0.125598</td>\n",
       "      <td>-0.479317</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.379017</td>\n",
       "      <td>-0.051390</td>\n",
       "      <td>0.313698</td>\n",
       "      <td>0.044153</td>\n",
       "      <td>-0.007904</td>\n",
       "      <td>0.450513</td>\n",
       "      <td>0.095244</td>\n",
       "      <td>0.018516</td>\n",
       "      <td>0.961717</td>\n",
       "      <td>0.181798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id   safra  y     VAR_2     VAR_3     VAR_4     VAR_9    VAR_14    VAR_17  \\\n",
       "0  1.0  201404  0 -0.306095 -0.342735 -0.482881 -0.979672  1.743720  0.520456   \n",
       "1  2.0  201407  0 -0.306095  2.017805  0.336321 -0.220662 -0.263784 -0.190603   \n",
       "2  3.0  201405  0  1.278230  2.017805  1.155524  1.135459 -0.283257 -0.125598   \n",
       "3  5.0  201403  1 -0.306095 -0.342735 -0.482881  1.297356 -0.862141 -0.279770   \n",
       "4  6.0  201405  0 -0.306095  4.378344  0.336321 -1.131474 -0.283257 -0.125598   \n",
       "\n",
       "     VAR_19  ...  log_VAR_65  log_VAR_15  log_VAR_35  log_VAR_52  log_VAR_5  \\\n",
       "0  2.336353  ...    0.533531   -1.062919    0.433640   -1.840272   0.971073   \n",
       "1  0.646951  ...    0.632763   -0.134397   -0.273064   -0.090019  -0.582670   \n",
       "2 -0.354176  ...    0.163875    0.707608   -1.691245    0.614341   0.254137   \n",
       "3 -0.479317  ...    0.618105   -0.903285    0.580232   -0.386644   0.039806   \n",
       "4 -0.479317  ...   -0.379017   -0.051390    0.313698    0.044153  -0.007904   \n",
       "\n",
       "   log_VAR_38  log_VAR_24  log_VAR_45  log_VAR_1  log_VAR_59  \n",
       "0    0.133697    0.809207    0.939938  -1.336531   -0.598788  \n",
       "1    0.716001    0.245783   -0.076276   0.988031   -0.580202  \n",
       "2   -0.552518    0.360154    0.018516   1.227918    0.328328  \n",
       "3    0.666908    0.810336    0.073144  -1.336531    0.149738  \n",
       "4    0.450513    0.095244    0.018516   0.961717    0.181798  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_parquet(\"../data/SOT/base_tratada_treino_LOG.parquet\")\n",
    "df_test = pd.read_parquet(\"../data/SOT/base_tratada_teste_LOG.parquet\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>safra</th>\n",
       "      <th>y</th>\n",
       "      <th>VAR_2</th>\n",
       "      <th>VAR_3</th>\n",
       "      <th>VAR_4</th>\n",
       "      <th>VAR_9</th>\n",
       "      <th>VAR_14</th>\n",
       "      <th>VAR_17</th>\n",
       "      <th>VAR_19</th>\n",
       "      <th>...</th>\n",
       "      <th>log_VAR_65</th>\n",
       "      <th>log_VAR_15</th>\n",
       "      <th>log_VAR_35</th>\n",
       "      <th>log_VAR_52</th>\n",
       "      <th>log_VAR_5</th>\n",
       "      <th>log_VAR_38</th>\n",
       "      <th>log_VAR_24</th>\n",
       "      <th>log_VAR_45</th>\n",
       "      <th>log_VAR_1</th>\n",
       "      <th>log_VAR_59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>201411</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.306095</td>\n",
       "      <td>-0.342735</td>\n",
       "      <td>-0.482881</td>\n",
       "      <td>-0.220662</td>\n",
       "      <td>-0.253162</td>\n",
       "      <td>-0.066866</td>\n",
       "      <td>-0.479317</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079928</td>\n",
       "      <td>0.939818</td>\n",
       "      <td>-0.099179</td>\n",
       "      <td>0.912198</td>\n",
       "      <td>1.438752</td>\n",
       "      <td>0.145762</td>\n",
       "      <td>1.129604</td>\n",
       "      <td>0.118659</td>\n",
       "      <td>-1.336531</td>\n",
       "      <td>0.308656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>201411</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.306095</td>\n",
       "      <td>-0.342735</td>\n",
       "      <td>-0.482881</td>\n",
       "      <td>1.297356</td>\n",
       "      <td>0.196490</td>\n",
       "      <td>0.696653</td>\n",
       "      <td>-0.479317</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079928</td>\n",
       "      <td>0.362980</td>\n",
       "      <td>-0.099179</td>\n",
       "      <td>0.437479</td>\n",
       "      <td>0.101585</td>\n",
       "      <td>-0.020108</td>\n",
       "      <td>0.047870</td>\n",
       "      <td>0.118659</td>\n",
       "      <td>-1.336531</td>\n",
       "      <td>0.308656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>201411</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.306095</td>\n",
       "      <td>-0.342735</td>\n",
       "      <td>-0.482881</td>\n",
       "      <td>-0.827870</td>\n",
       "      <td>0.600115</td>\n",
       "      <td>-0.889116</td>\n",
       "      <td>3.650333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.827502</td>\n",
       "      <td>-0.542711</td>\n",
       "      <td>-1.690791</td>\n",
       "      <td>0.597780</td>\n",
       "      <td>0.294404</td>\n",
       "      <td>-0.020108</td>\n",
       "      <td>-1.109161</td>\n",
       "      <td>0.118659</td>\n",
       "      <td>-0.054306</td>\n",
       "      <td>0.595424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>201411</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.306095</td>\n",
       "      <td>-0.342735</td>\n",
       "      <td>0.336321</td>\n",
       "      <td>0.690149</td>\n",
       "      <td>-0.486840</td>\n",
       "      <td>1.460171</td>\n",
       "      <td>-0.479317</td>\n",
       "      <td>...</td>\n",
       "      <td>0.190728</td>\n",
       "      <td>0.362980</td>\n",
       "      <td>-0.099179</td>\n",
       "      <td>0.437479</td>\n",
       "      <td>-0.360801</td>\n",
       "      <td>0.426502</td>\n",
       "      <td>0.447838</td>\n",
       "      <td>0.835193</td>\n",
       "      <td>0.841930</td>\n",
       "      <td>-0.198353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47</td>\n",
       "      <td>201411</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.306095</td>\n",
       "      <td>-0.342735</td>\n",
       "      <td>-0.482881</td>\n",
       "      <td>-0.827870</td>\n",
       "      <td>-0.253162</td>\n",
       "      <td>-0.654187</td>\n",
       "      <td>-0.479317</td>\n",
       "      <td>...</td>\n",
       "      <td>1.029933</td>\n",
       "      <td>1.913143</td>\n",
       "      <td>-0.099179</td>\n",
       "      <td>2.523441</td>\n",
       "      <td>0.101585</td>\n",
       "      <td>-0.020108</td>\n",
       "      <td>0.047870</td>\n",
       "      <td>0.118659</td>\n",
       "      <td>-1.336531</td>\n",
       "      <td>0.308656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   safra  y     VAR_2     VAR_3     VAR_4     VAR_9    VAR_14    VAR_17  \\\n",
       "0  13  201411  1 -0.306095 -0.342735 -0.482881 -0.220662 -0.253162 -0.066866   \n",
       "1  20  201411  0 -0.306095 -0.342735 -0.482881  1.297356  0.196490  0.696653   \n",
       "2  32  201411  0 -0.306095 -0.342735 -0.482881 -0.827870  0.600115 -0.889116   \n",
       "3  36  201411  1 -0.306095 -0.342735  0.336321  0.690149 -0.486840  1.460171   \n",
       "4  47  201411  0 -0.306095 -0.342735 -0.482881 -0.827870 -0.253162 -0.654187   \n",
       "\n",
       "     VAR_19  ...  log_VAR_65  log_VAR_15  log_VAR_35  log_VAR_52  log_VAR_5  \\\n",
       "0 -0.479317  ...    0.079928    0.939818   -0.099179    0.912198   1.438752   \n",
       "1 -0.479317  ...    0.079928    0.362980   -0.099179    0.437479   0.101585   \n",
       "2  3.650333  ...    0.827502   -0.542711   -1.690791    0.597780   0.294404   \n",
       "3 -0.479317  ...    0.190728    0.362980   -0.099179    0.437479  -0.360801   \n",
       "4 -0.479317  ...    1.029933    1.913143   -0.099179    2.523441   0.101585   \n",
       "\n",
       "   log_VAR_38  log_VAR_24  log_VAR_45  log_VAR_1  log_VAR_59  \n",
       "0    0.145762    1.129604    0.118659  -1.336531    0.308656  \n",
       "1   -0.020108    0.047870    0.118659  -1.336531    0.308656  \n",
       "2   -0.020108   -1.109161    0.118659  -0.054306    0.595424  \n",
       "3    0.426502    0.447838    0.835193   0.841930   -0.198353  \n",
       "4   -0.020108    0.047870    0.118659  -1.336531    0.308656  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForest\n",
    "rf_params = {\n",
    "    'n_estimators': [50, 100],  \n",
    "    'max_depth': [None, 10],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'bootstrap': [True]\n",
    "}\n",
    "\n",
    "# Ridge \n",
    "ridge_params = {\n",
    "    'alpha': [0.1, 1],\n",
    "    'solver': ['auto', 'saga'], \n",
    "    'fit_intercept': [True]\n",
    "}\n",
    "\n",
    "# Logistic Regression \n",
    "logreg_params = {\n",
    "    'C': [0.1, 1],\n",
    "    'solver': ['lbfgs'],\n",
    "    'max_iter': [100] \n",
    "}\n",
    "\n",
    "# SVC\n",
    "svc_params = {\n",
    "    'C': [0.1, 1],\n",
    "    'kernel': ['linear'],\n",
    "    'gamma': ['scale']\n",
    "}\n",
    "\n",
    "# KNN\n",
    "knn_params = {\n",
    "    'n_neighbors': [3, 5],\n",
    "    'weights': ['uniform'],\n",
    "    'metric': ['euclidean']\n",
    "}\n",
    "\n",
    "# DecisionTree\n",
    "dt_params = {\n",
    "    'criterion': ['gini'],\n",
    "    'max_depth': [10], \n",
    "    'min_samples_split': [2], \n",
    "    'min_samples_leaf': [1], \n",
    "}\n",
    "\n",
    "# AdaBoost \n",
    "ada_params = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'learning_rate': [0.1],\n",
    "    'algorithm': ['SAMME']\n",
    "}\n",
    "\n",
    "# GradientBoosting \n",
    "gb_params = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'learning_rate': [0.1],\n",
    "    'max_depth': [3], \n",
    "    'min_samples_split': [2] \n",
    "}\n",
    "\n",
    "# ExtraTree\n",
    "et_params = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [10], \n",
    "    'min_samples_split': [2], \n",
    "    'min_samples_leaf': [1],\n",
    "    'bootstrap': [True] \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = {\n",
    "    'RandomForest': RandomForestClassifier(random_state=98),\n",
    "    'Ridge': RidgeClassifier(random_state=98),\n",
    "    'LogisticRegression': LogisticRegression(random_state=98),\n",
    "    'SVC': SVC(random_state=98),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'DecisionTree': DecisionTreeClassifier(random_state=98),\n",
    "    'AdaBoost': AdaBoostClassifier(random_state=98),\n",
    "    'GradientBoosting': GradientBoostingClassifier(random_state=98),\n",
    "    'ExtraTrees': ExtraTreesClassifier(random_state=98)\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'RandomForest': rf_params,\n",
    "    'Ridge': ridge_params,\n",
    "    'LogisticRegression': logreg_params,\n",
    "    'SVC': svc_params,\n",
    "    'KNN': knn_params,\n",
    "    'DecisionTree': dt_params,\n",
    "    'AdaBoost': ada_params,\n",
    "    'GradientBoosting': gb_params,\n",
    "    'ExtraTrees': et_params\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(columns=[\"id\", \"safra\", \"y\"])\n",
    "y_train = df_train[\"y\"]\n",
    "X_test = df_test.drop(columns=[\"id\", \"safra\", \"y\"])\n",
    "y_test = df_test[\"y\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BorderlineSMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y\n",
       "0    6453\n",
       "1    6453\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blsmote = BorderlineSMOTE(sampling_strategy='minority', kind='borderline-1')\n",
    "X_train_sampled, y_train_sampled = blsmote.fit_resample(X_train,y_train)\n",
    "y_train_sampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest best score: 0.9311834479618823\n",
      "RandomForest best params: {'bootstrap': True, 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "RandomForest accuracy: 0.7054455445544554\n",
      "RandomForest confusion matrix: [[467  72]\n",
      " [166 103]]\n",
      "RandomForest classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.87      0.80       539\n",
      "           1       0.59      0.38      0.46       269\n",
      "\n",
      "    accuracy                           0.71       808\n",
      "   macro avg       0.66      0.62      0.63       808\n",
      "weighted avg       0.69      0.71      0.69       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "Ridge best score: 0.7660266525428812\n",
      "Ridge best params: {'alpha': 1, 'fit_intercept': True, 'solver': 'auto'}\n",
      "Ridge accuracy: 0.6905940594059405\n",
      "Ridge confusion matrix: [[410 129]\n",
      " [121 148]]\n",
      "Ridge classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.76      0.77       539\n",
      "           1       0.53      0.55      0.54       269\n",
      "\n",
      "    accuracy                           0.69       808\n",
      "   macro avg       0.65      0.66      0.65       808\n",
      "weighted avg       0.69      0.69      0.69       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "LogisticRegression best score: 0.7662187358211975\n",
      "LogisticRegression best params: {'C': 0.1, 'max_iter': 100, 'solver': 'lbfgs'}\n",
      "LogisticRegression accuracy: 0.6955445544554455\n",
      "LogisticRegression confusion matrix: [[416 123]\n",
      " [123 146]]\n",
      "LogisticRegression classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.77      0.77       539\n",
      "           1       0.54      0.54      0.54       269\n",
      "\n",
      "    accuracy                           0.70       808\n",
      "   macro avg       0.66      0.66      0.66       808\n",
      "weighted avg       0.70      0.70      0.70       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "SVC best score: 0.7666878250893554\n",
      "SVC best params: {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "SVC accuracy: 0.6905940594059405\n",
      "SVC confusion matrix: [[406 133]\n",
      " [117 152]]\n",
      "SVC classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.75      0.76       539\n",
      "           1       0.53      0.57      0.55       269\n",
      "\n",
      "    accuracy                           0.69       808\n",
      "   macro avg       0.65      0.66      0.66       808\n",
      "weighted avg       0.70      0.69      0.69       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "KNN best score: 0.8420155054108396\n",
      "KNN best params: {'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "KNN accuracy: 0.620049504950495\n",
      "KNN confusion matrix: [[347 192]\n",
      " [115 154]]\n",
      "KNN classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.64      0.69       539\n",
      "           1       0.45      0.57      0.50       269\n",
      "\n",
      "    accuracy                           0.62       808\n",
      "   macro avg       0.60      0.61      0.60       808\n",
      "weighted avg       0.65      0.62      0.63       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "DecisionTree best score: 0.8096157028863505\n",
      "DecisionTree best params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "DecisionTree accuracy: 0.6695544554455446\n",
      "DecisionTree confusion matrix: [[412 127]\n",
      " [140 129]]\n",
      "DecisionTree classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.76      0.76       539\n",
      "           1       0.50      0.48      0.49       269\n",
      "\n",
      "    accuracy                           0.67       808\n",
      "   macro avg       0.63      0.62      0.62       808\n",
      "weighted avg       0.67      0.67      0.67       808\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Leonardo\\anaconda3\\envs\\credit-score-challenge\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost best score: 0.7935652468272492\n",
      "AdaBoost best params: {'algorithm': 'SAMME', 'learning_rate': 0.1, 'n_estimators': 100}\n",
      "AdaBoost accuracy: 0.7029702970297029\n",
      "AdaBoost confusion matrix: [[447  92]\n",
      " [148 121]]\n",
      "AdaBoost classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.83      0.79       539\n",
      "           1       0.57      0.45      0.50       269\n",
      "\n",
      "    accuracy                           0.70       808\n",
      "   macro avg       0.66      0.64      0.65       808\n",
      "weighted avg       0.69      0.70      0.69       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "GradientBoosting best score: 0.8939307309864113\n",
      "GradientBoosting best params: {'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "GradientBoosting accuracy: 0.693069306930693\n",
      "GradientBoosting confusion matrix: [[481  58]\n",
      " [190  79]]\n",
      "GradientBoosting classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.89      0.80       539\n",
      "           1       0.58      0.29      0.39       269\n",
      "\n",
      "    accuracy                           0.69       808\n",
      "   macro avg       0.65      0.59      0.59       808\n",
      "weighted avg       0.67      0.69      0.66       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "ExtraTrees best score: 0.8248504664720349\n",
      "ExtraTrees best params: {'bootstrap': True, 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "ExtraTrees accuracy: 0.6868811881188119\n",
      "ExtraTrees confusion matrix: [[403 136]\n",
      " [117 152]]\n",
      "ExtraTrees classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.75      0.76       539\n",
      "           1       0.53      0.57      0.55       269\n",
      "\n",
      "    accuracy                           0.69       808\n",
      "   macro avg       0.65      0.66      0.65       808\n",
      "weighted avg       0.69      0.69      0.69       808\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "rgsrs, results = evaluate_classifiers(clfs, params, X_train_sampled, y_train_sampled, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weigthed Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = {\n",
    "    'RandomForest': RandomForestClassifier(class_weight='balanced',random_state=98),\n",
    "    'Ridge': RidgeClassifier(class_weight='balanced', random_state=98),\n",
    "    'LogisticRegression': LogisticRegression(class_weight='balanced', random_state=98),\n",
    "    'SVC': SVC(class_weight='balanced', random_state=98),\n",
    "    'DecisionTree': DecisionTreeClassifier(class_weight=\"balanced\",random_state=98),\n",
    "    # 'AdaBoost': AdaBoostClassifier(random_state=98),\n",
    "    # 'GradientBoosting': GradientBoostingClassifier(random_state=98),\n",
    "    'ExtraTrees': ExtraTreesClassifier(class_weight='balanced', random_state=98)\n",
    "}\n",
    "params = {\n",
    "    'RandomForest': rf_params,\n",
    "    'Ridge': ridge_params,\n",
    "    'LogisticRegression': logreg_params,\n",
    "    'SVC': svc_params,\n",
    "    'DecisionTree': dt_params,\n",
    "    # 'AdaBoost': ada_params,\n",
    "    # 'GradientBoosting': gb_params,\n",
    "    'ExtraTrees': et_params\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest best score: 0.9309485480285336\n",
      "RandomForest best params: {'bootstrap': True, 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "RandomForest accuracy: 0.7054455445544554\n",
      "RandomForest confusion matrix: [[467  72]\n",
      " [166 103]]\n",
      "RandomForest classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.87      0.80       539\n",
      "           1       0.59      0.38      0.46       269\n",
      "\n",
      "    accuracy                           0.71       808\n",
      "   macro avg       0.66      0.62      0.63       808\n",
      "weighted avg       0.69      0.71      0.69       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "Ridge best score: 0.7660270130979198\n",
      "Ridge best params: {'alpha': 0.1, 'fit_intercept': True, 'solver': 'auto'}\n",
      "Ridge accuracy: 0.6905940594059405\n",
      "Ridge confusion matrix: [[410 129]\n",
      " [121 148]]\n",
      "Ridge classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.76      0.77       539\n",
      "           1       0.53      0.55      0.54       269\n",
      "\n",
      "    accuracy                           0.69       808\n",
      "   macro avg       0.65      0.66      0.65       808\n",
      "weighted avg       0.69      0.69      0.69       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "LogisticRegression best score: 0.7662172947173118\n",
      "LogisticRegression best params: {'C': 0.1, 'max_iter': 100, 'solver': 'lbfgs'}\n",
      "LogisticRegression accuracy: 0.6955445544554455\n",
      "LogisticRegression confusion matrix: [[416 123]\n",
      " [123 146]]\n",
      "LogisticRegression classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.77      0.77       539\n",
      "           1       0.54      0.54      0.54       269\n",
      "\n",
      "    accuracy                           0.70       808\n",
      "   macro avg       0.66      0.66      0.66       808\n",
      "weighted avg       0.70      0.70      0.70       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "SVC best score: 0.7666782177301183\n",
      "SVC best params: {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "SVC accuracy: 0.6905940594059405\n",
      "SVC confusion matrix: [[406 133]\n",
      " [117 152]]\n",
      "SVC classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.75      0.76       539\n",
      "           1       0.53      0.57      0.55       269\n",
      "\n",
      "    accuracy                           0.69       808\n",
      "   macro avg       0.65      0.66      0.66       808\n",
      "weighted avg       0.70      0.69      0.69       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "DecisionTree best score: 0.8096885987245626\n",
      "DecisionTree best params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "DecisionTree accuracy: 0.6695544554455446\n",
      "DecisionTree confusion matrix: [[412 127]\n",
      " [140 129]]\n",
      "DecisionTree classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.76      0.76       539\n",
      "           1       0.50      0.48      0.49       269\n",
      "\n",
      "    accuracy                           0.67       808\n",
      "   macro avg       0.63      0.62      0.62       808\n",
      "weighted avg       0.67      0.67      0.67       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "ExtraTrees best score: 0.8246536356996632\n",
      "ExtraTrees best params: {'bootstrap': True, 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "ExtraTrees accuracy: 0.6868811881188119\n",
      "ExtraTrees confusion matrix: [[403 136]\n",
      " [117 152]]\n",
      "ExtraTrees classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.75      0.76       539\n",
      "           1       0.53      0.57      0.55       269\n",
      "\n",
      "    accuracy                           0.69       808\n",
      "   macro avg       0.65      0.66      0.65       808\n",
      "weighted avg       0.69      0.69      0.69       808\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "rgsrs, results = evaluate_classifiers(clfs, params, X_train_sampled, y_train_sampled, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning de Threshold do ExtraTree com Borderline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_parquet(\"../data/SOT/base_tratada_treino_sem_outliers.parquet\")\n",
    "df_test = pd.read_parquet(\"../data/SOT/base_tratada_teste.parquet\")\n",
    "X_train = df_train.drop(columns=[\"id\", \"safra\", \"y\"])\n",
    "y_train = df_train[\"y\"]\n",
    "X_test = df_test.drop(columns=[\"id\", \"safra\", \"y\"])\n",
    "y_test = df_test[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y\n",
       "0    6249\n",
       "1    6249\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blsmote = BorderlineSMOTE(sampling_strategy='minority', kind='borderline-1')\n",
    "X_train_sampled, y_train_sampled = blsmote.fit_resample(X_train,y_train)\n",
    "y_train_sampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ExtraTree\n",
    "et_params = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [10], \n",
    "    'min_samples_split': [2], \n",
    "    'min_samples_leaf': [1],\n",
    "    'bootstrap': [True] \n",
    "}\n",
    "\n",
    "clfs = {\n",
    "    'ExtraTrees': ExtraTreesClassifier(random_state=98)\n",
    "}\n",
    "params = {\n",
    "    'ExtraTrees': et_params\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTrees best score: 0.8098742185300241\n",
      "ExtraTrees best params: {'bootstrap': True, 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "ExtraTrees accuracy: 0.6943069306930693\n",
      "ExtraTrees confusion matrix: [[396 143]\n",
      " [104 165]]\n",
      "ExtraTrees classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.73      0.76       539\n",
      "           1       0.54      0.61      0.57       269\n",
      "\n",
      "    accuracy                           0.69       808\n",
      "   macro avg       0.66      0.67      0.67       808\n",
      "weighted avg       0.71      0.69      0.70       808\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "rgsrs, results = evaluate_classifiers(clfs, params, X_train_sampled, y_train_sampled, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.7570601851237881\n",
      "Test F1: 0.5636942675159236\n",
      "Threshold:  0.469\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[357, 182],\n",
       "       [ 92, 177]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_model = TunedThresholdClassifierCV(rgsrs[\"ExtraTrees\"], cv=5, scoring='f1', store_cv_results=True, random_state=98)\n",
    "tuned_model.fit(X_train_sampled, y_train_sampled)\n",
    "avg_f1_train = tuned_model.best_score_\n",
    "f1 = f1_score(y_test, tuned_model.predict(X_test))\n",
    "print(f\"Train F1: {avg_f1_train}\")\n",
    "print(f\"Test F1: {f1}\")\n",
    "print(f\"Threshold: {tuned_model.best_threshold_: .3f}\")\n",
    "\n",
    "confusion_matrix(y_test, tuned_model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.66      0.72       539\n",
      "           1       0.49      0.66      0.56       269\n",
      "\n",
      "    accuracy                           0.66       808\n",
      "   macro avg       0.64      0.66      0.64       808\n",
      "weighted avg       0.69      0.66      0.67       808\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, tuned_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sem inputaÃ§Ã£o de Missings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_parquet(\"../data/SOT/base_tratada_com_na.parquet\")\n",
    "df_test = pd.read_parquet(\"../data/SOT/base_tratada_teste_com_na.parquet\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HistGradientBoosting best params: {'l2_regularization': 0.0, 'learning_rate': 0.1, 'max_depth': 3, 'max_iter': 100, 'min_samples_leaf': 1}\n",
      "HistGradientBoosting best score: 0.738073802129549\n",
      "HistGradientBoosting accuracy: 0.6806930693069307\n",
      "HistGradientBoosting confusion matrix: [[505  34]\n",
      " [224  45]]\n",
      "HistGradientBoosting classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.94      0.80       539\n",
      "           1       0.57      0.17      0.26       269\n",
      "\n",
      "    accuracy                           0.68       808\n",
      "   macro avg       0.63      0.55      0.53       808\n",
      "weighted avg       0.65      0.68      0.62       808\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "# GradientBoosting\n",
    "gb_params = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'learning_rate': [0.1],\n",
    "    'max_depth': [3], \n",
    "    'min_samples_split': [2] \n",
    "}\n",
    "\n",
    "# HistGradientBoosting\n",
    "\n",
    "hgb_params = {\n",
    "    'max_iter': [50, 100],\n",
    "    'max_depth': [3], \n",
    "    'min_samples_leaf': [1],\n",
    "    'l2_regularization': [0.0, 0.1],\n",
    "    'learning_rate': [0.1]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "clfs = {\n",
    "    'HistGradientBoosting': HistGradientBoostingClassifier(random_state=98, class_weight='balanced')\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'HistGradientBoosting': hgb_params\n",
    "}\n",
    "\n",
    "X_train = df_train.drop(columns=[\"id\", \"safra\", \"y\"])\n",
    "y_train = df_train[\"y\"]\n",
    "\n",
    "X_test = df_test.drop(columns=[\"id\", \"safra\", \"y\"])\n",
    "y_test = df_test[\"y\"]\n",
    "\n",
    "rgsrs, results = evaluate_classifiers(clfs, params, X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InputaÃ§Ã£o de missings com MICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Leonardo\\anaconda3\\envs\\credit-score-challenge\\Lib\\site-packages\\sklearn\\impute\\_iterative.py:895: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest best params: {'bootstrap': True, 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "RandomForest best score: 0.7534887038068568\n",
      "RandomForest accuracy: 0.5185643564356436\n",
      "RandomForest confusion matrix: [[275 264]\n",
      " [125 144]]\n",
      "RandomForest classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.51      0.59       539\n",
      "           1       0.35      0.54      0.43       269\n",
      "\n",
      "    accuracy                           0.52       808\n",
      "   macro avg       0.52      0.52      0.51       808\n",
      "weighted avg       0.58      0.52      0.53       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "Ridge best params: {'alpha': 1, 'fit_intercept': True, 'solver': 'auto'}\n",
      "Ridge best score: 0.7499005901768707\n",
      "Ridge accuracy: 0.650990099009901\n",
      "Ridge confusion matrix: [[342 197]\n",
      " [ 85 184]]\n",
      "Ridge classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.63      0.71       539\n",
      "           1       0.48      0.68      0.57       269\n",
      "\n",
      "    accuracy                           0.65       808\n",
      "   macro avg       0.64      0.66      0.64       808\n",
      "weighted avg       0.70      0.65      0.66       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "LogisticRegression best params: {'C': 1, 'max_iter': 100, 'solver': 'lbfgs'}\n",
      "LogisticRegression best score: 0.7547762690278654\n",
      "LogisticRegression accuracy: 0.681930693069307\n",
      "LogisticRegression confusion matrix: [[497  42]\n",
      " [215  54]]\n",
      "LogisticRegression classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.92      0.79       539\n",
      "           1       0.56      0.20      0.30       269\n",
      "\n",
      "    accuracy                           0.68       808\n",
      "   macro avg       0.63      0.56      0.55       808\n",
      "weighted avg       0.65      0.68      0.63       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "SVC best params: {'C': 1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "SVC best score: 0.7370850634685592\n",
      "SVC accuracy: 0.6621287128712872\n",
      "SVC confusion matrix: [[386 153]\n",
      " [120 149]]\n",
      "SVC classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.72      0.74       539\n",
      "           1       0.49      0.55      0.52       269\n",
      "\n",
      "    accuracy                           0.66       808\n",
      "   macro avg       0.63      0.64      0.63       808\n",
      "weighted avg       0.67      0.66      0.67       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "KNN best params: {'metric': 'euclidean', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "KNN best score: 0.7285170000827756\n",
      "KNN accuracy: 0.6683168316831684\n",
      "KNN confusion matrix: [[539   0]\n",
      " [268   1]]\n",
      "KNN classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80       539\n",
      "           1       1.00      0.00      0.01       269\n",
      "\n",
      "    accuracy                           0.67       808\n",
      "   macro avg       0.83      0.50      0.40       808\n",
      "weighted avg       0.78      0.67      0.54       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "DecisionTree best params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "DecisionTree best score: 0.7249070578573615\n",
      "DecisionTree accuracy: 0.4319306930693069\n",
      "DecisionTree confusion matrix: [[209 330]\n",
      " [129 140]]\n",
      "DecisionTree classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.39      0.48       539\n",
      "           1       0.30      0.52      0.38       269\n",
      "\n",
      "    accuracy                           0.43       808\n",
      "   macro avg       0.46      0.45      0.43       808\n",
      "weighted avg       0.51      0.43      0.44       808\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Leonardo\\anaconda3\\envs\\credit-score-challenge\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost best params: {'algorithm': 'SAMME', 'learning_rate': 0.1, 'n_estimators': 100}\n",
      "AdaBoost best score: 0.722057976026613\n",
      "AdaBoost accuracy: 0.5037128712871287\n",
      "AdaBoost confusion matrix: [[230 309]\n",
      " [ 92 177]]\n",
      "AdaBoost classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.43      0.53       539\n",
      "           1       0.36      0.66      0.47       269\n",
      "\n",
      "    accuracy                           0.50       808\n",
      "   macro avg       0.54      0.54      0.50       808\n",
      "weighted avg       0.60      0.50      0.51       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "GradientBoosting best params: {'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "GradientBoosting best score: 0.7555835469138963\n",
      "GradientBoosting accuracy: 0.3353960396039604\n",
      "GradientBoosting confusion matrix: [[  2 537]\n",
      " [  0 269]]\n",
      "GradientBoosting classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.01       539\n",
      "           1       0.33      1.00      0.50       269\n",
      "\n",
      "    accuracy                           0.34       808\n",
      "   macro avg       0.67      0.50      0.25       808\n",
      "weighted avg       0.78      0.34      0.17       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "ExtraTrees best params: {'bootstrap': True, 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "ExtraTrees best score: 0.7306540584339131\n",
      "ExtraTrees accuracy: 0.6113861386138614\n",
      "ExtraTrees confusion matrix: [[427 112]\n",
      " [202  67]]\n",
      "ExtraTrees classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.79      0.73       539\n",
      "           1       0.37      0.25      0.30       269\n",
      "\n",
      "    accuracy                           0.61       808\n",
      "   macro avg       0.53      0.52      0.52       808\n",
      "weighted avg       0.58      0.61      0.59       808\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from fancyimpute import IterativeImputer\n",
    "\n",
    "imputador = IterativeImputer()\n",
    "\n",
    "df_train = pd.read_parquet(\"../data/SOT/base_tratada_com_na.parquet\")\n",
    "df_test = pd.read_parquet(\"../data/SOT/base_tratada_teste_com_na.parquet\")\n",
    "\n",
    "X_train = df_train.drop(columns=[\"id\", \"safra\", \"y\"])\n",
    "X_train = imputador.fit_transform(X_train)\n",
    "y_train = df_train[\"y\"]\n",
    "\n",
    "X_test = df_test.drop(columns=[\"id\", \"safra\", \"y\"])\n",
    "X_test = imputador.transform(X_test)\n",
    "y_test = df_test[\"y\"]\n",
    "\n",
    "# RandomForest\n",
    "rf_params = {\n",
    "    'n_estimators': [50, 100],  \n",
    "    'max_depth': [None, 10],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'bootstrap': [True]\n",
    "}\n",
    "\n",
    "# Ridge \n",
    "ridge_params = {\n",
    "    'alpha': [0.1, 1],\n",
    "    'solver': ['auto', 'saga'], \n",
    "    'fit_intercept': [True]\n",
    "}\n",
    "\n",
    "# Logistic Regression \n",
    "logreg_params = {\n",
    "    'C': [0.1, 1],\n",
    "    'solver': ['lbfgs'],\n",
    "    'max_iter': [100] \n",
    "}\n",
    "\n",
    "# SVC\n",
    "svc_params = {\n",
    "    'C': [0.1, 1],\n",
    "    'kernel': ['linear'],\n",
    "    'gamma': ['scale']\n",
    "}\n",
    "\n",
    "# KNN\n",
    "knn_params = {\n",
    "    'n_neighbors': [3, 5],\n",
    "    'weights': ['uniform'],\n",
    "    'metric': ['euclidean']\n",
    "}\n",
    "\n",
    "# DecisionTree\n",
    "dt_params = {\n",
    "    'criterion': ['gini'],\n",
    "    'max_depth': [10], \n",
    "    'min_samples_split': [2], \n",
    "    'min_samples_leaf': [1], \n",
    "}\n",
    "\n",
    "# AdaBoost \n",
    "ada_params = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'learning_rate': [0.1],\n",
    "    'algorithm': ['SAMME']\n",
    "}\n",
    "\n",
    "# GradientBoosting \n",
    "gb_params = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'learning_rate': [0.1],\n",
    "    'max_depth': [3], \n",
    "    'min_samples_split': [2] \n",
    "}\n",
    "\n",
    "# ExtraTree\n",
    "et_params = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [10], \n",
    "    'min_samples_split': [2], \n",
    "    'min_samples_leaf': [1],\n",
    "    'bootstrap': [True] \n",
    "}\n",
    "\n",
    "clfs = {\n",
    "    'RandomForest': RandomForestClassifier(random_state=98),\n",
    "    'Ridge': RidgeClassifier(random_state=98),\n",
    "    'LogisticRegression': LogisticRegression(random_state=98),\n",
    "    'SVC': SVC(random_state=98),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'DecisionTree': DecisionTreeClassifier(random_state=98),\n",
    "    'AdaBoost': AdaBoostClassifier(random_state=98),\n",
    "    'GradientBoosting': GradientBoostingClassifier(random_state=98),\n",
    "    'ExtraTrees': ExtraTreesClassifier(random_state=98)\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'RandomForest': rf_params,\n",
    "    'Ridge': ridge_params,\n",
    "    'LogisticRegression': logreg_params,\n",
    "    'SVC': svc_params,\n",
    "    'KNN': knn_params,\n",
    "    'DecisionTree': dt_params,\n",
    "    'AdaBoost': ada_params,\n",
    "    'GradientBoosting': gb_params,\n",
    "    'ExtraTrees': et_params\n",
    "}\n",
    "\n",
    "rgsrs, results = evaluate_classifiers(clfs, params, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Leonardo\\credit-code-challenge\\notebooks\\../src\\lib_aux.py:176: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '5063.5' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[df[coluna_alvo].isna() & (df[column] == grouped_var), coluna_alvo] = grouped_df.loc[grouped_var, (coluna_alvo, method)]\n"
     ]
    }
   ],
   "source": [
    "df_test = fill_na_by(df_test, method = \"median\") ### Preenche os NA's\n",
    "df_train = fill_na_by(df_train, \"safra\", method='median')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tunando o melhor modelo\n",
    "\n",
    "Ao que tudo indica, o melhor modelo foi a regressÃ£o logistica utilizando ADASYN sampling, portanto, vamos tentar refinar este modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_parquet(\"../data/SOT/base_tratada_treino_sem_outliers.parquet\")\n",
    "df_test = pd.read_parquet(\"../data/SOT/base_tratada_teste.parquet\")\n",
    "\n",
    "X_train = df_train.drop(columns=[\"id\", \"safra\", \"y\"])\n",
    "y_train = df_train[\"y\"]\n",
    "X_test = df_test.drop(columns=[\"id\", \"safra\", \"y\"])\n",
    "y_test = df_test[\"y\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ParÃ¢metros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression (more parameters)\n",
    "logreg_params = {\n",
    "\n",
    "    'C': [0.1, 1, 10],\n",
    "    'solver': ['lbfgs', 'liblinear'],\n",
    "    'max_iter': [100, 200],\n",
    "    'penalty': [\"l1\",\"l2\", None]\n",
    "}\n",
    "\n",
    "\n",
    "clfs = {\n",
    "    'LogisticRegression': LogisticRegression(random_state=98)\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'LogisticRegression': logreg_params,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tentativa de PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.95)\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_train_pca\n",
    "\n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression best params: {'C': 10, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "LogisticRegression best score: 0.7420510734157503\n",
      "LogisticRegression accuracy: 0.6893564356435643\n",
      "LogisticRegression confusion matrix: [[524  15]\n",
      " [236  33]]\n",
      "LogisticRegression classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.97      0.81       539\n",
      "           1       0.69      0.12      0.21       269\n",
      "\n",
      "    accuracy                           0.69       808\n",
      "   macro avg       0.69      0.55      0.51       808\n",
      "weighted avg       0.69      0.69      0.61       808\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Leonardo\\anaconda3\\envs\\credit-score-challenge\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: FitFailedWarning: \n",
      "60 fits failed out of a total of 180.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Leonardo\\anaconda3\\envs\\credit-score-challenge\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Leonardo\\anaconda3\\envs\\credit-score-challenge\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\Leonardo\\anaconda3\\envs\\credit-score-challenge\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1193, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Leonardo\\anaconda3\\envs\\credit-score-challenge\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 63, in _check_solver\n",
      "    raise ValueError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Leonardo\\anaconda3\\envs\\credit-score-challenge\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Leonardo\\anaconda3\\envs\\credit-score-challenge\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\Leonardo\\anaconda3\\envs\\credit-score-challenge\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1193, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Leonardo\\anaconda3\\envs\\credit-score-challenge\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 76, in _check_solver\n",
      "    raise ValueError(\"penalty=None is not supported for the liblinear solver\")\n",
      "ValueError: penalty=None is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Leonardo\\anaconda3\\envs\\credit-score-challenge\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning: One or more of the test scores are non-finite: [       nan 0.74102746 0.74194286 0.74175234 0.74188921        nan\n",
      "        nan 0.74102746 0.74194286 0.74175234 0.74188921        nan\n",
      "        nan 0.74175234 0.74182242 0.74188921 0.74188921        nan\n",
      "        nan 0.74175234 0.74182242 0.74188921 0.74188921        nan\n",
      "        nan 0.74188921 0.74188921 0.74205107 0.74188921        nan\n",
      "        nan 0.74188921 0.74188921 0.74205107 0.74188921        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "rgsrs, results = evaluate_classifiers(clfs, params, X_train_pca, y_train, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Leonardo\\anaconda3\\envs\\credit-score-challenge\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: FitFailedWarning: \n",
      "60 fits failed out of a total of 180.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Leonardo\\anaconda3\\envs\\credit-score-challenge\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Leonardo\\anaconda3\\envs\\credit-score-challenge\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\Leonardo\\anaconda3\\envs\\credit-score-challenge\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1193, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Leonardo\\anaconda3\\envs\\credit-score-challenge\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 63, in _check_solver\n",
      "    raise ValueError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Leonardo\\anaconda3\\envs\\credit-score-challenge\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Leonardo\\anaconda3\\envs\\credit-score-challenge\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\Leonardo\\anaconda3\\envs\\credit-score-challenge\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1193, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Leonardo\\anaconda3\\envs\\credit-score-challenge\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 76, in _check_solver\n",
      "    raise ValueError(\"penalty=None is not supported for the liblinear solver\")\n",
      "ValueError: penalty=None is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Leonardo\\anaconda3\\envs\\credit-score-challenge\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning: One or more of the test scores are non-finite: [       nan 0.6735464  0.67244151 0.67235442 0.67301086        nan\n",
      "        nan 0.6735464  0.67244151 0.67235442 0.67301086        nan\n",
      "        nan 0.67299346 0.67301086 0.67324944 0.67301086        nan\n",
      "        nan 0.67299346 0.67301086 0.67324944 0.67301086        nan\n",
      "        nan 0.67332719 0.67301086 0.67324944 0.67301086        nan\n",
      "        nan 0.67332719 0.67301086 0.67324944 0.67301086        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression best params: {'C': 0.1, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "LogisticRegression best score: 0.673546404388218\n",
      "LogisticRegression accuracy: 0.7042079207920792\n",
      "LogisticRegression confusion matrix: [[399 140]\n",
      " [ 99 170]]\n",
      "LogisticRegression classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.74      0.77       539\n",
      "           1       0.55      0.63      0.59       269\n",
      "\n",
      "    accuracy                           0.70       808\n",
      "   macro avg       0.67      0.69      0.68       808\n",
      "weighted avg       0.72      0.70      0.71       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "----------------------------------------- PURO\n",
      "LogisticRegression best params: {'C': 0.1, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "LogisticRegression best score: 0.6873782706960833\n",
      "LogisticRegression accuracy: 0.7029702970297029\n",
      "LogisticRegression confusion matrix: [[422 117]\n",
      " [123 146]]\n",
      "LogisticRegression classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.78      0.78       539\n",
      "           1       0.56      0.54      0.55       269\n",
      "\n",
      "    accuracy                           0.70       808\n",
      "   macro avg       0.66      0.66      0.66       808\n",
      "weighted avg       0.70      0.70      0.70       808\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Leonardo\\anaconda3\\envs\\credit-score-challenge\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: FitFailedWarning: \n",
      "60 fits failed out of a total of 180.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Leonardo\\anaconda3\\envs\\credit-score-challenge\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Leonardo\\anaconda3\\envs\\credit-score-challenge\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\Leonardo\\anaconda3\\envs\\credit-score-challenge\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1193, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Leonardo\\anaconda3\\envs\\credit-score-challenge\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 63, in _check_solver\n",
      "    raise ValueError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Leonardo\\anaconda3\\envs\\credit-score-challenge\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Leonardo\\anaconda3\\envs\\credit-score-challenge\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\Leonardo\\anaconda3\\envs\\credit-score-challenge\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1193, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Leonardo\\anaconda3\\envs\\credit-score-challenge\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 76, in _check_solver\n",
      "    raise ValueError(\"penalty=None is not supported for the liblinear solver\")\n",
      "ValueError: penalty=None is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Leonardo\\anaconda3\\envs\\credit-score-challenge\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning: One or more of the test scores are non-finite: [       nan 0.68737176 0.68737827 0.68729681 0.68692559        nan\n",
      "        nan 0.68737176 0.68737827 0.68729681 0.68692559        nan\n",
      "        nan 0.68722624 0.68715518 0.68732173 0.68692559        nan\n",
      "        nan 0.68722624 0.68715518 0.68732173 0.68692559        nan\n",
      "        nan 0.68724586 0.68700519 0.68724586 0.68692559        nan\n",
      "        nan 0.68724586 0.68700519 0.68724586 0.68692559        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "adasyn = ADASYN(sampling_strategy='minority', random_state=98)\n",
    "X_train_res, y_train_res = adasyn.fit_resample(X_train_pca, y_train)\n",
    "X_train_res_puro, y_train_res_puro = adasyn.fit_resample(X_train, y_train)\n",
    "\n",
    "rgsrs, results = evaluate_classifiers(clfs, params, X_train_res, y_train_res, X_test_pca, y_test)\n",
    "print(\"----------------------------------------- PURO\")\n",
    "rgsrs_puro, results_puro = evaluate_classifiers(clfs, params, X_train_res_puro, y_train_res_puro, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression best params: {'C': 0.1, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "LogisticRegression best score: 0.6730880156804665\n",
      "LogisticRegression accuracy: 0.6782178217821783\n",
      "LogisticRegression confusion matrix: [[373 166]\n",
      " [ 94 175]]\n",
      "LogisticRegression classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.69      0.74       539\n",
      "           1       0.51      0.65      0.57       269\n",
      "\n",
      "    accuracy                           0.68       808\n",
      "   macro avg       0.66      0.67      0.66       808\n",
      "weighted avg       0.70      0.68      0.69       808\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#### Tentando o ThreshHold Optimizer \n",
    "\n",
    "rgsrs_opt, results_opt = evaluate_classifiers(clfs, params, X_train_res, y_train_res, X_test_pca, y_test, True) ### Ainda fica pior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression (more parameters)\n",
    "logreg_params = {\n",
    "\n",
    "    'C': [0.1],\n",
    "    'solver': ['liblinear'],\n",
    "    'max_iter': [100],\n",
    "    'penalty': [\"l2\"]\n",
    "}\n",
    "\n",
    "\n",
    "clfs = {\n",
    "    'LogisticRegression': LogisticRegression(random_state=98)\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'LogisticRegression': logreg_params,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression best params: {'C': 0.1, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "LogisticRegression best score: 0.7020734096834057\n",
      "LogisticRegression accuracy: 0.6707920792079208\n",
      "LogisticRegression confusion matrix: [[376 163]\n",
      " [103 166]]\n",
      "LogisticRegression classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.70      0.74       539\n",
      "           1       0.50      0.62      0.56       269\n",
      "\n",
      "    accuracy                           0.67       808\n",
      "   macro avg       0.64      0.66      0.65       808\n",
      "weighted avg       0.69      0.67      0.68       808\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(X_train_res)\n",
    "X_poly_test = poly.transform(X_test_pca)\n",
    "\n",
    "rgsrs_poly, results_poly = evaluate_classifiers(clfs, params, X_poly, y_train_res, X_poly_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/logistic_regression_train_step.pkl']"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Salvando o modelo de treino\n",
    "\n",
    "joblib.dump(rgsrs[\"LogisticRegression\"], \"../models/logistic_regression_train_step.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conjunto de ValidaÃ§Ã£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Assumindo o melhor modelo como o de melhores metricas, vamos testar no conjunto de validaÃ§Ã£o\n",
    "\n",
    "df_val = pd.read_parquet(\"../data/SOT/base_validacao_nao_normalizada.parquet\")\n",
    "\n",
    "X_val = df_val.drop(columns=[\"id\", \"safra\", \"y\"])\n",
    "y_val = df_val[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgsrs[\"LogisticRegression\"].best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(**rgsrs[\"LogisticRegression\"].best_params_, random_state=98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgsrs[\"LogisticRegression\"].best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = joblib.load(\"../artifacts/scaler.pkl\")\n",
    "\n",
    "X_total = pd.concat([X_train, X_test])\n",
    "X_total = scaler.inverse_transform(X_total)\n",
    "y_total = pd.concat([y_train, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Leonardo\\anaconda3\\envs\\credit-score-challenge\\Lib\\site-packages\\sklearn\\utils\\validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.1, random_state=98, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=0.1, random_state=98, solver=&#x27;liblinear&#x27;)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=0.1, random_state=98, solver='liblinear')"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),          \n",
    "    ('pca', PCA(n_components=0.95))\n",
    "])\n",
    "\n",
    "X_train_total = pipeline.fit_transform(X_total)\n",
    "X_val_total = pipeline.transform(X_val)\n",
    "\n",
    "X_train_final, y_train_final = adasyn.fit_resample(X_train_total, y_total)\n",
    "\n",
    "model.fit(X_train_final, y_train_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6513994910941476\n",
      "confusion matrix: [[346 163]\n",
      " [111 166]]\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.68      0.72       509\n",
      "           1       0.50      0.60      0.55       277\n",
      "\n",
      "    accuracy                           0.65       786\n",
      "   macro avg       0.63      0.64      0.63       786\n",
      "weighted avg       0.67      0.65      0.66       786\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_val = model.predict(X_val_total)\n",
    "print(f'accuracy: {accuracy_score(y_val, y_pred_val)}')\n",
    "print(f'confusion matrix: {confusion_matrix(y_val, y_pred_val)}')\n",
    "print(f'classification report:')\n",
    "print(f'{classification_report(y_val, y_pred_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Vendo resultados\n",
    "\n",
    "threshold_v = np.linspace(0.01, 0.99, 100)\n",
    "acc_v = []\n",
    "prec_v = []\n",
    "recall_v = []\n",
    "f1_v = []\n",
    "\n",
    "for threshold in threshold_v:\n",
    "    y_pred = model.predict_proba(X_val_total)[:,1] > threshold\n",
    "\n",
    "    acc_v.append(accuracy_score(y_val, y_pred))\n",
    "    recall_v.append(recall_score(y_val, y_pred))\n",
    "    f1_v.append(f1_score(y_val, y_pred))\n",
    "    \n",
    "plt.plot(threshold_v, acc_v, label='accuracy')\n",
    "plt.plot(threshold_v, recall_v, label='recall')\n",
    "plt.plot(threshold_v, f1_v, label='f1')\n",
    "plt.xlabel('threshold')\n",
    "plt.ylabel('valor da mÃ©trica')\n",
    "plt.savefig(\"../graficos/linha_metricas.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_val, model.predict_proba(X_val_total)[:,1])\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0,1], [0,1])\n",
    "plt.xlabel('Falso positivo')\n",
    "plt.ylabel('Verdadeiro positivo')\n",
    "plt.title('Curva ROC')\n",
    "plt.savefig(\"../graficos/curva_roc.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.6808068485669501\n"
     ]
    }
   ],
   "source": [
    "print(\"AUC: \",auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_val, y_pred_val)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Previsto Negativo', 'Previsto Positivo'], yticklabels=['Real Negativo', 'Real Positivo'])\n",
    "plt.xlabel('Previsto')\n",
    "plt.ylabel('Real')\n",
    "plt.title('Matriz de ConfusÃ£o')\n",
    "plt.savefig(\"../graficos/confusion_matrix.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "credit-score-challenge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
