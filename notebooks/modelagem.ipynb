{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import RidgeClassifier, LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import TunedThresholdClassifierCV\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>safra</th>\n",
       "      <th>y</th>\n",
       "      <th>VAR_1</th>\n",
       "      <th>VAR_2</th>\n",
       "      <th>VAR_3</th>\n",
       "      <th>VAR_4</th>\n",
       "      <th>VAR_5</th>\n",
       "      <th>VAR_6</th>\n",
       "      <th>VAR_7</th>\n",
       "      <th>...</th>\n",
       "      <th>VAR_54</th>\n",
       "      <th>VAR_57</th>\n",
       "      <th>VAR_59</th>\n",
       "      <th>VAR_65</th>\n",
       "      <th>VAR_66</th>\n",
       "      <th>VAR_67</th>\n",
       "      <th>VAR_72</th>\n",
       "      <th>VAR_74</th>\n",
       "      <th>VAR_76</th>\n",
       "      <th>VAR_77</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>201404</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.727634</td>\n",
       "      <td>-0.306095</td>\n",
       "      <td>-0.342735</td>\n",
       "      <td>-0.482881</td>\n",
       "      <td>0.673819</td>\n",
       "      <td>0.278301</td>\n",
       "      <td>-0.213637</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.809742</td>\n",
       "      <td>-0.064927</td>\n",
       "      <td>-0.943633</td>\n",
       "      <td>0.143174</td>\n",
       "      <td>-0.685373</td>\n",
       "      <td>0.142450</td>\n",
       "      <td>-0.014629</td>\n",
       "      <td>2.354360</td>\n",
       "      <td>-0.525657</td>\n",
       "      <td>-0.433522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>201407</td>\n",
       "      <td>0</td>\n",
       "      <td>0.627340</td>\n",
       "      <td>-0.306095</td>\n",
       "      <td>2.017805</td>\n",
       "      <td>0.336321</td>\n",
       "      <td>-0.566411</td>\n",
       "      <td>0.150841</td>\n",
       "      <td>0.541208</td>\n",
       "      <td>...</td>\n",
       "      <td>0.175248</td>\n",
       "      <td>1.107199</td>\n",
       "      <td>-0.932521</td>\n",
       "      <td>0.284367</td>\n",
       "      <td>0.800071</td>\n",
       "      <td>0.198180</td>\n",
       "      <td>0.107461</td>\n",
       "      <td>-0.270421</td>\n",
       "      <td>-0.499363</td>\n",
       "      <td>0.272032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>201405</td>\n",
       "      <td>0</td>\n",
       "      <td>1.368341</td>\n",
       "      <td>1.278230</td>\n",
       "      <td>2.017805</td>\n",
       "      <td>1.155524</td>\n",
       "      <td>-0.040989</td>\n",
       "      <td>0.056239</td>\n",
       "      <td>-0.798100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105216</td>\n",
       "      <td>-1.158910</td>\n",
       "      <td>0.066244</td>\n",
       "      <td>-0.246443</td>\n",
       "      <td>0.243029</td>\n",
       "      <td>0.209016</td>\n",
       "      <td>-0.201156</td>\n",
       "      <td>-0.270421</td>\n",
       "      <td>0.738035</td>\n",
       "      <td>1.160245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>201403</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.727634</td>\n",
       "      <td>-0.306095</td>\n",
       "      <td>-0.342735</td>\n",
       "      <td>-0.482881</td>\n",
       "      <td>-0.201561</td>\n",
       "      <td>-0.155736</td>\n",
       "      <td>-0.473936</td>\n",
       "      <td>...</td>\n",
       "      <td>0.796639</td>\n",
       "      <td>-0.611919</td>\n",
       "      <td>-0.224547</td>\n",
       "      <td>0.262330</td>\n",
       "      <td>-0.221172</td>\n",
       "      <td>-0.486060</td>\n",
       "      <td>-0.272375</td>\n",
       "      <td>-0.270421</td>\n",
       "      <td>-0.244562</td>\n",
       "      <td>-0.433522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>201405</td>\n",
       "      <td>0</td>\n",
       "      <td>0.563826</td>\n",
       "      <td>-0.306095</td>\n",
       "      <td>4.378344</td>\n",
       "      <td>0.336321</td>\n",
       "      <td>-0.234582</td>\n",
       "      <td>-0.201127</td>\n",
       "      <td>-0.493764</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.612744</td>\n",
       "      <td>-1.002627</td>\n",
       "      <td>-0.176851</td>\n",
       "      <td>-0.563487</td>\n",
       "      <td>-0.221172</td>\n",
       "      <td>0.209016</td>\n",
       "      <td>-0.509773</td>\n",
       "      <td>-0.270421</td>\n",
       "      <td>-0.226272</td>\n",
       "      <td>-0.433522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id   safra  y     VAR_1     VAR_2     VAR_3     VAR_4     VAR_5     VAR_6  \\\n",
       "0  1.0  201404  0 -0.727634 -0.306095 -0.342735 -0.482881  0.673819  0.278301   \n",
       "1  2.0  201407  0  0.627340 -0.306095  2.017805  0.336321 -0.566411  0.150841   \n",
       "2  3.0  201405  0  1.368341  1.278230  2.017805  1.155524 -0.040989  0.056239   \n",
       "3  5.0  201403  1 -0.727634 -0.306095 -0.342735 -0.482881 -0.201561 -0.155736   \n",
       "4  6.0  201405  0  0.563826 -0.306095  4.378344  0.336321 -0.234582 -0.201127   \n",
       "\n",
       "      VAR_7  ...    VAR_54    VAR_57    VAR_59    VAR_65    VAR_66    VAR_67  \\\n",
       "0 -0.213637  ... -0.809742 -0.064927 -0.943633  0.143174 -0.685373  0.142450   \n",
       "1  0.541208  ...  0.175248  1.107199 -0.932521  0.284367  0.800071  0.198180   \n",
       "2 -0.798100  ...  0.105216 -1.158910  0.066244 -0.246443  0.243029  0.209016   \n",
       "3 -0.473936  ...  0.796639 -0.611919 -0.224547  0.262330 -0.221172 -0.486060   \n",
       "4 -0.493764  ... -0.612744 -1.002627 -0.176851 -0.563487 -0.221172  0.209016   \n",
       "\n",
       "     VAR_72    VAR_74    VAR_76    VAR_77  \n",
       "0 -0.014629  2.354360 -0.525657 -0.433522  \n",
       "1  0.107461 -0.270421 -0.499363  0.272032  \n",
       "2 -0.201156 -0.270421  0.738035  1.160245  \n",
       "3 -0.272375 -0.270421 -0.244562 -0.433522  \n",
       "4 -0.509773 -0.270421 -0.226272 -0.433522  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_parquet(\"../data/SOT/base_tratada_treino_sem_outliers.parquet\")\n",
    "df_test = pd.read_parquet(\"../data/SOT/base_tratada_teste.parquet\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>safra</th>\n",
       "      <th>y</th>\n",
       "      <th>VAR_1</th>\n",
       "      <th>VAR_2</th>\n",
       "      <th>VAR_3</th>\n",
       "      <th>VAR_4</th>\n",
       "      <th>VAR_5</th>\n",
       "      <th>VAR_6</th>\n",
       "      <th>VAR_7</th>\n",
       "      <th>...</th>\n",
       "      <th>VAR_54</th>\n",
       "      <th>VAR_57</th>\n",
       "      <th>VAR_59</th>\n",
       "      <th>VAR_65</th>\n",
       "      <th>VAR_66</th>\n",
       "      <th>VAR_67</th>\n",
       "      <th>VAR_72</th>\n",
       "      <th>VAR_74</th>\n",
       "      <th>VAR_76</th>\n",
       "      <th>VAR_77</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>201411</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.727634</td>\n",
       "      <td>-0.306095</td>\n",
       "      <td>-0.342735</td>\n",
       "      <td>-0.482881</td>\n",
       "      <td>1.335696</td>\n",
       "      <td>-0.147789</td>\n",
       "      <td>-0.678210</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.481412</td>\n",
       "      <td>-0.064927</td>\n",
       "      <td>0.031056</td>\n",
       "      <td>-0.311434</td>\n",
       "      <td>-0.128332</td>\n",
       "      <td>0.145546</td>\n",
       "      <td>0.046416</td>\n",
       "      <td>-0.270421</td>\n",
       "      <td>-0.153449</td>\n",
       "      <td>-0.433522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>201411</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.727634</td>\n",
       "      <td>-0.306095</td>\n",
       "      <td>-0.342735</td>\n",
       "      <td>-0.482881</td>\n",
       "      <td>-0.157372</td>\n",
       "      <td>0.001526</td>\n",
       "      <td>-0.251333</td>\n",
       "      <td>...</td>\n",
       "      <td>1.554235</td>\n",
       "      <td>0.638348</td>\n",
       "      <td>0.031056</td>\n",
       "      <td>-0.311434</td>\n",
       "      <td>-0.499693</td>\n",
       "      <td>0.114585</td>\n",
       "      <td>2.528917</td>\n",
       "      <td>-0.270421</td>\n",
       "      <td>-0.153449</td>\n",
       "      <td>-0.433522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>201411</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.537090</td>\n",
       "      <td>-0.306095</td>\n",
       "      <td>-0.342735</td>\n",
       "      <td>-0.482881</td>\n",
       "      <td>-0.008453</td>\n",
       "      <td>0.351812</td>\n",
       "      <td>-0.251333</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.122948</td>\n",
       "      <td>-1.080769</td>\n",
       "      <td>0.636713</td>\n",
       "      <td>0.621421</td>\n",
       "      <td>0.057349</td>\n",
       "      <td>0.161027</td>\n",
       "      <td>-0.408031</td>\n",
       "      <td>0.604506</td>\n",
       "      <td>1.045672</td>\n",
       "      <td>0.200039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>201411</td>\n",
       "      <td>1</td>\n",
       "      <td>0.309768</td>\n",
       "      <td>-0.306095</td>\n",
       "      <td>-0.342735</td>\n",
       "      <td>0.336321</td>\n",
       "      <td>-0.451647</td>\n",
       "      <td>-0.128991</td>\n",
       "      <td>0.166783</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087416</td>\n",
       "      <td>-0.377494</td>\n",
       "      <td>-0.639244</td>\n",
       "      <td>-0.224089</td>\n",
       "      <td>-0.128332</td>\n",
       "      <td>0.145546</td>\n",
       "      <td>-0.723430</td>\n",
       "      <td>2.354360</td>\n",
       "      <td>-0.389530</td>\n",
       "      <td>-0.433522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47</td>\n",
       "      <td>201411</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.727634</td>\n",
       "      <td>-0.306095</td>\n",
       "      <td>-0.342735</td>\n",
       "      <td>-0.482881</td>\n",
       "      <td>-0.157372</td>\n",
       "      <td>-0.183704</td>\n",
       "      <td>-0.251333</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.744076</td>\n",
       "      <td>1.419765</td>\n",
       "      <td>0.031056</td>\n",
       "      <td>1.076810</td>\n",
       "      <td>-0.128332</td>\n",
       "      <td>0.145546</td>\n",
       "      <td>0.334685</td>\n",
       "      <td>-0.270421</td>\n",
       "      <td>-0.153449</td>\n",
       "      <td>-0.433522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   safra  y     VAR_1     VAR_2     VAR_3     VAR_4     VAR_5     VAR_6  \\\n",
       "0  13  201411  1 -0.727634 -0.306095 -0.342735 -0.482881  1.335696 -0.147789   \n",
       "1  20  201411  0 -0.727634 -0.306095 -0.342735 -0.482881 -0.157372  0.001526   \n",
       "2  32  201411  0 -0.537090 -0.306095 -0.342735 -0.482881 -0.008453  0.351812   \n",
       "3  36  201411  1  0.309768 -0.306095 -0.342735  0.336321 -0.451647 -0.128991   \n",
       "4  47  201411  0 -0.727634 -0.306095 -0.342735 -0.482881 -0.157372 -0.183704   \n",
       "\n",
       "      VAR_7  ...    VAR_54    VAR_57    VAR_59    VAR_65    VAR_66    VAR_67  \\\n",
       "0 -0.678210  ... -0.481412 -0.064927  0.031056 -0.311434 -0.128332  0.145546   \n",
       "1 -0.251333  ...  1.554235  0.638348  0.031056 -0.311434 -0.499693  0.114585   \n",
       "2 -0.251333  ... -0.122948 -1.080769  0.636713  0.621421  0.057349  0.161027   \n",
       "3  0.166783  ... -0.087416 -0.377494 -0.639244 -0.224089 -0.128332  0.145546   \n",
       "4 -0.251333  ... -0.744076  1.419765  0.031056  1.076810 -0.128332  0.145546   \n",
       "\n",
       "     VAR_72    VAR_74    VAR_76    VAR_77  \n",
       "0  0.046416 -0.270421 -0.153449 -0.433522  \n",
       "1  2.528917 -0.270421 -0.153449 -0.433522  \n",
       "2 -0.408031  0.604506  1.045672  0.200039  \n",
       "3 -0.723430  2.354360 -0.389530 -0.433522  \n",
       "4  0.334685 -0.270421 -0.153449 -0.433522  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(columns=[\"id\", \"safra\", \"y\"])\n",
    "y_train = df_train[\"y\"]\n",
    "X_test = df_test.drop(columns=[\"id\", \"safra\", \"y\"])\n",
    "y_test = df_test[\"y\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForest\n",
    "rf_params = {\n",
    "    'n_estimators': [50, 100],  \n",
    "    'max_depth': [None, 10],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'bootstrap': [True]\n",
    "}\n",
    "\n",
    "# Ridge \n",
    "ridge_params = {\n",
    "    'alpha': [0.1, 1],\n",
    "    'solver': ['auto', 'saga'], \n",
    "    'fit_intercept': [True]\n",
    "}\n",
    "\n",
    "# Logistic Regression \n",
    "logreg_params = {\n",
    "    'C': [0.1, 1],\n",
    "    'solver': ['lbfgs'],\n",
    "    'max_iter': [100] \n",
    "}\n",
    "\n",
    "# SVC\n",
    "svc_params = {\n",
    "    'C': [0.1, 1],\n",
    "    'kernel': ['linear'],\n",
    "    'gamma': ['scale']\n",
    "}\n",
    "\n",
    "# KNN\n",
    "knn_params = {\n",
    "    'n_neighbors': [3, 5],\n",
    "    'weights': ['uniform'],\n",
    "    'metric': ['euclidean']\n",
    "}\n",
    "\n",
    "# DecisionTree\n",
    "dt_params = {\n",
    "    'criterion': ['gini'],\n",
    "    'max_depth': [10], \n",
    "    'min_samples_split': [2], \n",
    "    'min_samples_leaf': [1], \n",
    "}\n",
    "\n",
    "# AdaBoost \n",
    "ada_params = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'learning_rate': [0.1],\n",
    "    'algorithm': ['SAMME']\n",
    "}\n",
    "\n",
    "# GradientBoosting \n",
    "gb_params = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'learning_rate': [0.1],\n",
    "    'max_depth': [3], \n",
    "    'min_samples_split': [2] \n",
    "}\n",
    "\n",
    "# ExtraTree\n",
    "et_params = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [10], \n",
    "    'min_samples_split': [2], \n",
    "    'min_samples_leaf': [1],\n",
    "    'bootstrap': [True] \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = {\n",
    "    'RandomForest': RandomForestClassifier(random_state=98),\n",
    "    'Ridge': RidgeClassifier(random_state=98),\n",
    "    'LogisticRegression': LogisticRegression(random_state=98),\n",
    "    'SVC': SVC(random_state=98),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'DecisionTree': DecisionTreeClassifier(random_state=98),\n",
    "    'AdaBoost': AdaBoostClassifier(random_state=98),\n",
    "    'GradientBoosting': GradientBoostingClassifier(random_state=98),\n",
    "    'ExtraTrees': ExtraTreesClassifier(random_state=98)\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'RandomForest': rf_params,\n",
    "    'Ridge': ridge_params,\n",
    "    'LogisticRegression': logreg_params,\n",
    "    'SVC': svc_params,\n",
    "    'KNN': knn_params,\n",
    "    'DecisionTree': dt_params,\n",
    "    'AdaBoost': ada_params,\n",
    "    'GradientBoosting': gb_params,\n",
    "    'ExtraTrees': et_params\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificadores sem balanceamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classifiers(clfs, params, X_train, y_train, X_test, y_test, tune_threshold=False):\n",
    "        rgsrs = {}\n",
    "        results = {}\n",
    "\n",
    "        for model in clfs.keys():\n",
    "                gs = GridSearchCV(clfs[model], params[model], cv=5, scoring='f1_weighted', n_jobs=-1)\n",
    "                gs.fit(X_train, y_train)\n",
    "                print(f'{model} best params: {gs.best_params_}')\n",
    "                if tune_threshold:\n",
    "                        gs = TunedThresholdClassifierCV(gs, cv=5, scoring='f1_weighted', n_jobs=-1)\n",
    "                        gs.fit(X_train, y_train)\n",
    "\n",
    "                rgsrs[model] = gs\n",
    "                results[model] = gs.best_score_\n",
    "                print(f'{model} best score: {gs.best_score_}')\n",
    "\n",
    "                y_pred = gs.predict(X_test)\n",
    "                print(f'{model} accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "                print(f'{model} confusion matrix: {confusion_matrix(y_test, y_pred)}')\n",
    "                print(f'{model} classification report:')\n",
    "                print(f'{classification_report(y_test, y_pred)}')\n",
    "                print('------------------------------------------------------------')\n",
    "        \n",
    "        return rgsrs, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest best score: 0.7895887860006082\n",
      "RandomForest best params: {'bootstrap': True, 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "RandomForest accuracy: 0.6757425742574258\n",
      "RandomForest confusion matrix: [[529  10]\n",
      " [252  17]]\n",
      "RandomForest classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.98      0.80       539\n",
      "           1       0.63      0.06      0.11       269\n",
      "\n",
      "    accuracy                           0.68       808\n",
      "   macro avg       0.65      0.52      0.46       808\n",
      "weighted avg       0.66      0.68      0.57       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "Ridge best score: 0.7839054318245146\n",
      "Ridge best params: {'alpha': 1, 'fit_intercept': True, 'solver': 'saga'}\n",
      "Ridge accuracy: 0.681930693069307\n",
      "Ridge confusion matrix: [[524  15]\n",
      " [242  27]]\n",
      "Ridge classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.97      0.80       539\n",
      "           1       0.64      0.10      0.17       269\n",
      "\n",
      "    accuracy                           0.68       808\n",
      "   macro avg       0.66      0.54      0.49       808\n",
      "weighted avg       0.67      0.68      0.59       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "LogisticRegression best score: 0.7859313642295364\n",
      "LogisticRegression best params: {'C': 0.1, 'max_iter': 100, 'solver': 'lbfgs'}\n",
      "LogisticRegression accuracy: 0.6868811881188119\n",
      "LogisticRegression confusion matrix: [[522  17]\n",
      " [236  33]]\n",
      "LogisticRegression classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.97      0.80       539\n",
      "           1       0.66      0.12      0.21       269\n",
      "\n",
      "    accuracy                           0.69       808\n",
      "   macro avg       0.67      0.55      0.51       808\n",
      "weighted avg       0.68      0.69      0.61       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "SVC best score: 0.7726591957168234\n",
      "SVC best params: {'C': 1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "SVC accuracy: 0.6707920792079208\n",
      "SVC confusion matrix: [[527  12]\n",
      " [254  15]]\n",
      "SVC classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.98      0.80       539\n",
      "           1       0.56      0.06      0.10       269\n",
      "\n",
      "    accuracy                           0.67       808\n",
      "   macro avg       0.62      0.52      0.45       808\n",
      "weighted avg       0.64      0.67      0.57       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "KNN best score: 0.6986869771834583\n",
      "KNN best params: {'metric': 'euclidean', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "KNN accuracy: 0.6658415841584159\n",
      "KNN confusion matrix: [[487  52]\n",
      " [218  51]]\n",
      "KNN classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.90      0.78       539\n",
      "           1       0.50      0.19      0.27       269\n",
      "\n",
      "    accuracy                           0.67       808\n",
      "   macro avg       0.59      0.55      0.53       808\n",
      "weighted avg       0.63      0.67      0.61       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "DecisionTree best score: 0.6860738410159029\n",
      "DecisionTree best params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "DecisionTree accuracy: 0.6522277227722773\n",
      "DecisionTree confusion matrix: [[495  44]\n",
      " [237  32]]\n",
      "DecisionTree classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.92      0.78       539\n",
      "           1       0.42      0.12      0.19       269\n",
      "\n",
      "    accuracy                           0.65       808\n",
      "   macro avg       0.55      0.52      0.48       808\n",
      "weighted avg       0.59      0.65      0.58       808\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Leonardo\\anaconda3\\envs\\credit-score-challenge\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost best score: 0.7614176858281264\n",
      "AdaBoost best params: {'algorithm': 'SAMME', 'learning_rate': 0.1, 'n_estimators': 100}\n",
      "AdaBoost accuracy: 0.6707920792079208\n",
      "AdaBoost confusion matrix: [[532   7]\n",
      " [259  10]]\n",
      "AdaBoost classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.99      0.80       539\n",
      "           1       0.59      0.04      0.07       269\n",
      "\n",
      "    accuracy                           0.67       808\n",
      "   macro avg       0.63      0.51      0.43       808\n",
      "weighted avg       0.64      0.67      0.56       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "GradientBoosting best score: 0.8025369499076607\n",
      "GradientBoosting best params: {'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "GradientBoosting accuracy: 0.6806930693069307\n",
      "GradientBoosting confusion matrix: [[526  13]\n",
      " [245  24]]\n",
      "GradientBoosting classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.98      0.80       539\n",
      "           1       0.65      0.09      0.16       269\n",
      "\n",
      "    accuracy                           0.68       808\n",
      "   macro avg       0.67      0.53      0.48       808\n",
      "weighted avg       0.67      0.68      0.59       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "ExtraTrees best score: 0.7802440452647408\n",
      "ExtraTrees best params: {'bootstrap': True, 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "ExtraTrees accuracy: 0.6745049504950495\n",
      "ExtraTrees confusion matrix: [[535   4]\n",
      " [259  10]]\n",
      "ExtraTrees classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.99      0.80       539\n",
      "           1       0.71      0.04      0.07       269\n",
      "\n",
      "    accuracy                           0.67       808\n",
      "   macro avg       0.69      0.51      0.44       808\n",
      "weighted avg       0.69      0.67      0.56       808\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Call the function\n",
    "rgsrs, results = evaluate_classifiers(clfs, params, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Com OverSampling por SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y\n",
       "0    6249\n",
       "1    6249\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote=SMOTE(sampling_strategy='minority') \n",
    "X_train_sampled, y_train_sampled = smote.fit_resample(X_train,y_train)\n",
    "y_train_sampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTrees best params: {'bootstrap': True, 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "ExtraTrees best score: 0.743578808684535\n",
      "ExtraTrees accuracy: 0.7066831683168316\n",
      "ExtraTrees confusion matrix: [[437 102]\n",
      " [135 134]]\n",
      "ExtraTrees classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.81      0.79       539\n",
      "           1       0.57      0.50      0.53       269\n",
      "\n",
      "    accuracy                           0.71       808\n",
      "   macro avg       0.67      0.65      0.66       808\n",
      "weighted avg       0.70      0.71      0.70       808\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "rgsrs, results = evaluate_classifiers(clfs, params, X_train_sampled, y_train_sampled, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tentando FEAT com ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y\n",
       "1    6489\n",
       "0    6249\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "# Applying ADASYN\n",
    "adasyn = ADASYN(sampling_strategy='minority')\n",
    "smote=SMOTE(sampling_strategy='minority') \n",
    "X_train_sampled, y_train_sampled = adasyn.fit_resample(X_train,y_train)\n",
    "y_train_sampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest best score: 0.9301797257212556\n",
      "RandomForest best params: {'bootstrap': True, 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "RandomForest accuracy: 0.7017326732673267\n",
      "RandomForest confusion matrix: [[486  53]\n",
      " [188  81]]\n",
      "RandomForest classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.90      0.80       539\n",
      "           1       0.60      0.30      0.40       269\n",
      "\n",
      "    accuracy                           0.70       808\n",
      "   macro avg       0.66      0.60      0.60       808\n",
      "weighted avg       0.68      0.70      0.67       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "Ridge best score: 0.7579097917622726\n",
      "Ridge best params: {'alpha': 1, 'fit_intercept': True, 'solver': 'saga'}\n",
      "Ridge accuracy: 0.7004950495049505\n",
      "Ridge confusion matrix: [[414 125]\n",
      " [117 152]]\n",
      "Ridge classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.77      0.77       539\n",
      "           1       0.55      0.57      0.56       269\n",
      "\n",
      "    accuracy                           0.70       808\n",
      "   macro avg       0.66      0.67      0.67       808\n",
      "weighted avg       0.70      0.70      0.70       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "LogisticRegression best score: 0.7584542944287156\n",
      "LogisticRegression best params: {'C': 1, 'max_iter': 100, 'solver': 'lbfgs'}\n",
      "LogisticRegression accuracy: 0.7029702970297029\n",
      "LogisticRegression confusion matrix: [[417 122]\n",
      " [118 151]]\n",
      "LogisticRegression classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.77      0.78       539\n",
      "           1       0.55      0.56      0.56       269\n",
      "\n",
      "    accuracy                           0.70       808\n",
      "   macro avg       0.67      0.67      0.67       808\n",
      "weighted avg       0.70      0.70      0.70       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "SVC best score: 0.7565680784275297\n",
      "SVC best params: {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "SVC accuracy: 0.698019801980198\n",
      "SVC confusion matrix: [[400 139]\n",
      " [105 164]]\n",
      "SVC classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.74      0.77       539\n",
      "           1       0.54      0.61      0.57       269\n",
      "\n",
      "    accuracy                           0.70       808\n",
      "   macro avg       0.67      0.68      0.67       808\n",
      "weighted avg       0.71      0.70      0.70       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "KNN best score: 0.8335705585184675\n",
      "KNN best params: {'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "KNN accuracy: 0.5891089108910891\n",
      "KNN confusion matrix: [[335 204]\n",
      " [128 141]]\n",
      "KNN classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.62      0.67       539\n",
      "           1       0.41      0.52      0.46       269\n",
      "\n",
      "    accuracy                           0.59       808\n",
      "   macro avg       0.57      0.57      0.56       808\n",
      "weighted avg       0.62      0.59      0.60       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "DecisionTree best score: 0.7972193080216406\n",
      "DecisionTree best params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "DecisionTree accuracy: 0.655940594059406\n",
      "DecisionTree confusion matrix: [[403 136]\n",
      " [142 127]]\n",
      "DecisionTree classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.75      0.74       539\n",
      "           1       0.48      0.47      0.48       269\n",
      "\n",
      "    accuracy                           0.66       808\n",
      "   macro avg       0.61      0.61      0.61       808\n",
      "weighted avg       0.65      0.66      0.65       808\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Leonardo\\anaconda3\\envs\\credit-score-challenge\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost best score: 0.7860149768729474\n",
      "AdaBoost best params: {'algorithm': 'SAMME', 'learning_rate': 0.1, 'n_estimators': 100}\n",
      "AdaBoost accuracy: 0.693069306930693\n",
      "AdaBoost confusion matrix: [[441  98]\n",
      " [150 119]]\n",
      "AdaBoost classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78       539\n",
      "           1       0.55      0.44      0.49       269\n",
      "\n",
      "    accuracy                           0.69       808\n",
      "   macro avg       0.65      0.63      0.64       808\n",
      "weighted avg       0.68      0.69      0.68       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "GradientBoosting best score: 0.8926470224468087\n",
      "GradientBoosting best params: {'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "GradientBoosting accuracy: 0.7004950495049505\n",
      "GradientBoosting confusion matrix: [[492  47]\n",
      " [195  74]]\n",
      "GradientBoosting classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.91      0.80       539\n",
      "           1       0.61      0.28      0.38       269\n",
      "\n",
      "    accuracy                           0.70       808\n",
      "   macro avg       0.66      0.59      0.59       808\n",
      "weighted avg       0.68      0.70      0.66       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "ExtraTrees best score: 0.8033209237635655\n",
      "ExtraTrees best params: {'bootstrap': True, 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "ExtraTrees accuracy: 0.6905940594059405\n",
      "ExtraTrees confusion matrix: [[392 147]\n",
      " [103 166]]\n",
      "ExtraTrees classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.73      0.76       539\n",
      "           1       0.53      0.62      0.57       269\n",
      "\n",
      "    accuracy                           0.69       808\n",
      "   macro avg       0.66      0.67      0.66       808\n",
      "weighted avg       0.70      0.69      0.70       808\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "rgsrs, results = evaluate_classifiers(clfs, params, X_train_sampled, y_train_sampled, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest best params: {'bootstrap': True, 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "RandomForest best score: 0.8541826933548986\n",
      "RandomForest accuracy: 0.6992574257425742\n",
      "RandomForest confusion matrix: [[481  58]\n",
      " [185  84]]\n",
      "RandomForest classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.89      0.80       539\n",
      "           1       0.59      0.31      0.41       269\n",
      "\n",
      "    accuracy                           0.70       808\n",
      "   macro avg       0.66      0.60      0.60       808\n",
      "weighted avg       0.68      0.70      0.67       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "Ridge best params: {'alpha': 0.1, 'fit_intercept': True, 'solver': 'auto'}\n",
      "Ridge best score: 0.6866028411226593\n",
      "Ridge accuracy: 0.6943069306930693\n",
      "Ridge confusion matrix: [[401 138]\n",
      " [109 160]]\n",
      "Ridge classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.74      0.76       539\n",
      "           1       0.54      0.59      0.56       269\n",
      "\n",
      "    accuracy                           0.69       808\n",
      "   macro avg       0.66      0.67      0.66       808\n",
      "weighted avg       0.70      0.69      0.70       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "LogisticRegression best params: {'C': 0.1, 'max_iter': 100, 'solver': 'lbfgs'}\n",
      "LogisticRegression best score: 0.686848153224221\n",
      "LogisticRegression accuracy: 0.7054455445544554\n",
      "LogisticRegression confusion matrix: [[428 111]\n",
      " [127 142]]\n",
      "LogisticRegression classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.79      0.78       539\n",
      "           1       0.56      0.53      0.54       269\n",
      "\n",
      "    accuracy                           0.71       808\n",
      "   macro avg       0.67      0.66      0.66       808\n",
      "weighted avg       0.70      0.71      0.70       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "SVC best params: {'C': 1, 'gamma': 'scale', 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "rgsrs, results = evaluate_classifiers(clfs, params, X_train_sampled, y_train_sampled, X_test, y_test, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Borderline SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y\n",
       "0    6249\n",
       "1    6249\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "\n",
    "# Applying ADASYN\n",
    "blsmote = BorderlineSMOTE(sampling_strategy='minority', kind='borderline-1')\n",
    "X_train_sampled, y_train_sampled = blsmote.fit_resample(X_train,y_train)\n",
    "y_train_sampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest best score: 0.9313598073338671\n",
      "RandomForest best params: {'bootstrap': True, 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "RandomForest accuracy: 0.6967821782178217\n",
      "RandomForest confusion matrix: [[470  69]\n",
      " [176  93]]\n",
      "RandomForest classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.87      0.79       539\n",
      "           1       0.57      0.35      0.43       269\n",
      "\n",
      "    accuracy                           0.70       808\n",
      "   macro avg       0.65      0.61      0.61       808\n",
      "weighted avg       0.68      0.70      0.67       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "Ridge best score: 0.763205688160128\n",
      "Ridge best params: {'alpha': 0.1, 'fit_intercept': True, 'solver': 'auto'}\n",
      "Ridge accuracy: 0.6955445544554455\n",
      "Ridge confusion matrix: [[411 128]\n",
      " [118 151]]\n",
      "Ridge classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.76      0.77       539\n",
      "           1       0.54      0.56      0.55       269\n",
      "\n",
      "    accuracy                           0.70       808\n",
      "   macro avg       0.66      0.66      0.66       808\n",
      "weighted avg       0.70      0.70      0.70       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "LogisticRegression best score: 0.7634616408134507\n",
      "LogisticRegression best params: {'C': 0.1, 'max_iter': 100, 'solver': 'lbfgs'}\n",
      "LogisticRegression accuracy: 0.7017326732673267\n",
      "LogisticRegression confusion matrix: [[417 122]\n",
      " [119 150]]\n",
      "LogisticRegression classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.77      0.78       539\n",
      "           1       0.55      0.56      0.55       269\n",
      "\n",
      "    accuracy                           0.70       808\n",
      "   macro avg       0.66      0.67      0.67       808\n",
      "weighted avg       0.70      0.70      0.70       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "SVC best score: 0.7622360946164932\n",
      "SVC best params: {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "SVC accuracy: 0.6943069306930693\n",
      "SVC confusion matrix: [[402 137]\n",
      " [110 159]]\n",
      "SVC classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.75      0.76       539\n",
      "           1       0.54      0.59      0.56       269\n",
      "\n",
      "    accuracy                           0.69       808\n",
      "   macro avg       0.66      0.67      0.66       808\n",
      "weighted avg       0.70      0.69      0.70       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "KNN best score: 0.8460953090664531\n",
      "KNN best params: {'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "KNN accuracy: 0.6064356435643564\n",
      "KNN confusion matrix: [[360 179]\n",
      " [139 130]]\n",
      "KNN classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.67      0.69       539\n",
      "           1       0.42      0.48      0.45       269\n",
      "\n",
      "    accuracy                           0.61       808\n",
      "   macro avg       0.57      0.58      0.57       808\n",
      "weighted avg       0.62      0.61      0.61       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "DecisionTree best score: 0.8047240205732585\n",
      "DecisionTree best params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "DecisionTree accuracy: 0.6522277227722773\n",
      "DecisionTree confusion matrix: [[414 125]\n",
      " [156 113]]\n",
      "DecisionTree classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.75       539\n",
      "           1       0.47      0.42      0.45       269\n",
      "\n",
      "    accuracy                           0.65       808\n",
      "   macro avg       0.60      0.59      0.60       808\n",
      "weighted avg       0.64      0.65      0.65       808\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Leonardo\\anaconda3\\envs\\credit-score-challenge\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost best score: 0.7735108667542034\n",
      "AdaBoost best params: {'algorithm': 'SAMME', 'learning_rate': 0.1, 'n_estimators': 100}\n",
      "AdaBoost accuracy: 0.6905940594059405\n",
      "AdaBoost confusion matrix: [[422 117]\n",
      " [133 136]]\n",
      "AdaBoost classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.78      0.77       539\n",
      "           1       0.54      0.51      0.52       269\n",
      "\n",
      "    accuracy                           0.69       808\n",
      "   macro avg       0.65      0.64      0.65       808\n",
      "weighted avg       0.69      0.69      0.69       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "GradientBoosting best score: 0.8896749080800641\n",
      "GradientBoosting best params: {'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "GradientBoosting accuracy: 0.6967821782178217\n",
      "GradientBoosting confusion matrix: [[471  68]\n",
      " [177  92]]\n",
      "GradientBoosting classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.87      0.79       539\n",
      "           1       0.57      0.34      0.43       269\n",
      "\n",
      "    accuracy                           0.70       808\n",
      "   macro avg       0.65      0.61      0.61       808\n",
      "weighted avg       0.68      0.70      0.67       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "ExtraTrees best score: 0.8098529718622898\n",
      "ExtraTrees best params: {'bootstrap': True, 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "ExtraTrees accuracy: 0.6967821782178217\n",
      "ExtraTrees confusion matrix: [[401 138]\n",
      " [107 162]]\n",
      "ExtraTrees classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.74      0.77       539\n",
      "           1       0.54      0.60      0.57       269\n",
      "\n",
      "    accuracy                           0.70       808\n",
      "   macro avg       0.66      0.67      0.67       808\n",
      "weighted avg       0.71      0.70      0.70       808\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "rgsrs, results = evaluate_classifiers(clfs, params, X_train_sampled, y_train_sampled, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smote-ENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y\n",
       "1    5051\n",
       "0    2343\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.combine import SMOTEENN\n",
    "smote_enn = SMOTEENN()\n",
    "X_train_sampled, y_train_sampled = smote_enn.fit_resample(X_train,y_train)\n",
    "y_train_sampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest best score: 0.972185841472737\n",
      "RandomForest best params: {'bootstrap': True, 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "RandomForest accuracy: 0.6695544554455446\n",
      "RandomForest confusion matrix: [[382 157]\n",
      " [110 159]]\n",
      "RandomForest classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.71      0.74       539\n",
      "           1       0.50      0.59      0.54       269\n",
      "\n",
      "    accuracy                           0.67       808\n",
      "   macro avg       0.64      0.65      0.64       808\n",
      "weighted avg       0.69      0.67      0.68       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "Ridge best score: 0.9057700540973199\n",
      "Ridge best params: {'alpha': 1, 'fit_intercept': True, 'solver': 'saga'}\n",
      "Ridge accuracy: 0.6349009900990099\n",
      "Ridge confusion matrix: [[302 237]\n",
      " [ 58 211]]\n",
      "Ridge classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.56      0.67       539\n",
      "           1       0.47      0.78      0.59       269\n",
      "\n",
      "    accuracy                           0.63       808\n",
      "   macro avg       0.65      0.67      0.63       808\n",
      "weighted avg       0.72      0.63      0.64       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "LogisticRegression best score: 0.9154437988992681\n",
      "LogisticRegression best params: {'C': 1, 'max_iter': 100, 'solver': 'lbfgs'}\n",
      "LogisticRegression accuracy: 0.6485148514851485\n",
      "LogisticRegression confusion matrix: [[321 218]\n",
      " [ 66 203]]\n",
      "LogisticRegression classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.60      0.69       539\n",
      "           1       0.48      0.75      0.59       269\n",
      "\n",
      "    accuracy                           0.65       808\n",
      "   macro avg       0.66      0.68      0.64       808\n",
      "weighted avg       0.71      0.65      0.66       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "SVC best score: 0.9137036998531821\n",
      "SVC best params: {'C': 1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "SVC accuracy: 0.6423267326732673\n",
      "SVC confusion matrix: [[313 226]\n",
      " [ 63 206]]\n",
      "SVC classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.58      0.68       539\n",
      "           1       0.48      0.77      0.59       269\n",
      "\n",
      "    accuracy                           0.64       808\n",
      "   macro avg       0.65      0.67      0.64       808\n",
      "weighted avg       0.71      0.64      0.65       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "KNN best score: 0.9659040095834154\n",
      "KNN best params: {'metric': 'euclidean', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "KNN accuracy: 0.556930693069307\n",
      "KNN confusion matrix: [[247 292]\n",
      " [ 66 203]]\n",
      "KNN classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.46      0.58       539\n",
      "           1       0.41      0.75      0.53       269\n",
      "\n",
      "    accuracy                           0.56       808\n",
      "   macro avg       0.60      0.61      0.56       808\n",
      "weighted avg       0.66      0.56      0.56       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "DecisionTree best score: 0.8417266035294123\n",
      "DecisionTree best params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "DecisionTree accuracy: 0.5977722772277227\n",
      "DecisionTree confusion matrix: [[382 157]\n",
      " [168 101]]\n",
      "DecisionTree classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.71      0.70       539\n",
      "           1       0.39      0.38      0.38       269\n",
      "\n",
      "    accuracy                           0.60       808\n",
      "   macro avg       0.54      0.54      0.54       808\n",
      "weighted avg       0.59      0.60      0.60       808\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Leonardo\\anaconda3\\envs\\credit-score-challenge\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost best score: 0.9107064693168357\n",
      "AdaBoost best params: {'algorithm': 'SAMME', 'learning_rate': 0.1, 'n_estimators': 100}\n",
      "AdaBoost accuracy: 0.594059405940594\n",
      "AdaBoost confusion matrix: [[276 263]\n",
      " [ 65 204]]\n",
      "AdaBoost classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.51      0.63       539\n",
      "           1       0.44      0.76      0.55       269\n",
      "\n",
      "    accuracy                           0.59       808\n",
      "   macro avg       0.62      0.64      0.59       808\n",
      "weighted avg       0.69      0.59      0.60       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "GradientBoosting best score: 0.9573007638476756\n",
      "GradientBoosting best params: {'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "GradientBoosting accuracy: 0.6584158415841584\n",
      "GradientBoosting confusion matrix: [[341 198]\n",
      " [ 78 191]]\n",
      "GradientBoosting classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.63      0.71       539\n",
      "           1       0.49      0.71      0.58       269\n",
      "\n",
      "    accuracy                           0.66       808\n",
      "   macro avg       0.65      0.67      0.65       808\n",
      "weighted avg       0.71      0.66      0.67       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "ExtraTrees best score: 0.9329726459639209\n",
      "ExtraTrees best params: {'bootstrap': True, 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "ExtraTrees accuracy: 0.6089108910891089\n",
      "ExtraTrees confusion matrix: [[285 254]\n",
      " [ 62 207]]\n",
      "ExtraTrees classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.53      0.64       539\n",
      "           1       0.45      0.77      0.57       269\n",
      "\n",
      "    accuracy                           0.61       808\n",
      "   macro avg       0.64      0.65      0.61       808\n",
      "weighted avg       0.70      0.61      0.62       808\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "rgsrs, results = evaluate_classifiers(clfs, params, X_train_sampled, y_train_sampled, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parâmetros com Class Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = {\n",
    "    'RandomForest': RandomForestClassifier(class_weight='balanced',random_state=98),\n",
    "    'Ridge': RidgeClassifier(class_weight='balanced', random_state=98),\n",
    "    'LogisticRegression': LogisticRegression(class_weight='balanced', random_state=98),\n",
    "    'SVC': SVC(class_weight='balanced', random_state=98),\n",
    "    'DecisionTree': DecisionTreeClassifier(class_weight=\"balanced\",random_state=98),\n",
    "    # 'AdaBoost': AdaBoostClassifier(random_state=98),\n",
    "    # 'GradientBoosting': GradientBoostingClassifier(random_state=98),\n",
    "    'ExtraTrees': ExtraTreesClassifier(class_weight='balanced', random_state=98)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'RandomForest': rf_params,\n",
    "    'Ridge': ridge_params,\n",
    "    'LogisticRegression': logreg_params,\n",
    "    'SVC': svc_params,\n",
    "    'DecisionTree': dt_params,\n",
    "    # 'AdaBoost': ada_params,\n",
    "    # 'GradientBoosting': gb_params,\n",
    "    'ExtraTrees': et_params\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest best score: 0.791079008614386\n",
      "RandomForest best params: {'bootstrap': True, 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "RandomForest accuracy: 0.7128712871287128\n",
      "RandomForest confusion matrix: [[504  35]\n",
      " [197  72]]\n",
      "RandomForest classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.94      0.81       539\n",
      "           1       0.67      0.27      0.38       269\n",
      "\n",
      "    accuracy                           0.71       808\n",
      "   macro avg       0.70      0.60      0.60       808\n",
      "weighted avg       0.70      0.71      0.67       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "Ridge best score: 0.7858027219857531\n",
      "Ridge best params: {'alpha': 1, 'fit_intercept': True, 'solver': 'auto'}\n",
      "Ridge accuracy: 0.7215346534653465\n",
      "Ridge confusion matrix: [[460  79]\n",
      " [146 123]]\n",
      "Ridge classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.85      0.80       539\n",
      "           1       0.61      0.46      0.52       269\n",
      "\n",
      "    accuracy                           0.72       808\n",
      "   macro avg       0.68      0.66      0.66       808\n",
      "weighted avg       0.71      0.72      0.71       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "LogisticRegression best score: 0.7860844583784397\n",
      "LogisticRegression best params: {'C': 0.1, 'max_iter': 100, 'solver': 'lbfgs'}\n",
      "LogisticRegression accuracy: 0.7153465346534653\n",
      "LogisticRegression confusion matrix: [[452  87]\n",
      " [143 126]]\n",
      "LogisticRegression classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.84      0.80       539\n",
      "           1       0.59      0.47      0.52       269\n",
      "\n",
      "    accuracy                           0.72       808\n",
      "   macro avg       0.68      0.65      0.66       808\n",
      "weighted avg       0.70      0.72      0.71       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "SVC best score: 0.7841610430672349\n",
      "SVC best params: {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "SVC accuracy: 0.7091584158415841\n",
      "SVC confusion matrix: [[448  91]\n",
      " [144 125]]\n",
      "SVC classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.83      0.79       539\n",
      "           1       0.58      0.46      0.52       269\n",
      "\n",
      "    accuracy                           0.71       808\n",
      "   macro avg       0.67      0.65      0.65       808\n",
      "weighted avg       0.70      0.71      0.70       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "DecisionTree best score: 0.692166282540909\n",
      "DecisionTree best params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "DecisionTree accuracy: 0.6534653465346535\n",
      "DecisionTree confusion matrix: [[398 141]\n",
      " [139 130]]\n",
      "DecisionTree classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.74      0.74       539\n",
      "           1       0.48      0.48      0.48       269\n",
      "\n",
      "    accuracy                           0.65       808\n",
      "   macro avg       0.61      0.61      0.61       808\n",
      "weighted avg       0.65      0.65      0.65       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "ExtraTrees best score: 0.777056671833036\n",
      "ExtraTrees best params: {'bootstrap': True, 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "ExtraTrees accuracy: 0.724009900990099\n",
      "ExtraTrees confusion matrix: [[474  65]\n",
      " [158 111]]\n",
      "ExtraTrees classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.88      0.81       539\n",
      "           1       0.63      0.41      0.50       269\n",
      "\n",
      "    accuracy                           0.72       808\n",
      "   macro avg       0.69      0.65      0.65       808\n",
      "weighted avg       0.71      0.72      0.71       808\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "rgsrs, results = evaluate_classifiers(clfs, params, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Weight + SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y\n",
       "0    6249\n",
       "1    3749\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smote = SMOTE(sampling_strategy=0.6, random_state=98) \n",
    "X_train_sampled, y_train_sampled = smote.fit_resample(X_train,y_train)\n",
    "y_train_sampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest best score: 0.8657714388132419\n",
      "RandomForest best params: {'bootstrap': True, 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "RandomForest accuracy: 0.6868811881188119\n",
      "RandomForest confusion matrix: [[519  20]\n",
      " [233  36]]\n",
      "RandomForest classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.96      0.80       539\n",
      "           1       0.64      0.13      0.22       269\n",
      "\n",
      "    accuracy                           0.69       808\n",
      "   macro avg       0.67      0.55      0.51       808\n",
      "weighted avg       0.67      0.69      0.61       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "Ridge best score: 0.7933723144907951\n",
      "Ridge best params: {'alpha': 1, 'fit_intercept': True, 'solver': 'auto'}\n",
      "Ridge accuracy: 0.7103960396039604\n",
      "Ridge confusion matrix: [[452  87]\n",
      " [147 122]]\n",
      "Ridge classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.84      0.79       539\n",
      "           1       0.58      0.45      0.51       269\n",
      "\n",
      "    accuracy                           0.71       808\n",
      "   macro avg       0.67      0.65      0.65       808\n",
      "weighted avg       0.70      0.71      0.70       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "LogisticRegression best score: 0.7936612470271508\n",
      "LogisticRegression best params: {'C': 1, 'max_iter': 100, 'solver': 'lbfgs'}\n",
      "LogisticRegression accuracy: 0.7091584158415841\n",
      "LogisticRegression confusion matrix: [[449  90]\n",
      " [145 124]]\n",
      "LogisticRegression classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.83      0.79       539\n",
      "           1       0.58      0.46      0.51       269\n",
      "\n",
      "    accuracy                           0.71       808\n",
      "   macro avg       0.67      0.65      0.65       808\n",
      "weighted avg       0.70      0.71      0.70       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "SVC best score: 0.792597651269441\n",
      "SVC best params: {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "SVC accuracy: 0.719059405940594\n",
      "SVC confusion matrix: [[447  92]\n",
      " [135 134]]\n",
      "SVC classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.83      0.80       539\n",
      "           1       0.59      0.50      0.54       269\n",
      "\n",
      "    accuracy                           0.72       808\n",
      "   macro avg       0.68      0.66      0.67       808\n",
      "weighted avg       0.71      0.72      0.71       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "DecisionTree best score: 0.7423338483388331\n",
      "DecisionTree best params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "DecisionTree accuracy: 0.6745049504950495\n",
      "DecisionTree confusion matrix: [[397 142]\n",
      " [121 148]]\n",
      "DecisionTree classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.74      0.75       539\n",
      "           1       0.51      0.55      0.53       269\n",
      "\n",
      "    accuracy                           0.67       808\n",
      "   macro avg       0.64      0.64      0.64       808\n",
      "weighted avg       0.68      0.67      0.68       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "ExtraTrees best score: 0.8046064195056696\n",
      "ExtraTrees best params: {'bootstrap': True, 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "ExtraTrees accuracy: 0.7202970297029703\n",
      "ExtraTrees confusion matrix: [[456  83]\n",
      " [143 126]]\n",
      "ExtraTrees classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.85      0.80       539\n",
      "           1       0.60      0.47      0.53       269\n",
      "\n",
      "    accuracy                           0.72       808\n",
      "   macro avg       0.68      0.66      0.66       808\n",
      "weighted avg       0.71      0.72      0.71       808\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "rgsrs, results = evaluate_classifiers(clfs, params, X_train_sampled, y_train_sampled, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAW Data + PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from lib_aux import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>safra</th>\n",
       "      <th>y</th>\n",
       "      <th>VAR_1</th>\n",
       "      <th>VAR_2</th>\n",
       "      <th>VAR_3</th>\n",
       "      <th>VAR_4</th>\n",
       "      <th>VAR_5</th>\n",
       "      <th>VAR_6</th>\n",
       "      <th>VAR_7</th>\n",
       "      <th>...</th>\n",
       "      <th>VAR_69</th>\n",
       "      <th>VAR_70</th>\n",
       "      <th>VAR_71</th>\n",
       "      <th>VAR_72</th>\n",
       "      <th>VAR_73</th>\n",
       "      <th>VAR_74</th>\n",
       "      <th>VAR_75</th>\n",
       "      <th>VAR_76</th>\n",
       "      <th>VAR_77</th>\n",
       "      <th>VAR_78</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>201404</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>124.54</td>\n",
       "      <td>3277.0</td>\n",
       "      <td>51.98</td>\n",
       "      <td>...</td>\n",
       "      <td>156.38</td>\n",
       "      <td>7.52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>477.84</td>\n",
       "      <td>173.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>201407</td>\n",
       "      <td>0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>47.92</td>\n",
       "      <td>2443.0</td>\n",
       "      <td>84.72</td>\n",
       "      <td>...</td>\n",
       "      <td>707.84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>187.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>184.69</td>\n",
       "      <td>54.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>201405</td>\n",
       "      <td>0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>80.38</td>\n",
       "      <td>1824.0</td>\n",
       "      <td>26.63</td>\n",
       "      <td>...</td>\n",
       "      <td>471.86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>732.00</td>\n",
       "      <td>121.98</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>201412</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.58</td>\n",
       "      <td>3796.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>119.96</td>\n",
       "      <td>23.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>417.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>201403</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.46</td>\n",
       "      <td>437.0</td>\n",
       "      <td>40.69</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>914.45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   safra  y  VAR_1  VAR_2  VAR_3  VAR_4   VAR_5   VAR_6  VAR_7  ...  \\\n",
       "0   1  201404  0    0.0    0.0    0.0    0.0  124.54  3277.0  51.98  ...   \n",
       "1   2  201407  0   64.0    0.0    2.0    1.0   47.92  2443.0  84.72  ...   \n",
       "2   3  201405  0   99.0    2.0    2.0    2.0   80.38  1824.0  26.63  ...   \n",
       "3   4  201412  0    0.0    0.0    0.0    0.0   10.58  3796.0    NaN  ...   \n",
       "4   5  201403  1    0.0    0.0    0.0    0.0   70.46   437.0  40.69  ...   \n",
       "\n",
       "   VAR_69  VAR_70  VAR_71  VAR_72  VAR_73  VAR_74  VAR_75  VAR_76  VAR_77  \\\n",
       "0  156.38    7.52     0.0   151.0     0.0     3.0  477.84  173.06    0.00   \n",
       "1  707.84     NaN     NaN   187.0     NaN     NaN     NaN  184.69   54.00   \n",
       "2  471.86     NaN     NaN    96.0     NaN     NaN     NaN  732.00  121.98   \n",
       "3  119.96   23.00     0.0   417.0     0.0     0.0     NaN     NaN    0.00   \n",
       "4     NaN     NaN     0.0    75.0     0.0     0.0  914.45     NaN     NaN   \n",
       "\n",
       "   VAR_78  \n",
       "0     3.0  \n",
       "1     NaN  \n",
       "2     NaN  \n",
       "3     0.0  \n",
       "4     0.0  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/SOR/base_modelo.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_test shape: (808, 81)\n",
      "df_val shape: (786, 81)\n",
      "df shape: (9144, 81)\n"
     ]
    }
   ],
   "source": [
    "# Apply filtering\n",
    "df_test = df[df[\"safra\"] == 201411].copy(deep=True)\n",
    "df_val = df[df[\"safra\"] == 201412].copy(deep=True)\n",
    "df = df[df[\"safra\"] < 201411].reset_index(drop=True)\n",
    "\n",
    "# Print final results\n",
    "print(\"df_test shape:\", df_test.shape)\n",
    "print(\"df_val shape:\", df_val.shape)\n",
    "print(\"df shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(columns=['id', 'safra'], inplace=True)\n",
    "df_test.drop(columns=['id', 'safra'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_count = (df_train.isna().sum() / len(df_train) * 100).sort_values(ascending=False)\n",
    "na_count_critical = na_count[na_count >= 60]\n",
    "df_train.drop(columns = na_count_critical.index, inplace=True)\n",
    "df_test.drop(columns=na_count_critical.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = fill_na_by(df_train, method = \"median\") ### Preenche os NA's\n",
    "df_test = fill_na_by(df_test, method = \"median\") ### Preenche os NA's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(columns=[\"y\"])\n",
    "y_train = df_train[\"y\"]\n",
    "X_test = df_test.drop(columns=[\"y\"])\n",
    "y_test = df_test[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),          # Step 1: StandardScaler for normalization\n",
    "    ('pca', PCA(n_components=0.95)),       # Step 2: PCA to retain 95% variance\n",
    "    ('clf', LogisticRegression())         # Step 3: Logistic Regression classifier\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForest\n",
    "rf_params = {\n",
    "    'clf__n_estimators': [50, 100],  \n",
    "    'clf__max_depth': [None, 10],\n",
    "    'clf__min_samples_split': [2, 5],\n",
    "    'clf__min_samples_leaf': [1, 2],\n",
    "    'clf__bootstrap': [True]\n",
    "}\n",
    "\n",
    "# Ridge \n",
    "ridge_params = {\n",
    "    'clf__alpha': [0.1, 1],\n",
    "    'clf__solver': ['auto', 'saga'], \n",
    "    'clf__fit_intercept': [True]\n",
    "}\n",
    "\n",
    "# Logistic Regression \n",
    "logreg_params = {\n",
    "    'clf__C': [0.1, 1],\n",
    "    'clf__solver': ['lbfgs'],\n",
    "    'clf__max_iter': [100] \n",
    "}\n",
    "\n",
    "# SVC\n",
    "svc_params = {\n",
    "    'clf__C': [0.1, 1],\n",
    "    'clf__kernel': ['linear'],\n",
    "    'clf__gamma': ['scale']\n",
    "}\n",
    "\n",
    "# KNN\n",
    "knn_params = {\n",
    "    'clf__n_neighbors': [3, 5],\n",
    "    'clf__weights': ['uniform'],\n",
    "    'clf__metric': ['euclidean']\n",
    "}\n",
    "\n",
    "# DecisionTree\n",
    "dt_params = {\n",
    "    'clf__criterion': ['gini'],\n",
    "    'clf__max_depth': [10], \n",
    "    'clf__min_samples_split': [2], \n",
    "    'clf__min_samples_leaf': [1], \n",
    "}\n",
    "\n",
    "# AdaBoost \n",
    "ada_params = {\n",
    "    'clf__n_estimators': [50, 100],\n",
    "    'clf__learning_rate': [0.1],\n",
    "    'clf__algorithm': ['SAMME']\n",
    "}\n",
    "\n",
    "# GradientBoosting \n",
    "gb_params = {\n",
    "    'clf__n_estimators': [50, 100],\n",
    "    'clf__learning_rate': [0.1],\n",
    "    'clf__max_depth': [3], \n",
    "    'clf__min_samples_split': [2] \n",
    "}\n",
    "\n",
    "# ExtraTree\n",
    "et_params = {\n",
    "    'clf__n_estimators': [50, 100],\n",
    "    'clf__max_depth': [10], \n",
    "    'clf__min_samples_split': [2], \n",
    "    'clf__min_samples_leaf': [1],\n",
    "    'clf__bootstrap': [True] \n",
    "}\n",
    "\n",
    "params = {\n",
    "    'RandomForest': rf_params,\n",
    "    'Ridge': ridge_params,\n",
    "    'LogisticRegression': logreg_params,\n",
    "    'SVC': svc_params,\n",
    "    'KNN': knn_params,\n",
    "    'DecisionTree': dt_params,\n",
    "    'AdaBoost': ada_params,\n",
    "    'GradientBoosting': gb_params,\n",
    "    'ExtraTrees': et_params\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest best score: 0.7661389890232708\n",
      "RandomForest best params: {'clf__bootstrap': True, 'clf__max_depth': 10, 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 5, 'clf__n_estimators': 100}\n",
      "RandomForest accuracy: 0.7116336633663366\n",
      "RandomForest confusion matrix: [[487  52]\n",
      " [181  88]]\n",
      "RandomForest classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.90      0.81       539\n",
      "           1       0.63      0.33      0.43       269\n",
      "\n",
      "    accuracy                           0.71       808\n",
      "   macro avg       0.68      0.62      0.62       808\n",
      "weighted avg       0.70      0.71      0.68       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "Ridge best score: 0.7750761796494046\n",
      "Ridge best params: {'clf__alpha': 1, 'clf__fit_intercept': True, 'clf__solver': 'saga'}\n",
      "Ridge accuracy: 0.7091584158415841\n",
      "Ridge confusion matrix: [[436 103]\n",
      " [132 137]]\n",
      "Ridge classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.81      0.79       539\n",
      "           1       0.57      0.51      0.54       269\n",
      "\n",
      "    accuracy                           0.71       808\n",
      "   macro avg       0.67      0.66      0.66       808\n",
      "weighted avg       0.70      0.71      0.70       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "LogisticRegression best score: 0.7758526290234855\n",
      "LogisticRegression best params: {'clf__C': 0.1, 'clf__max_iter': 100, 'clf__solver': 'lbfgs'}\n",
      "LogisticRegression accuracy: 0.7116336633663366\n",
      "LogisticRegression confusion matrix: [[434 105]\n",
      " [128 141]]\n",
      "LogisticRegression classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.81      0.79       539\n",
      "           1       0.57      0.52      0.55       269\n",
      "\n",
      "    accuracy                           0.71       808\n",
      "   macro avg       0.67      0.66      0.67       808\n",
      "weighted avg       0.71      0.71      0.71       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "SVC best score: 0.7731281718822827\n",
      "SVC best params: {'clf__C': 0.1, 'clf__gamma': 'scale', 'clf__kernel': 'linear'}\n",
      "SVC accuracy: 0.7066831683168316\n",
      "SVC confusion matrix: [[431 108]\n",
      " [129 140]]\n",
      "SVC classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.80      0.78       539\n",
      "           1       0.56      0.52      0.54       269\n",
      "\n",
      "    accuracy                           0.71       808\n",
      "   macro avg       0.67      0.66      0.66       808\n",
      "weighted avg       0.70      0.71      0.70       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "DecisionTree best score: 0.65475770955633\n",
      "DecisionTree best params: {'clf__criterion': 'gini', 'clf__max_depth': 10, 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 2}\n",
      "DecisionTree accuracy: 0.6349009900990099\n",
      "DecisionTree confusion matrix: [[381 158]\n",
      " [137 132]]\n",
      "DecisionTree classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.71      0.72       539\n",
      "           1       0.46      0.49      0.47       269\n",
      "\n",
      "    accuracy                           0.63       808\n",
      "   macro avg       0.60      0.60      0.60       808\n",
      "weighted avg       0.64      0.63      0.64       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "ExtraTrees best score: 0.7477639700064269\n",
      "ExtraTrees best params: {'clf__bootstrap': True, 'clf__max_depth': 10, 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 2, 'clf__n_estimators': 100}\n",
      "ExtraTrees accuracy: 0.7091584158415841\n",
      "ExtraTrees confusion matrix: [[448  91]\n",
      " [144 125]]\n",
      "ExtraTrees classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.83      0.79       539\n",
      "           1       0.58      0.46      0.52       269\n",
      "\n",
      "    accuracy                           0.71       808\n",
      "   macro avg       0.67      0.65      0.65       808\n",
      "weighted avg       0.70      0.71      0.70       808\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "rgsrs = {}\n",
    "results = {}\n",
    "\n",
    "for model, clf in clfs.items():\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),          # Step 1: StandardScaler for normalization\n",
    "        ('pca', PCA(n_components=0.95)),       # Step 2: PCA to retain 95% variance\n",
    "        ('clf', clf)                           # Step 3: Classifier (this will change)\n",
    "    ])\n",
    "    \n",
    "    # Step 4b: Set up GridSearchCV for each classifier with its respective parameters\n",
    "    gs = GridSearchCV(pipeline, param_grid=params[model], cv=5, n_jobs=-1, scoring='roc_auc')\n",
    "\n",
    "    gs.fit(X_train, y_train)\n",
    "    y_pred = gs.predict(X_test)\n",
    "    rgsrs[model] = gs\n",
    "    results[model] = gs.best_score_\n",
    "    print(f'{model} best score: {gs.best_score_}')\n",
    "    print(f'{model} best params: {gs.best_params_}')\n",
    "    print(f'{model} accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "    print(f'{model} confusion matrix: {confusion_matrix(y_test, y_pred)}')\n",
    "    print(f'{model} classification report:')\n",
    "    print(f'{classification_report(y_test, y_pred)}')\n",
    "    print('------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe com LOGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>safra</th>\n",
       "      <th>y</th>\n",
       "      <th>VAR_2</th>\n",
       "      <th>VAR_3</th>\n",
       "      <th>VAR_4</th>\n",
       "      <th>VAR_9</th>\n",
       "      <th>VAR_14</th>\n",
       "      <th>VAR_17</th>\n",
       "      <th>VAR_19</th>\n",
       "      <th>...</th>\n",
       "      <th>log_VAR_65</th>\n",
       "      <th>log_VAR_15</th>\n",
       "      <th>log_VAR_35</th>\n",
       "      <th>log_VAR_52</th>\n",
       "      <th>log_VAR_5</th>\n",
       "      <th>log_VAR_38</th>\n",
       "      <th>log_VAR_24</th>\n",
       "      <th>log_VAR_45</th>\n",
       "      <th>log_VAR_1</th>\n",
       "      <th>log_VAR_59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>201404</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.306095</td>\n",
       "      <td>-0.342735</td>\n",
       "      <td>-0.482881</td>\n",
       "      <td>-0.979672</td>\n",
       "      <td>1.743720</td>\n",
       "      <td>0.520456</td>\n",
       "      <td>2.336353</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533531</td>\n",
       "      <td>-1.062919</td>\n",
       "      <td>0.433640</td>\n",
       "      <td>-1.840272</td>\n",
       "      <td>0.971073</td>\n",
       "      <td>0.133697</td>\n",
       "      <td>0.809207</td>\n",
       "      <td>0.939938</td>\n",
       "      <td>-1.336531</td>\n",
       "      <td>-0.598788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>201407</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.306095</td>\n",
       "      <td>2.017805</td>\n",
       "      <td>0.336321</td>\n",
       "      <td>-0.220662</td>\n",
       "      <td>-0.263784</td>\n",
       "      <td>-0.190603</td>\n",
       "      <td>0.646951</td>\n",
       "      <td>...</td>\n",
       "      <td>0.632763</td>\n",
       "      <td>-0.134397</td>\n",
       "      <td>-0.273064</td>\n",
       "      <td>-0.090019</td>\n",
       "      <td>-0.582670</td>\n",
       "      <td>0.716001</td>\n",
       "      <td>0.245783</td>\n",
       "      <td>-0.076276</td>\n",
       "      <td>0.988031</td>\n",
       "      <td>-0.580202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>201405</td>\n",
       "      <td>0</td>\n",
       "      <td>1.278230</td>\n",
       "      <td>2.017805</td>\n",
       "      <td>1.155524</td>\n",
       "      <td>1.135459</td>\n",
       "      <td>-0.283257</td>\n",
       "      <td>-0.125598</td>\n",
       "      <td>-0.354176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.163875</td>\n",
       "      <td>0.707608</td>\n",
       "      <td>-1.691245</td>\n",
       "      <td>0.614341</td>\n",
       "      <td>0.254137</td>\n",
       "      <td>-0.552518</td>\n",
       "      <td>0.360154</td>\n",
       "      <td>0.018516</td>\n",
       "      <td>1.227918</td>\n",
       "      <td>0.328328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>201403</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.306095</td>\n",
       "      <td>-0.342735</td>\n",
       "      <td>-0.482881</td>\n",
       "      <td>1.297356</td>\n",
       "      <td>-0.862141</td>\n",
       "      <td>-0.279770</td>\n",
       "      <td>-0.479317</td>\n",
       "      <td>...</td>\n",
       "      <td>0.618105</td>\n",
       "      <td>-0.903285</td>\n",
       "      <td>0.580232</td>\n",
       "      <td>-0.386644</td>\n",
       "      <td>0.039806</td>\n",
       "      <td>0.666908</td>\n",
       "      <td>0.810336</td>\n",
       "      <td>0.073144</td>\n",
       "      <td>-1.336531</td>\n",
       "      <td>0.149738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>201405</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.306095</td>\n",
       "      <td>4.378344</td>\n",
       "      <td>0.336321</td>\n",
       "      <td>-1.131474</td>\n",
       "      <td>-0.283257</td>\n",
       "      <td>-0.125598</td>\n",
       "      <td>-0.479317</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.379017</td>\n",
       "      <td>-0.051390</td>\n",
       "      <td>0.313698</td>\n",
       "      <td>0.044153</td>\n",
       "      <td>-0.007904</td>\n",
       "      <td>0.450513</td>\n",
       "      <td>0.095244</td>\n",
       "      <td>0.018516</td>\n",
       "      <td>0.961717</td>\n",
       "      <td>0.181798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id   safra  y     VAR_2     VAR_3     VAR_4     VAR_9    VAR_14    VAR_17  \\\n",
       "0  1.0  201404  0 -0.306095 -0.342735 -0.482881 -0.979672  1.743720  0.520456   \n",
       "1  2.0  201407  0 -0.306095  2.017805  0.336321 -0.220662 -0.263784 -0.190603   \n",
       "2  3.0  201405  0  1.278230  2.017805  1.155524  1.135459 -0.283257 -0.125598   \n",
       "3  5.0  201403  1 -0.306095 -0.342735 -0.482881  1.297356 -0.862141 -0.279770   \n",
       "4  6.0  201405  0 -0.306095  4.378344  0.336321 -1.131474 -0.283257 -0.125598   \n",
       "\n",
       "     VAR_19  ...  log_VAR_65  log_VAR_15  log_VAR_35  log_VAR_52  log_VAR_5  \\\n",
       "0  2.336353  ...    0.533531   -1.062919    0.433640   -1.840272   0.971073   \n",
       "1  0.646951  ...    0.632763   -0.134397   -0.273064   -0.090019  -0.582670   \n",
       "2 -0.354176  ...    0.163875    0.707608   -1.691245    0.614341   0.254137   \n",
       "3 -0.479317  ...    0.618105   -0.903285    0.580232   -0.386644   0.039806   \n",
       "4 -0.479317  ...   -0.379017   -0.051390    0.313698    0.044153  -0.007904   \n",
       "\n",
       "   log_VAR_38  log_VAR_24  log_VAR_45  log_VAR_1  log_VAR_59  \n",
       "0    0.133697    0.809207    0.939938  -1.336531   -0.598788  \n",
       "1    0.716001    0.245783   -0.076276   0.988031   -0.580202  \n",
       "2   -0.552518    0.360154    0.018516   1.227918    0.328328  \n",
       "3    0.666908    0.810336    0.073144  -1.336531    0.149738  \n",
       "4    0.450513    0.095244    0.018516   0.961717    0.181798  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_parquet(\"../data/SOT/base_tratada_treino_LOG.parquet\")\n",
    "df_test = pd.read_parquet(\"../data/SOT/base_tratada_teste_LOG.parquet\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>safra</th>\n",
       "      <th>y</th>\n",
       "      <th>VAR_2</th>\n",
       "      <th>VAR_3</th>\n",
       "      <th>VAR_4</th>\n",
       "      <th>VAR_9</th>\n",
       "      <th>VAR_14</th>\n",
       "      <th>VAR_17</th>\n",
       "      <th>VAR_19</th>\n",
       "      <th>...</th>\n",
       "      <th>log_VAR_65</th>\n",
       "      <th>log_VAR_15</th>\n",
       "      <th>log_VAR_35</th>\n",
       "      <th>log_VAR_52</th>\n",
       "      <th>log_VAR_5</th>\n",
       "      <th>log_VAR_38</th>\n",
       "      <th>log_VAR_24</th>\n",
       "      <th>log_VAR_45</th>\n",
       "      <th>log_VAR_1</th>\n",
       "      <th>log_VAR_59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>201411</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.306095</td>\n",
       "      <td>-0.342735</td>\n",
       "      <td>-0.482881</td>\n",
       "      <td>-0.220662</td>\n",
       "      <td>-0.253162</td>\n",
       "      <td>-0.066866</td>\n",
       "      <td>-0.479317</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079928</td>\n",
       "      <td>0.939818</td>\n",
       "      <td>-0.099179</td>\n",
       "      <td>0.912198</td>\n",
       "      <td>1.438752</td>\n",
       "      <td>0.145762</td>\n",
       "      <td>1.129604</td>\n",
       "      <td>0.118659</td>\n",
       "      <td>-1.336531</td>\n",
       "      <td>0.308656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>201411</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.306095</td>\n",
       "      <td>-0.342735</td>\n",
       "      <td>-0.482881</td>\n",
       "      <td>1.297356</td>\n",
       "      <td>0.196490</td>\n",
       "      <td>0.696653</td>\n",
       "      <td>-0.479317</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079928</td>\n",
       "      <td>0.362980</td>\n",
       "      <td>-0.099179</td>\n",
       "      <td>0.437479</td>\n",
       "      <td>0.101585</td>\n",
       "      <td>-0.020108</td>\n",
       "      <td>0.047870</td>\n",
       "      <td>0.118659</td>\n",
       "      <td>-1.336531</td>\n",
       "      <td>0.308656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>201411</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.306095</td>\n",
       "      <td>-0.342735</td>\n",
       "      <td>-0.482881</td>\n",
       "      <td>-0.827870</td>\n",
       "      <td>0.600115</td>\n",
       "      <td>-0.889116</td>\n",
       "      <td>3.650333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.827502</td>\n",
       "      <td>-0.542711</td>\n",
       "      <td>-1.690791</td>\n",
       "      <td>0.597780</td>\n",
       "      <td>0.294404</td>\n",
       "      <td>-0.020108</td>\n",
       "      <td>-1.109161</td>\n",
       "      <td>0.118659</td>\n",
       "      <td>-0.054306</td>\n",
       "      <td>0.595424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>201411</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.306095</td>\n",
       "      <td>-0.342735</td>\n",
       "      <td>0.336321</td>\n",
       "      <td>0.690149</td>\n",
       "      <td>-0.486840</td>\n",
       "      <td>1.460171</td>\n",
       "      <td>-0.479317</td>\n",
       "      <td>...</td>\n",
       "      <td>0.190728</td>\n",
       "      <td>0.362980</td>\n",
       "      <td>-0.099179</td>\n",
       "      <td>0.437479</td>\n",
       "      <td>-0.360801</td>\n",
       "      <td>0.426502</td>\n",
       "      <td>0.447838</td>\n",
       "      <td>0.835193</td>\n",
       "      <td>0.841930</td>\n",
       "      <td>-0.198353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47</td>\n",
       "      <td>201411</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.306095</td>\n",
       "      <td>-0.342735</td>\n",
       "      <td>-0.482881</td>\n",
       "      <td>-0.827870</td>\n",
       "      <td>-0.253162</td>\n",
       "      <td>-0.654187</td>\n",
       "      <td>-0.479317</td>\n",
       "      <td>...</td>\n",
       "      <td>1.029933</td>\n",
       "      <td>1.913143</td>\n",
       "      <td>-0.099179</td>\n",
       "      <td>2.523441</td>\n",
       "      <td>0.101585</td>\n",
       "      <td>-0.020108</td>\n",
       "      <td>0.047870</td>\n",
       "      <td>0.118659</td>\n",
       "      <td>-1.336531</td>\n",
       "      <td>0.308656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   safra  y     VAR_2     VAR_3     VAR_4     VAR_9    VAR_14    VAR_17  \\\n",
       "0  13  201411  1 -0.306095 -0.342735 -0.482881 -0.220662 -0.253162 -0.066866   \n",
       "1  20  201411  0 -0.306095 -0.342735 -0.482881  1.297356  0.196490  0.696653   \n",
       "2  32  201411  0 -0.306095 -0.342735 -0.482881 -0.827870  0.600115 -0.889116   \n",
       "3  36  201411  1 -0.306095 -0.342735  0.336321  0.690149 -0.486840  1.460171   \n",
       "4  47  201411  0 -0.306095 -0.342735 -0.482881 -0.827870 -0.253162 -0.654187   \n",
       "\n",
       "     VAR_19  ...  log_VAR_65  log_VAR_15  log_VAR_35  log_VAR_52  log_VAR_5  \\\n",
       "0 -0.479317  ...    0.079928    0.939818   -0.099179    0.912198   1.438752   \n",
       "1 -0.479317  ...    0.079928    0.362980   -0.099179    0.437479   0.101585   \n",
       "2  3.650333  ...    0.827502   -0.542711   -1.690791    0.597780   0.294404   \n",
       "3 -0.479317  ...    0.190728    0.362980   -0.099179    0.437479  -0.360801   \n",
       "4 -0.479317  ...    1.029933    1.913143   -0.099179    2.523441   0.101585   \n",
       "\n",
       "   log_VAR_38  log_VAR_24  log_VAR_45  log_VAR_1  log_VAR_59  \n",
       "0    0.145762    1.129604    0.118659  -1.336531    0.308656  \n",
       "1   -0.020108    0.047870    0.118659  -1.336531    0.308656  \n",
       "2   -0.020108   -1.109161    0.118659  -0.054306    0.595424  \n",
       "3    0.426502    0.447838    0.835193   0.841930   -0.198353  \n",
       "4   -0.020108    0.047870    0.118659  -1.336531    0.308656  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForest\n",
    "rf_params = {\n",
    "    'n_estimators': [50, 100],  \n",
    "    'max_depth': [None, 10],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'bootstrap': [True]\n",
    "}\n",
    "\n",
    "# Ridge \n",
    "ridge_params = {\n",
    "    'alpha': [0.1, 1],\n",
    "    'solver': ['auto', 'saga'], \n",
    "    'fit_intercept': [True]\n",
    "}\n",
    "\n",
    "# Logistic Regression \n",
    "logreg_params = {\n",
    "    'C': [0.1, 1],\n",
    "    'solver': ['lbfgs'],\n",
    "    'max_iter': [100] \n",
    "}\n",
    "\n",
    "# SVC\n",
    "svc_params = {\n",
    "    'C': [0.1, 1],\n",
    "    'kernel': ['linear'],\n",
    "    'gamma': ['scale']\n",
    "}\n",
    "\n",
    "# KNN\n",
    "knn_params = {\n",
    "    'n_neighbors': [3, 5],\n",
    "    'weights': ['uniform'],\n",
    "    'metric': ['euclidean']\n",
    "}\n",
    "\n",
    "# DecisionTree\n",
    "dt_params = {\n",
    "    'criterion': ['gini'],\n",
    "    'max_depth': [10], \n",
    "    'min_samples_split': [2], \n",
    "    'min_samples_leaf': [1], \n",
    "}\n",
    "\n",
    "# AdaBoost \n",
    "ada_params = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'learning_rate': [0.1],\n",
    "    'algorithm': ['SAMME']\n",
    "}\n",
    "\n",
    "# GradientBoosting \n",
    "gb_params = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'learning_rate': [0.1],\n",
    "    'max_depth': [3], \n",
    "    'min_samples_split': [2] \n",
    "}\n",
    "\n",
    "# ExtraTree\n",
    "et_params = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [10], \n",
    "    'min_samples_split': [2], \n",
    "    'min_samples_leaf': [1],\n",
    "    'bootstrap': [True] \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = {\n",
    "    'RandomForest': RandomForestClassifier(random_state=98),\n",
    "    'Ridge': RidgeClassifier(random_state=98),\n",
    "    'LogisticRegression': LogisticRegression(random_state=98),\n",
    "    'SVC': SVC(random_state=98),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'DecisionTree': DecisionTreeClassifier(random_state=98),\n",
    "    'AdaBoost': AdaBoostClassifier(random_state=98),\n",
    "    'GradientBoosting': GradientBoostingClassifier(random_state=98),\n",
    "    'ExtraTrees': ExtraTreesClassifier(random_state=98)\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'RandomForest': rf_params,\n",
    "    'Ridge': ridge_params,\n",
    "    'LogisticRegression': logreg_params,\n",
    "    'SVC': svc_params,\n",
    "    'KNN': knn_params,\n",
    "    'DecisionTree': dt_params,\n",
    "    'AdaBoost': ada_params,\n",
    "    'GradientBoosting': gb_params,\n",
    "    'ExtraTrees': et_params\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(columns=[\"id\", \"safra\", \"y\"])\n",
    "y_train = df_train[\"y\"]\n",
    "X_test = df_test.drop(columns=[\"id\", \"safra\", \"y\"])\n",
    "y_test = df_test[\"y\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BorderlineSMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y\n",
       "0    6453\n",
       "1    6453\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blsmote = BorderlineSMOTE(sampling_strategy='minority', kind='borderline-1')\n",
    "X_train_sampled, y_train_sampled = blsmote.fit_resample(X_train,y_train)\n",
    "y_train_sampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest best score: 0.9311834479618823\n",
      "RandomForest best params: {'bootstrap': True, 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "RandomForest accuracy: 0.7054455445544554\n",
      "RandomForest confusion matrix: [[467  72]\n",
      " [166 103]]\n",
      "RandomForest classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.87      0.80       539\n",
      "           1       0.59      0.38      0.46       269\n",
      "\n",
      "    accuracy                           0.71       808\n",
      "   macro avg       0.66      0.62      0.63       808\n",
      "weighted avg       0.69      0.71      0.69       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "Ridge best score: 0.7660266525428812\n",
      "Ridge best params: {'alpha': 1, 'fit_intercept': True, 'solver': 'auto'}\n",
      "Ridge accuracy: 0.6905940594059405\n",
      "Ridge confusion matrix: [[410 129]\n",
      " [121 148]]\n",
      "Ridge classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.76      0.77       539\n",
      "           1       0.53      0.55      0.54       269\n",
      "\n",
      "    accuracy                           0.69       808\n",
      "   macro avg       0.65      0.66      0.65       808\n",
      "weighted avg       0.69      0.69      0.69       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "LogisticRegression best score: 0.7662187358211975\n",
      "LogisticRegression best params: {'C': 0.1, 'max_iter': 100, 'solver': 'lbfgs'}\n",
      "LogisticRegression accuracy: 0.6955445544554455\n",
      "LogisticRegression confusion matrix: [[416 123]\n",
      " [123 146]]\n",
      "LogisticRegression classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.77      0.77       539\n",
      "           1       0.54      0.54      0.54       269\n",
      "\n",
      "    accuracy                           0.70       808\n",
      "   macro avg       0.66      0.66      0.66       808\n",
      "weighted avg       0.70      0.70      0.70       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "SVC best score: 0.7666878250893554\n",
      "SVC best params: {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "SVC accuracy: 0.6905940594059405\n",
      "SVC confusion matrix: [[406 133]\n",
      " [117 152]]\n",
      "SVC classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.75      0.76       539\n",
      "           1       0.53      0.57      0.55       269\n",
      "\n",
      "    accuracy                           0.69       808\n",
      "   macro avg       0.65      0.66      0.66       808\n",
      "weighted avg       0.70      0.69      0.69       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "KNN best score: 0.8420155054108396\n",
      "KNN best params: {'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "KNN accuracy: 0.620049504950495\n",
      "KNN confusion matrix: [[347 192]\n",
      " [115 154]]\n",
      "KNN classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.64      0.69       539\n",
      "           1       0.45      0.57      0.50       269\n",
      "\n",
      "    accuracy                           0.62       808\n",
      "   macro avg       0.60      0.61      0.60       808\n",
      "weighted avg       0.65      0.62      0.63       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "DecisionTree best score: 0.8096157028863505\n",
      "DecisionTree best params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "DecisionTree accuracy: 0.6695544554455446\n",
      "DecisionTree confusion matrix: [[412 127]\n",
      " [140 129]]\n",
      "DecisionTree classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.76      0.76       539\n",
      "           1       0.50      0.48      0.49       269\n",
      "\n",
      "    accuracy                           0.67       808\n",
      "   macro avg       0.63      0.62      0.62       808\n",
      "weighted avg       0.67      0.67      0.67       808\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Leonardo\\anaconda3\\envs\\credit-score-challenge\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost best score: 0.7935652468272492\n",
      "AdaBoost best params: {'algorithm': 'SAMME', 'learning_rate': 0.1, 'n_estimators': 100}\n",
      "AdaBoost accuracy: 0.7029702970297029\n",
      "AdaBoost confusion matrix: [[447  92]\n",
      " [148 121]]\n",
      "AdaBoost classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.83      0.79       539\n",
      "           1       0.57      0.45      0.50       269\n",
      "\n",
      "    accuracy                           0.70       808\n",
      "   macro avg       0.66      0.64      0.65       808\n",
      "weighted avg       0.69      0.70      0.69       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "GradientBoosting best score: 0.8939307309864113\n",
      "GradientBoosting best params: {'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "GradientBoosting accuracy: 0.693069306930693\n",
      "GradientBoosting confusion matrix: [[481  58]\n",
      " [190  79]]\n",
      "GradientBoosting classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.89      0.80       539\n",
      "           1       0.58      0.29      0.39       269\n",
      "\n",
      "    accuracy                           0.69       808\n",
      "   macro avg       0.65      0.59      0.59       808\n",
      "weighted avg       0.67      0.69      0.66       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "ExtraTrees best score: 0.8248504664720349\n",
      "ExtraTrees best params: {'bootstrap': True, 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "ExtraTrees accuracy: 0.6868811881188119\n",
      "ExtraTrees confusion matrix: [[403 136]\n",
      " [117 152]]\n",
      "ExtraTrees classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.75      0.76       539\n",
      "           1       0.53      0.57      0.55       269\n",
      "\n",
      "    accuracy                           0.69       808\n",
      "   macro avg       0.65      0.66      0.65       808\n",
      "weighted avg       0.69      0.69      0.69       808\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "rgsrs, results = evaluate_classifiers(clfs, params, X_train_sampled, y_train_sampled, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weigthed Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = {\n",
    "    'RandomForest': RandomForestClassifier(class_weight='balanced',random_state=98),\n",
    "    'Ridge': RidgeClassifier(class_weight='balanced', random_state=98),\n",
    "    'LogisticRegression': LogisticRegression(class_weight='balanced', random_state=98),\n",
    "    'SVC': SVC(class_weight='balanced', random_state=98),\n",
    "    'DecisionTree': DecisionTreeClassifier(class_weight=\"balanced\",random_state=98),\n",
    "    # 'AdaBoost': AdaBoostClassifier(random_state=98),\n",
    "    # 'GradientBoosting': GradientBoostingClassifier(random_state=98),\n",
    "    'ExtraTrees': ExtraTreesClassifier(class_weight='balanced', random_state=98)\n",
    "}\n",
    "params = {\n",
    "    'RandomForest': rf_params,\n",
    "    'Ridge': ridge_params,\n",
    "    'LogisticRegression': logreg_params,\n",
    "    'SVC': svc_params,\n",
    "    'DecisionTree': dt_params,\n",
    "    # 'AdaBoost': ada_params,\n",
    "    # 'GradientBoosting': gb_params,\n",
    "    'ExtraTrees': et_params\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest best score: 0.9309485480285336\n",
      "RandomForest best params: {'bootstrap': True, 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "RandomForest accuracy: 0.7054455445544554\n",
      "RandomForest confusion matrix: [[467  72]\n",
      " [166 103]]\n",
      "RandomForest classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.87      0.80       539\n",
      "           1       0.59      0.38      0.46       269\n",
      "\n",
      "    accuracy                           0.71       808\n",
      "   macro avg       0.66      0.62      0.63       808\n",
      "weighted avg       0.69      0.71      0.69       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "Ridge best score: 0.7660270130979198\n",
      "Ridge best params: {'alpha': 0.1, 'fit_intercept': True, 'solver': 'auto'}\n",
      "Ridge accuracy: 0.6905940594059405\n",
      "Ridge confusion matrix: [[410 129]\n",
      " [121 148]]\n",
      "Ridge classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.76      0.77       539\n",
      "           1       0.53      0.55      0.54       269\n",
      "\n",
      "    accuracy                           0.69       808\n",
      "   macro avg       0.65      0.66      0.65       808\n",
      "weighted avg       0.69      0.69      0.69       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "LogisticRegression best score: 0.7662172947173118\n",
      "LogisticRegression best params: {'C': 0.1, 'max_iter': 100, 'solver': 'lbfgs'}\n",
      "LogisticRegression accuracy: 0.6955445544554455\n",
      "LogisticRegression confusion matrix: [[416 123]\n",
      " [123 146]]\n",
      "LogisticRegression classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.77      0.77       539\n",
      "           1       0.54      0.54      0.54       269\n",
      "\n",
      "    accuracy                           0.70       808\n",
      "   macro avg       0.66      0.66      0.66       808\n",
      "weighted avg       0.70      0.70      0.70       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "SVC best score: 0.7666782177301183\n",
      "SVC best params: {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "SVC accuracy: 0.6905940594059405\n",
      "SVC confusion matrix: [[406 133]\n",
      " [117 152]]\n",
      "SVC classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.75      0.76       539\n",
      "           1       0.53      0.57      0.55       269\n",
      "\n",
      "    accuracy                           0.69       808\n",
      "   macro avg       0.65      0.66      0.66       808\n",
      "weighted avg       0.70      0.69      0.69       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "DecisionTree best score: 0.8096885987245626\n",
      "DecisionTree best params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "DecisionTree accuracy: 0.6695544554455446\n",
      "DecisionTree confusion matrix: [[412 127]\n",
      " [140 129]]\n",
      "DecisionTree classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.76      0.76       539\n",
      "           1       0.50      0.48      0.49       269\n",
      "\n",
      "    accuracy                           0.67       808\n",
      "   macro avg       0.63      0.62      0.62       808\n",
      "weighted avg       0.67      0.67      0.67       808\n",
      "\n",
      "------------------------------------------------------------\n",
      "ExtraTrees best score: 0.8246536356996632\n",
      "ExtraTrees best params: {'bootstrap': True, 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "ExtraTrees accuracy: 0.6868811881188119\n",
      "ExtraTrees confusion matrix: [[403 136]\n",
      " [117 152]]\n",
      "ExtraTrees classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.75      0.76       539\n",
      "           1       0.53      0.57      0.55       269\n",
      "\n",
      "    accuracy                           0.69       808\n",
      "   macro avg       0.65      0.66      0.65       808\n",
      "weighted avg       0.69      0.69      0.69       808\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "rgsrs, results = evaluate_classifiers(clfs, params, X_train_sampled, y_train_sampled, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning de Threshold do ExtraTree com Borderline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_parquet(\"../data/SOT/base_tratada_treino_sem_outliers.parquet\")\n",
    "df_test = pd.read_parquet(\"../data/SOT/base_tratada_teste.parquet\")\n",
    "X_train = df_train.drop(columns=[\"id\", \"safra\", \"y\"])\n",
    "y_train = df_train[\"y\"]\n",
    "X_test = df_test.drop(columns=[\"id\", \"safra\", \"y\"])\n",
    "y_test = df_test[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y\n",
       "0    6249\n",
       "1    6249\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blsmote = BorderlineSMOTE(sampling_strategy='minority', kind='borderline-1')\n",
    "X_train_sampled, y_train_sampled = blsmote.fit_resample(X_train,y_train)\n",
    "y_train_sampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ExtraTree\n",
    "et_params = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [10], \n",
    "    'min_samples_split': [2], \n",
    "    'min_samples_leaf': [1],\n",
    "    'bootstrap': [True] \n",
    "}\n",
    "\n",
    "clfs = {\n",
    "    'ExtraTrees': ExtraTreesClassifier(random_state=98)\n",
    "}\n",
    "params = {\n",
    "    'ExtraTrees': et_params\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTrees best score: 0.8098742185300241\n",
      "ExtraTrees best params: {'bootstrap': True, 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "ExtraTrees accuracy: 0.6943069306930693\n",
      "ExtraTrees confusion matrix: [[396 143]\n",
      " [104 165]]\n",
      "ExtraTrees classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.73      0.76       539\n",
      "           1       0.54      0.61      0.57       269\n",
      "\n",
      "    accuracy                           0.69       808\n",
      "   macro avg       0.66      0.67      0.67       808\n",
      "weighted avg       0.71      0.69      0.70       808\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "rgsrs, results = evaluate_classifiers(clfs, params, X_train_sampled, y_train_sampled, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.7570601851237881\n",
      "Test F1: 0.5636942675159236\n",
      "Threshold:  0.469\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[357, 182],\n",
       "       [ 92, 177]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_model = TunedThresholdClassifierCV(rgsrs[\"ExtraTrees\"], cv=5, scoring='f1', store_cv_results=True, random_state=98)\n",
    "tuned_model.fit(X_train_sampled, y_train_sampled)\n",
    "avg_f1_train = tuned_model.best_score_\n",
    "f1 = f1_score(y_test, tuned_model.predict(X_test))\n",
    "print(f\"Train F1: {avg_f1_train}\")\n",
    "print(f\"Test F1: {f1}\")\n",
    "print(f\"Threshold: {tuned_model.best_threshold_: .3f}\")\n",
    "\n",
    "confusion_matrix(y_test, tuned_model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.66      0.72       539\n",
      "           1       0.49      0.66      0.56       269\n",
      "\n",
      "    accuracy                           0.66       808\n",
      "   macro avg       0.64      0.66      0.64       808\n",
      "weighted avg       0.69      0.66      0.67       808\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, tuned_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "credit-score-challenge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
